---
title: Pre-Pilot Optimization of Conversation-Based Assessment Items Using Synthetic Response Data
date: '2025-10-01'
author:
  - name: Tyler Burleigh
  - name: Jing Chen
  - name: Kristen Dicerbo
options:
  categories:
    - Large Language Models
    - Educational Assessment
    - Automated Scoring
  pub-info:
    reference: >-
      Burleigh, T., Chen, J., & Dicerbo, K. (2025). Pre-Pilot Optimization of Conversation-Based Assessment Items Using Synthetic Response Data. Proceedings of the Artificial Intelligence in Measurement and Education Conference (AIME-Con), 61-68.
    links:
      - name: Publisher page
        url: https://aclanthology.org/2025.aimecon-sessions.7/
        icon: fa-solid fa-scroll
---

:::{articleinfo} burleigh-et-al-2025b
:::


## Abstract

Story retell assessments provide valuable insights into reading comprehension but face implementation barriers due to time-intensive administration and scoring. This study examines whether Large Language Models (LLMs) can reliably replicate human judgment in grading story retells using synthetic response data. The system uses AI to generate 150 synthetic responses per item for iterative testing. Across 17 items and 68 iteration cycles, scoring reliability improved from 59% to 100% of items meeting criteria. Results support hybrid assessment architectures where AI handles routine scoring, enabling more frequent formative assessment while directing teacher expertise toward students requiring nuanced support.
