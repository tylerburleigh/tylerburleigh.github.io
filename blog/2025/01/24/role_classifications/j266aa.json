{
  "filename": "j266aa",
  "responsibilities": [
    "\u2022 Build and operationalize complex data solutions, correct problems, apply transformations, and recommend data cleansing/quality solutions.",
    "\u2022 Design complex data solutions.",
    "\u2022 Perform analysis of complex sources to determine value and use and recommend data to include in analytical processes.",
    "\u2022 Incorporate core data management competencies including data governance, data security, and data quality.",
    "\u2022 Collaborate within and across teams to support delivery and educate end users on complex data products/analytic environment.",
    "\u2022 Perform data and system analysis, assessment, and resolution for complex defects and incidents and correct as appropriate.",
    "\u2022 Test data movement, transformation code, and data components.",
    "\u2022 Design and implement secure data pipelines to support LLM and GenAI applications across international markets.",
    "\u2022 Build and maintain vector database infrastructure for efficient storage and retrieval of embeddings used in RAG applications.",
    "\u2022 Develop APIs and integration layers for enterprise AI services, ensuring compliance with regional data protection requirements.",
    "\u2022 Create and optimize data streaming architectures for real-time AI applications across multiple geographic regions.",
    "\u2022 Implement monitoring and observability solutions for AI data pipelines to ensure performance and reliability across international operations.",
    "\u2022 Collaborate with international teams to establish data governance practices for AI applications across different regulatory environments.",
    "\u2022 Perform other duties as assigned."
  ],
  "skills": [
    "\u2022 Technical expertise in Large Language Models (LLMs) and Generative AI platforms (Anthropic, OpenAI).",
    "\u2022 Prompt engineering and LLM optimization techniques.",
    "\u2022 Retrieval-Augmented Generation (RAG) architectures.",
    "\u2022 Vector database implementations (Postgres, OpenSearch, Pinecone, or Weaviate).",
    "\u2022 AI Agent development and orchestration.",
    "\u2022 Enterprise API development and integration.",
    "\u2022 Responsible AI and AI safety practices.",
    "\u2022 Data security and privacy frameworks.",
    "\u2022 Cloud and AI infrastructure experience, including AWS services (especially Bedrock, Lambda, S3).",
    "\u2022 LLM deployment strategies and integration.",
    "\u2022 Model serving and scaling techniques.",
    "\u2022 Container orchestration (Kubernetes/Docker).",
    "\u2022 Infrastructure as Code (Terraform).",
    "\u2022 MLOps and monitoring practices.",
    "\u2022 Data processing and storage, including Snowflake and data warehouse technologies.",
    "\u2022 Real-time and batch processing systems.",
    "\u2022 ETL/ELT pipeline development.",
    "\u2022 Data quality and validation frameworks.",
    "\u2022 Vector embedding techniques.",
    "\u2022 Knowledge base creation and management.",
    "\u2022 Development practices, including Python, SQL, and shell scripting.",
    "\u2022 API design and development.",
    "\u2022 Git and CI/CD pipelines.",
    "\u2022 Testing and monitoring frameworks.",
    "\u2022 Documentation and technical writing.",
    "\u2022 Agile/Scrum methodologies."
  ],
  "analysis": "The job responsibilities and skills focus heavily on data solutions, AI applications, and infrastructure, with a strong emphasis on data pipelines, AI services, and compliance with data protection requirements. The skills required include expertise in LLMs, AI platforms, vector databases, API development, cloud infrastructure, and MLOps practices.\n\n1. **AI Research Scientist**: This option focuses on AI methodologies, experiments, and staying current with AI research. While there is some overlap in LLM expertise, the job's focus on data solutions and infrastructure is not aligned with this role's primary focus on research and experimentation.\n\n2. **AI/ML Engineer**: This role involves transforming research into scalable AI solutions and developing data pipelines. There is some overlap with the job's focus on data pipelines and AI applications, but the job's emphasis on infrastructure and compliance is not a primary focus here.\n\n3. **MLOps / AI Infrastructure Engineer**: This option is closely aligned with the job's focus on reliable deployment, scaling, and monitoring of AI systems. The responsibilities and skills related to CI/CD pipelines, monitoring, and infrastructure management match well with the job's requirements.\n\n4. **AI Solution Architect**: This role involves designing AI solutions and ensuring compliance with data governance and security, which aligns with some aspects of the job. However, the job's focus on data pipelines and infrastructure is more technical than the architect's focus on solution design and collaboration.\n\n5. **Data Scientist**: This role focuses on statistical analysis, machine learning, and data visualization, which does not align with the job's emphasis on data solutions and AI infrastructure.\n\n6. **Data Engineer**: This role involves designing and maintaining data pipelines and architectures, which aligns with the job's focus on data solutions and infrastructure. The skills in ETL/ELT, cloud services, and data governance are relevant to the job.\n\n7. **Product Manager**: This role focuses on product vision and strategy, which does not align with the technical and infrastructure-focused responsibilities of the job.\n\n8. **Software Engineer**: This role involves software development and system architecture, which does not align with the job's focus on data solutions and AI infrastructure.\n\nThe job is most similar to the \"MLOps / AI Infrastructure Engineer\" option, as it involves ensuring reliable deployment, scaling, and monitoring of AI systems, which matches the job's focus on data pipelines, AI applications, and infrastructure management.",
  "role_classification": 3,
  "role_title": "MLOps / AI Infrastructure Engineer"
}