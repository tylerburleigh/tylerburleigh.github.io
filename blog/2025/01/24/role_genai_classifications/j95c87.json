{
  "filename": "j95c87",
  "responsibilities": [
    "Co-design future hardware for programmability and performance with hardware vendors.",
    "Assist hardware vendors in developing optimal kernels and add support for it in our compiler.",
    "Develop performance estimates for critical kernels for different hardware configurations.",
    "Work with machine learning engineers, kernel engineers, and compiler developers to understand their vision and needs from high-performance accelerators.",
    "Manage communication and coordination with internal and external partners.",
    "Influence the roadmap of hardware partners to optimize them for OpenAI\u2019s workloads.",
    "Evaluate potential partners\u2019 accelerators and platforms.",
    "Build simulations and performance models to progressively improve decision-making fidelity.",
    "Understand and influence roadmaps for hardware partners for datacenter networks, racks, and buildings as the scope of the role and team grows."
  ],
  "qualifications": [
    "Strong experience in software/hardware co-design.",
    "Deep understanding of GPU and/or other AI accelerators.",
    "Experience with CUDA or a related accelerator programming language.",
    "Experience driving Machine Learning accuracy with low precision formats.",
    "Familiarity with the fundamentals of deep learning computing and chip microarchitecture.",
    "Ability to actively collaborate with ML engineers, kernel writers, and compiler developers.",
    "Strong coding skills in C/C++ and Python.",
    "Strong understanding of LLMs and challenges related to their training and inference."
  ],
  "analysis": "The job involves co-designing hardware for performance and programmability, working with hardware vendors, and developing performance estimates for critical kernels. The responsibilities also include working with machine learning engineers and understanding their needs from high-performance accelerators. The skills required include a strong understanding of GPU and AI accelerators, experience with CUDA, and familiarity with deep learning computing and chip microarchitecture. Importantly, the skills section explicitly mentions a \"Strong understanding of LLMs and challenges related to their training and inference.\" This indicates that the job involves working with language models, specifically Large Language Models (LLMs), which are a subset of Generative AI (GenAI). The focus on optimizing hardware for OpenAI's workloads further suggests involvement with AI models, likely including LLMs.",
  "is_genai_role": true
}