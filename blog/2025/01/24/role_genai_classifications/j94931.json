{
  "filename": "j94931",
  "responsibilities": [
    "Design, build, and scale the infrastructure for data engineering, data science, and analytics efforts.",
    "Lay down industry standard data engineering practices and solutions.",
    "Bring in new tools and technologies when necessary.",
    "Scale current data infrastructure.",
    "Evangelize and drive new technology adoption."
  ],
  "qualifications": [
    "Strong infrastructure and data engineering skills.",
    "Strong programming skills in Python or a similar language.",
    "Experience deploying and managing open source frameworks such as Airflow, Kafka, Spark, Kubernetes, Terraform, Docker, Helm charts.",
    "Comfortable working with Spark/PySpark.",
    "Working knowledge of OLAP and OLTP databases like Clickhouse, Postgres.",
    "Experience with security, controls, and access management for data."
  ],
  "analysis": "The job responsibilities focus on designing, building, and scaling infrastructure for data engineering, data science, and analytics. It emphasizes industry-standard data engineering practices, scaling data infrastructure, and adopting new technologies. The skills required include strong infrastructure and data engineering skills, programming in Python or similar languages, and experience with open-source frameworks like Airflow, Kafka, Spark, Kubernetes, Terraform, Docker, and Helm charts. Additionally, there is a need for knowledge of OLAP and OLTP databases and experience with security and access management for data.\n\nThere is no mention of Generative AI (GenAI) or language models (LLMs) in the responsibilities or skills. The focus is primarily on data engineering, infrastructure, and related technologies, rather than on AI model development or deployment, which would typically involve GenAI or LLMs.",
  "is_genai_role": false
}