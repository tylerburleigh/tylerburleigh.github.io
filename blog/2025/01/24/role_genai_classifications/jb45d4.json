{
  "filename": "jb45d4",
  "responsibilities": [
    "Enable the building, maintenance, enhancements, and support of new and existing Azure data pipelines for various analytical use cases.",
    "Partner with team members to understand data and leverage it to serve businesses and operations.",
    "Ensure adherence to Manulife\u2019s IT security and Risk guidelines.",
    "Gain deep understanding of data by collaborating with business and advanced analytics partners.",
    "Design, curate, and publish connected data sets that enable users to self-serve.",
    "Propose technology improvements or innovative solutions to solve business problems.",
    "Collaborate with Architecture, security, and risk teams to implement latest guidelines and Azure standard methodologies.",
    "Automate infrastructure provisioning and deployment using tools such as terraform.",
    "Implement CI/CD pipelines for automated code deployment.",
    "Participate in Agile sprints and ceremonies; support rapid iteration and development.",
    "Cultivate and maintain strong relationships and foster collaboration with various teams and partners within the organization."
  ],
  "qualifications": [
    "Solid understanding of Azure infrastructure, including subscriptions, resource groups, resources, access control with RBAC, integrations with Azure AD, and Azure security principles.",
    "Strong hands-on knowledge of Azure Databricks (Unity Catalog), ADF, ADLS, Synapse Serverless/dedicated/spark pools, Python, PySpark, and T-SQL.",
    "Experience designing and developing scripts for ETL processes and automation in Azure data factory and Azure databricks.",
    "High proficiency in GIT/Jenkins/dev ops processes to maintain and resolve issues with data pipelines in production.",
    "Knowledge of implementing azure technologies and networking via terraform.",
    "Good understanding of data modeling/data marts/Lake house architecture, SCD, data mesh, and delta lake.",
    "Solid understanding of data privacy and compliance regulations and standard methodologies for preserving customer data.",
    "Knowledge of insurance and financial products is a plus."
  ],
  "analysis": "The job responsibilities and skills listed focus primarily on data engineering and infrastructure management within the Azure ecosystem. The responsibilities include building and maintaining Azure data pipelines, collaborating with teams to understand and leverage data, ensuring IT security, and automating infrastructure provisioning. The skills required include a solid understanding of Azure infrastructure, Azure Databricks, Azure Data Factory, and other Azure services, as well as proficiency in Python, PySpark, and T-SQL.\n\nThere is no mention of Generative AI (GenAI) or language models (LLMs) in the responsibilities or skills. The focus is on data engineering, data pipelines, and Azure infrastructure, which are not directly related to working with GenAI or LLMs. Therefore, this job does not involve working with Generative AI or language models.",
  "is_genai_role": false
}