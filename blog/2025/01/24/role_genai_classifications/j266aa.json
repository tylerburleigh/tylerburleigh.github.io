{
  "filename": "j266aa",
  "responsibilities": [
    "\u2022 Build and operationalize complex data solutions, correct problems, apply transformations, and recommend data cleansing/quality solutions.",
    "\u2022 Design complex data solutions.",
    "\u2022 Perform analysis of complex sources to determine value and use and recommend data to include in analytical processes.",
    "\u2022 Incorporate core data management competencies including data governance, data security, and data quality.",
    "\u2022 Collaborate within and across teams to support delivery and educate end users on complex data products/analytic environment.",
    "\u2022 Perform data and system analysis, assessment, and resolution for complex defects and incidents and correct as appropriate.",
    "\u2022 Test data movement, transformation code, and data components.",
    "\u2022 Design and implement secure data pipelines to support LLM and GenAI applications across international markets.",
    "\u2022 Build and maintain vector database infrastructure for efficient storage and retrieval of embeddings used in RAG applications.",
    "\u2022 Develop APIs and integration layers for enterprise AI services, ensuring compliance with regional data protection requirements.",
    "\u2022 Create and optimize data streaming architectures for real-time AI applications across multiple geographic regions.",
    "\u2022 Implement monitoring and observability solutions for AI data pipelines to ensure performance and reliability across international operations.",
    "\u2022 Collaborate with international teams to establish data governance practices for AI applications across different regulatory environments.",
    "\u2022 Perform other duties as assigned."
  ],
  "qualifications": [
    "\u2022 Technical expertise in Large Language Models (LLMs) and Generative AI platforms (Anthropic, OpenAI).",
    "\u2022 Prompt engineering and LLM optimization techniques.",
    "\u2022 Retrieval-Augmented Generation (RAG) architectures.",
    "\u2022 Vector database implementations (Postgres, OpenSearch, Pinecone, or Weaviate).",
    "\u2022 AI Agent development and orchestration.",
    "\u2022 Enterprise API development and integration.",
    "\u2022 Responsible AI and AI safety practices.",
    "\u2022 Data security and privacy frameworks.",
    "\u2022 Cloud and AI infrastructure experience, including AWS services (especially Bedrock, Lambda, S3).",
    "\u2022 LLM deployment strategies and integration.",
    "\u2022 Model serving and scaling techniques.",
    "\u2022 Container orchestration (Kubernetes/Docker).",
    "\u2022 Infrastructure as Code (Terraform).",
    "\u2022 MLOps and monitoring practices.",
    "\u2022 Data processing and storage, including Snowflake and data warehouse technologies.",
    "\u2022 Real-time and batch processing systems.",
    "\u2022 ETL/ELT pipeline development.",
    "\u2022 Data quality and validation frameworks.",
    "\u2022 Vector embedding techniques.",
    "\u2022 Knowledge base creation and management.",
    "\u2022 Development practices, including Python, SQL, and shell scripting.",
    "\u2022 API design and development.",
    "\u2022 Git and CI/CD pipelines.",
    "\u2022 Testing and monitoring frameworks.",
    "\u2022 Documentation and technical writing.",
    "\u2022 Agile/Scrum methodologies."
  ],
  "analysis": "The job responsibilities and skills clearly indicate involvement with Generative AI (GenAI) and Large Language Models (LLMs). The responsibilities include designing and implementing secure data pipelines to support LLM and GenAI applications, building and maintaining vector database infrastructure for RAG applications, and developing APIs for enterprise AI services. These tasks are directly related to the deployment and operationalization of AI models, including LLMs and GenAI.\n\nThe skills section further reinforces this with explicit mentions of technical expertise in LLMs and GenAI platforms, prompt engineering, LLM optimization techniques, and AI agent development. Additionally, skills such as vector database implementations, LLM deployment strategies, and model serving and scaling techniques are directly related to working with language models and generative AI technologies.\n\nOverall, both the responsibilities and skills sections provide strong evidence that the job involves working with Generative AI and language models.",
  "is_genai_role": true
}