{
  "filename": "jadbd5",
  "responsibilities": [
    "Provide coding and design leadership on the construction and maintenance of robust and efficient data applications and reusable frameworks.",
    "Develop data pipelines in an AWS Cloud environment using Python and AWS Glue (PySpark) technology.",
    "Coordinate or participate in all aspects of the development cycle from design and development to release planning and implementation of data systems.",
    "Mentor and guide other data developers across various locations to ensure all code follows applicable standards and is efficient and easily maintainable.",
    "Translate requirements into detailed functional and technical design using architecturally approved technology.",
    "Provide high level solution options and estimates for project proposals, and detailed work estimates in support of assigned work.",
    "Deliver solutions according to Systems Development Life Cycle (SDLC) methodology for either waterfall or agile projects.",
    "Provide consultation for the evaluation of data and software systems.",
    "Develop and manage effective working relationships with other departments, groups or personnel with whom work must be coordinated."
  ],
  "qualifications": [
    "Strong core competency in SQL.",
    "Experience with Big Data including knowledge of Hive.",
    "Experience with creating complex data frames/structures in Hadoop for data integration and complex calculations.",
    "Experience with HDFS, Tez, and Spark.",
    "Understanding and/or hands-on experience with Step and Lambda functions.",
    "Experience with data modeling concepts and data structure design for supporting high performing read SQLs.",
    "Advanced level of SQL writing skills for handling large volume of data efficiently.",
    "Ability to deep dive in existing data integration code to analyze and reverse engineer.",
    "Experience with handling complex multi-level data transformations to integrate source system data to deliver on business needs.",
    "Experience with production implementation change management processes.",
    "Experience with project management and software development life cycle/SDLC in an Agile environment.",
    "Strong analytical skills, including conceptual, requirements interpretation, solution creation and problem-solving abilities.",
    "Excellent collaboration and leadership skills and proven ability to adapt to challenges, coaching and mentoring.",
    "Ability to work in a global multi-site environment and working in a matrix environment, onshore/offshore IT mode.",
    "Ability to lead a team of diverse skill sets and interface with peripheral technical teams."
  ],
  "analysis": "The job responsibilities and skills listed focus primarily on data applications, data pipelines, and data systems development in an AWS Cloud environment. The responsibilities include coding, design leadership, data pipeline development, and mentoring other developers. The skills required include strong SQL competency, experience with Big Data technologies like Hive, Hadoop, HDFS, Tez, and Spark, and understanding of data modeling and data structure design. There is also a focus on project management, software development life cycle, and collaboration in a global environment.\n\nThere is no mention of Generative AI (GenAI) or language models (LLMs) in the responsibilities or skills. The job seems to be centered around data engineering and data systems development rather than working with AI models or language models. The technologies and skills mentioned are more aligned with data processing and integration rather than AI model development or deployment.",
  "is_genai_role": false
}