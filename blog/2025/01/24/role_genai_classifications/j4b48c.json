{
  "filename": "j4b48c",
  "responsibilities": [
    "Design, implement, and maintain scalable data lakehouse solutions in Microsoft Azure, ensuring data reliability, integrity, and security.",
    "Develop, optimize, and manage ETL/ELT pipelines for data integration, transformation, and storage using Azure Data Factory, DataBricks, and Delta Lake.",
    "Collaborate with cross-functional teams to define data architecture strategies that support business goals and analytics requirements.",
    "Monitor and improve data pipeline performance, addressing bottlenecks and ensuring efficient data flow and processing.",
    "Implement best practices for data governance, data quality, and metadata management in the data lakehouse environment.",
    "Manage and optimize large-scale data processing jobs using Apache Spark and SparkSQL within the DataBricks environment.",
    "Develop and maintain automated data workflows and processes, leveraging Infrastructure as Code (IaC) and Policy as Code (PaC) where applicable.",
    "Ensure seamless integration of data sources, enabling real-time analytics and business intelligence through streaming and batch processing.",
    "Conduct regular audits of data infrastructure to ensure compliance with security policies and regulatory requirements.",
    "Provide technical leadership and mentorship to data engineers and data scientists, fostering a culture of continuous learning and improvement."
  ],
  "qualifications": [
    "Familiarity with Infrastructure as Code (IaC) and Policy as Code (PaC).",
    "Hands-on exposure to logging and monitoring solutions.",
    "Familiarity with Microsoft Azure IaaS & PaaS solutions.",
    "Expertise to continuously deliver while valuing and maintaining a strong attention to detail.",
    "Experience with Agile software development organizations.",
    "Ability to quickly identify and drive to the optimal solution when presented with a series of constraints."
  ],
  "analysis": "The job responsibilities and skills listed focus primarily on data engineering and data architecture within the Microsoft Azure ecosystem. The responsibilities include designing and maintaining data lakehouse solutions, developing ETL/ELT pipelines, optimizing data processing jobs, and ensuring data governance and security. The skills required include familiarity with Infrastructure as Code, logging and monitoring solutions, and experience with Agile software development.\n\nThere is no mention of Generative AI (GenAI) or language models (LLMs) in the responsibilities or skills. The focus is on data integration, transformation, and processing using tools like Azure Data Factory, DataBricks, and Apache Spark. The job is centered around data management and analytics infrastructure rather than AI model development or deployment.\n\nTherefore, based on the provided information, this job does not involve working with Generative AI or language models.",
  "is_genai_role": false
}