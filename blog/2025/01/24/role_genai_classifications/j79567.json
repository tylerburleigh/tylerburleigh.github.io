{
  "filename": "j79567",
  "responsibilities": [
    "Train and deploy ML perception models",
    "Be involved in the full software development life cycle of perception ML tasks, from planning to maintenance",
    "Stay current with latest advancements in perception and robotics",
    "Collaborate with a cross-functional team of engineers to iterate and improve the perception capabilities",
    "Follow best practices for reproducible research and code development",
    "Represent and lead with Apptronik's core values: Curiosity, Humility, Integrity, Passion, Creativity"
  ],
  "qualifications": [
    "Experience in modern computer vision techniques",
    "Object detection, object pose estimation, semantic 2D and 3D scene understanding, bin picking",
    "Experience with different sensor modalities",
    "Strong Python & C++ programming skills, proficient in popular ML frameworks",
    "Experience working with large datasets",
    "Familiarity with robotics frameworks such as ROS / ROS 2",
    "Ability to independently research difficult open-ended problems and come to a working solution",
    "Solid understanding of software development lifecycle (SDLC) and agile methodologies",
    "Effective communication and collaboration skills to work effectively across teams and stakeholders",
    "(Preferred) Experience deploying perception systems on low SWaP devices",
    "(Preferred) Experience with multi-modal sensor fusion",
    "(Preferred) Prior experience working on robotic perception for manipulation, automated warehouse systems, or autonomous vehicles"
  ],
  "analysis": "The job responsibilities and skills listed are primarily focused on machine learning (ML) perception models, computer vision techniques, and robotics. The responsibilities include training and deploying ML perception models, collaborating with a cross-functional team to improve perception capabilities, and staying current with advancements in perception and robotics. The skills required include experience in computer vision techniques, object detection, semantic scene understanding, and working with different sensor modalities. There is also a focus on robotics frameworks, such as ROS, and deploying perception systems on low SWaP devices.\n\nThere is no mention of Generative AI (GenAI) or language models (LLMs) in the responsibilities or skills. The focus is on perception models, computer vision, and robotics, which are distinct areas from GenAI and LLMs. GenAI typically involves creating new content, such as text, images, or music, while LLMs are used for understanding and generating human language. The job does not involve these aspects.",
  "is_genai_role": false
}