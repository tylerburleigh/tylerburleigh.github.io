{
  "filename": "j49f93",
  "responsibilities": [
    "Develop and improve feature store tooling and services, and contribute to the ML infrastructure development",
    "Collaborate with ML practitioners to build streaming data ecosystem",
    "Develop low-latency services to enable and support event-driven pipelines",
    "Work on multi-faceted projects with engineers from diverse backgrounds, heterogenous skills and across teams",
    "Drive and maintain a culture of quality, innovation and experimentation",
    "Work in an Agile environment that focuses on collaboration and teamwork"
  ],
  "skills": [
    "Experience working in large scale, real-time distributed systems",
    "Experience building and deploying big data pipelines in production",
    "Experience with cloud technologies in AWS or GCP",
    "Experience with container systems such as Docker or Kubernetes",
    "Excellent communication and people engagement skills"
  ],
  "analysis": "The job responsibilities focus on developing and improving feature store tooling and services, collaborating with machine learning (ML) practitioners, building streaming data ecosystems, and developing low-latency services for event-driven pipelines. These tasks are related to ML infrastructure and data engineering rather than directly working with Generative AI or language models. The skills required include experience with large-scale, real-time distributed systems, big data pipelines, cloud technologies, and container systems, which are essential for handling data and ML infrastructure but do not specifically indicate work with GenAI or LLMs. There is no mention of tasks or skills directly related to developing, training, or deploying language models or generative AI systems.",
  "is_genai_role": false
}