{
  "responsibilities": [
    "Design and develop robust data architectures and data pipelines to support data ingestion, processing, storage, and retrieval.",
    "Evaluate and select appropriate technologies, frameworks, and tools to build scalable and reliable data infrastructure.",
    "Optimize data engineering systems and processes to handle large-scale data sets efficiently.",
    "Collaborate with cross-functional teams, such as data scientists, software engineers, and business stakeholders, to understand data requirements and deliver solutions that meet business needs.",
    "Effectively communicate complex technical concepts to non-technical stakeholders.",
    "Enforce data governance policies and practices to maintain data integrity, security, and compliance with relevant regulations.",
    "Collaborate with data governance and security teams to implement robust data protection mechanisms and access controls."
  ],
  "skills": [
    "Proficiency in data engineering tech stack; Snowflake / PostgreSQL / Python / SQL / GitLab / AWS / Airflow/ DBT and others.",
    "Proficiency in relational database platforms and cloud database platforms such as Snowflake, Redshift, or GCP.",
    "Strong in Python and/or another data-centric language.",
    "Thorough knowledge of data modeling, database design, data architecture principles, and data operations.",
    "Strong analytical and problem-solving abilities, with the capability to simplify complex issues into actionable plans.",
    "Experience with Apache Spark."
  ],
  "qualifications": [
    "A bachelor's degree in Computer Science, Data Science, Engineering, or a related field.",
    "8+ years of experience in data engineering and analytics technical strategy.",
    "Experience in the Fintech industry is advantageous."
  ]
}