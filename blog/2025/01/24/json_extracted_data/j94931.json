{
  "responsibilities": [
    "Design, build, and scale the infrastructure for data engineering, data science, and analytics efforts.",
    "Lay down industry standard data engineering practices and solutions.",
    "Bring in new tools and technologies when necessary.",
    "Scale current data infrastructure.",
    "Evangelize and drive new technology adoption."
  ],
  "skills": [
    "Strong infrastructure and data engineering skills.",
    "Strong programming skills in Python or a similar language.",
    "Experience deploying and managing open source frameworks such as Airflow, Kafka, Spark, Kubernetes, Terraform, Docker, Helm charts.",
    "Comfortable working with Spark/PySpark.",
    "Working knowledge of OLAP and OLTP databases like Clickhouse, Postgres.",
    "Experience with security, controls, and access management for data."
  ],
  "qualifications": [
    "3+ years of dedicated experience building data pipelines, and building and scaling data infrastructure.",
    "2+ years of experience working with cloud-based infrastructure, specifically AWS and Databricks.",
    "Proven track record of successfully building and scaling data infrastructure leveraged by growing companies.",
    "Bonus points for experience in ML operations."
  ]
}