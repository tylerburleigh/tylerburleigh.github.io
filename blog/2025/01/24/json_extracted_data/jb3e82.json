{
  "responsibilities": [
    "Build and operationalize complex data solutions, correct problems, apply transformations, and recommend data cleansing/quality solutions.",
    "Design complex data solutions.",
    "Perform analysis of complex sources to determine value and use and recommend data to include in analytical processes.",
    "Incorporate core data management competencies including data governance, data security, and data quality.",
    "Collaborate within and across teams to support delivery and educate end users on complex data products/analytic environment.",
    "Perform data and system analysis, assessment, and resolution for complex defects and incidents and correct as appropriate.",
    "Test data movement, transformation code, and data components.",
    "Perform other duties as assigned."
  ],
  "skills": [
    "Strong experience in AWS, Databricks workflow & Machine Learning, Ab Initio, Snowflake, SQL Server, Python, PySpark, SQL, Terraform, etc.",
    "Identify performance bottlenecks and optimize applications for efficiency and cost-effectiveness.",
    "Drive standards and best practices, resolving issues.",
    "Highly proficient use of tools, techniques, and manipulation including Cloud platforms, programming languages, and a full understanding of modern software engineering practices.",
    "Strong problem-solving skills to ensure systems are built with longevity and create innovative ways to resolve issues.",
    "Strong written and verbal communication skills with the ability to collaborate well with team members and business partners.",
    "Ability to lead team members and help create a safe environment for others to learn and grow as engineers."
  ],
  "qualifications": [
    "Bachelor’s Degree in STEM-related field or equivalent.",
    "Eight years of related experience.",
    "AWS/Databricks/Snowflake certifications recommended.",
    "Experience in machine learning workflows within Databricks, AWS SageMaker is a plus.",
    "Demonstrated track record of domain expertise including understanding technical concepts necessary and industry trends.",
    "Possess in-depth knowledge of immediate systems worked on and some knowledge of adjacent systems.",
    "Proven track record of self-motivation in identifying opportunities and tracking team efforts.",
    "Bachelor’s degree or equivalent training with data tools, techniques, and manipulation.",
    "Four years of data engineering or equivalent experience."
  ]
}