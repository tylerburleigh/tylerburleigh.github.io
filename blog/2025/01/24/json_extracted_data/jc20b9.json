{
  "responsibilities": [
    "Develop solutions to scale message queue and streaming infrastructure.",
    "Support data infrastructure including Kafka, Airflow, RabbitMQ, Trino, and GCP alternatives.",
    "Work with users to determine capacity and functionality requirements.",
    "Develop monitoring tools and maintain reliable operations.",
    "Partner with database teams for optimal configuration of applications.",
    "Collaborate on data migration tooling, change data capture analytics pipelines, and streaming solutions.",
    "Migrate infrastructure to the cloud using GCP."
  ],
  "skills": [
    "Experience with Kafka, Airflow, and GCP.",
    "Expertise in developing backend services and ETL streaming and message processing.",
    "Proficiency in writing automation scripts and libraries in the Data world.",
    "Proficiency in CI/CD tools such as Jenkins and GitLab."
  ],
  "qualifications": [
    "5+ years of experience in relevant fields.",
    "Desire to assume responsibility for infrastructure pieces and define strategies.",
    "Satisfaction in creating rock solid systems."
  ]
}