{
  "responsibilities": [
    "Design and create evaluation measures, harnesses, and datasets for measuring risks posed by frontier AI systems.",
    "Design and build harnesses to test AI agents for dangerous capabilities such as hacking or exploiting security vulnerabilities.",
    "Develop and run human-in-the-loop tests of AI capabilities to deceive, manipulate, blackmail, or engage in social engineering.",
    "Work with government agencies or other labs to collectively scope and design evaluations to measure and mitigate risks posed by advanced AI systems."
  ],
  "skills": [
    "Proficiency in frameworks like Pytorch, Jax, or Tensorflow.",
    "Ability to interpret research literature and quickly turn new ideas into prototypes.",
    "Strong written and verbal communication skills.",
    "Practical ML prototyping and debugging skills.",
    "Experience with open source LLM fine-tuning or bespoke LLM fine-tuning projects.",
    "Experience working with cloud technology stack (e.g., AWS or GCP) and developing machine learning models in a cloud environment."
  ],
  "qualifications": [
    "Commitment to promoting safe, secure, and trustworthy AI deployments.",
    "Practical experience conducting technical research collaboratively.",
    "A track record of published research in machine learning, particularly in generative AI.",
    "At least three years of experience addressing sophisticated ML problems in a research setting or product development."
  ]
}