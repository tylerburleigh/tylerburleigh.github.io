{
  "responsibilities": [
    "Design, build, and maintain scalable data pipelines while ensuring data reliability, accuracy, and integrity.",
    "Lead data ingestion, transformation, and warehousing initiatives to support business objectives.",
    "Design and implement data pipelines to collect, ingest, and transform data from various sources into a structured format.",
    "Collaborate with the team to monitor and maintain data quality standards, perform data validation, and resolve data quality issues.",
    "Design and maintain data warehousing solutions to store and manage large volumes of data efficiently.",
    "Work on automating routine data engineering tasks to improve efficiency and reliability.",
    "Develop and maintain lightweight data applications for ML interfaces, simple CRUD operations, and quick interactive analysis.",
    "Identify and implement optimizations to all parts of the data stack to improve data pipeline performance and reduce processing times.",
    "Create and maintain documentation for data pipelines, processes, and data flows.",
    "Collaborate with cross-functional teams including data analysts, data scientists, other engineering teams, and business stakeholders to understand data requirements and deliver data solutions.",
    "Stay up to date with industry best practices and emerging technologies in data engineering.",
    "Serve as an informal leader on the data engineering team, collaborating with other data engineers on solution designs, and help to continually raise the collective competency of the team by sharing learnings and mentoring team members in earlier stages of their careers.",
    "Interact effectively with leadership, team members, other engineering/technical teams, and business stakeholders to drive projects to effective and timely resolutions."
  ],
  "skills": [
    "Proficiency with SQL and Python in data engineering workflows.",
    "Proficiency in utilizing and managing data integration and ETL tools (e.g., Stitch/Talend, Airbyte, Fivetran, etc).",
    "Experience with data orchestration and workflow management tools (e.g., Dagster, Airflow).",
    "Applied knowledge of data warehousing concepts and technologies (e.g., Snowflake, AWS Redshift, Google BigQuery, etc).",
    "Experience in deployment of various data pipelines and components and ML-ops solutions within cloud computing platforms, particularly in AWS.",
    "Excellent problem-solving skills and attention to detail.",
    "Strong communication and teamwork skills, with a demonstrated competency for collaboration and mentoring.",
    "Ability to work in a fast-paced, collaborative environment.",
    "Aptitude for continuous improvement through learning and sharing, along with an ability to quickly and effectively adopt and adapt to new technologies and tools."
  ],
  "qualifications": [
    "Bachelor's degree in Computer Science, Information Technology, or a related field.",
    "5+ years of applicable experience with data engineering concepts and practice, over the full data lifecycle.",
    "Demonstrated proficiency with SQL and Python in data engineering workflows.",
    "Proficiency in utilizing and managing data integration and ETL tools (e.g., Stitch/Talend, Airbyte, Fivetran, etc).",
    "Experience with data orchestration and workflow management tools (e.g., Dagster, Airflow).",
    "Applied knowledge of data warehousing concepts and technologies (e.g., Snowflake, AWS Redshift, Google BigQuery, etc).",
    "Experience in deployment of various data pipelines and components and ML-ops solutions within cloud computing platforms, particularly in AWS.",
    "Excellent problem-solving skills and attention to detail.",
    "Strong communication and teamwork skills, with a demonstrated competency for collaboration and mentoring.",
    "Ability to work in a fast-paced, collaborative environment.",
    "Aptitude for continuous improvement through learning and sharing, along with an ability to quickly and effectively adopt and adapt to new technologies and tools.",
    "Nice to have: Masterâ€™s degree in Computer Science, Information Technology, or a related field.",
    "Nice to have: Understanding of and prior work with machine learning models.",
    "Nice to have: Familiarity and experience with data governance and security best practices."
  ]
}