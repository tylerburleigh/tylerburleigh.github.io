{
  "responsibilities": [
    "Propose and establish technical designs to meet business and technical requirements.",
    "Develop and maintain data engineering and ML solutions based on requirements and design specifications using appropriate tools and technologies.",
    "Create and optimize data pipelines / ETL pipelines for performance.",
    "Test and validate developed solutions to ensure they meet requirements.",
    "Coach other members of the data engineering team on workflows, technical topics, and pipeline management.",
    "Coach and manage junior Data and ML Engineers, providing guidance, mentorship, and support to foster their professional growth and ensure project success.",
    "Create design and development documentation based on standards for knowledge transfer, training, and maintenance.",
    "Work with business and product teams to understand requirements and translate them into technical needs.",
    "Adhere to and promote best practices and standards for code management, automated testing, and deployments.",
    "Leverage existing or create new standard data pipelines within Sanofi to bring value through business use cases.",
    "Develop automated tests for CI/CD pipelines.",
    "Gather and organize large and complex data assets, and perform relevant analysis.",
    "Conduct peer reviews for quality, consistency, and rigor for production-level solutions.",
    "Actively contribute to the Data Engineering community and define leading practices and frameworks.",
    "Communicate results and findings in a clear, structured manner to stakeholders.",
    "Stay up to date on the company’s standards, industry practices, and emerging technologies."
  ],
  "skills": [
    "Strong technical analysis and problem-solving skills related to data and technology solutions.",
    "Excellent written, verbal, and interpersonal skills with the ability to communicate ideas, concepts, and solutions to peers and leaders.",
    "Pragmatic and capable of solving complex issues with technical intuition and attention to detail.",
    "Service-oriented, flexible, and approachable team player.",
    "Proficient in SQL and relational database technologies/concepts.",
    "Working knowledge of scripting languages (Python, Shell scripting).",
    "Experience with cloud-based data platforms (Snowflake is a plus).",
    "Experience with job scheduling and orchestration tools (Airflow is a plus).",
    "Strong understanding of data structures and algorithms."
  ],
  "qualifications": [
    "Bachelor’s Degree or equivalent in Computer Science, Engineering, or a relevant field.",
    "6+ years of experience in data engineering, integration, data warehousing, business intelligence, business analytics, or a comparable role with relevant technologies and tools, such as Spark/Scala, Informatica/IICS/dbt.",
    "Experience working with cross-functional teams to solve complex data architecture and engineering problems.",
    "Demonstrated ability to quickly learn new data and software engineering technologies.",
    "Good understanding of agile/scrum development processes and concepts.",
    "Ability to work in a fast-paced, constantly evolving environment and manage multiple priorities.",
    "Experience working with data models and query tuning.",
    "Nice to have: Experience working in the life sciences/pharmaceutical industry is a plus.",
    "Familiarity with data ingestion through batch, near real-time, and streaming environments.",
    "Familiarity with data warehouse concepts and architectures (data mesh is a plus).",
    "Familiarity with Source Code Management Tools (GitHub is a plus)."
  ]
}