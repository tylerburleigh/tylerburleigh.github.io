{
  "responsibilities": [
    "Build next-generation AI & analytics framework developed on a group of core technologies.",
    "Utilize Generative AI techniques to create innovative solutions for business challenges.",
    "Leverage AWS AI services like Amazon Bedrock, SageMaker, Comprehend, Rekognition, Transcribe to accelerate AI development and deployment.",
    "Lead multi-functional teams in designing and implementing cloud-based data and AI solutions.",
    "Ensure data pipelines are scalable, secure, and repeatable.",
    "Utilize AWS data services like Amazon S3, Amazon Redshift, and Amazon DynamoDB to store, manage, and process large-scale datasets.",
    "Collaborate with stakeholders to understand business requirements and turn data into insights.",
    "Develop and maintain cloud infrastructure, including data lakes, warehouses, and analytics platforms.",
    "Implement data governance and security best practices.",
    "Contribute to a DevSecOps culture by adhering to standard methodologies for secure software development and deployment.",
    "Automate AI model development, testing, and deployment using CI/CD pipelines.",
    "Act as an inspiring leader, with an outstanding perspective, and promote the adoption of new software and technology across the company.",
    "Work on multiple projects as a technical team member driving business requirements end to end.",
    "Take end to end accountability of all data products and solutions.",
    "Conduct training bootcamps and cross-training workshops for internal collaborators and customers."
  ],
  "skills": [
    "Proficiency in programming languages such as Python, Java, or similar.",
    "Experience with data engineering concepts and tools.",
    "Understanding of data governance and security principles.",
    "Hands-on experience with DevSecOps and CI/CD practices.",
    "Excellent problem-solving and analytical skills.",
    "Ability to work independently and as part of a team.",
    "Familiarity with containerization technologies (e.g., Docker, Kubernetes).",
    "Experience with specific generative AI models like Llama, Sonnet, others from HuggingFace.",
    "Knowledge of deep learning frameworks such as TensorFlow or PyTorch.",
    "Contributions to open-source AI projects or communities."
  ],
  "qualifications": [
    "Bachelor's or Master's degree in Computer Science, Artificial Intelligence, Machine Learning, or equivalent work experience.",
    "Typically requires 5 or more years of experience.",
    "Proven experience in Generative AI, data engineering, AWS AI, and AWS data services.",
    "Must be a U.S. Citizen or a Green Card holder with the intent to become a U.S. Citizen.",
    "Certifications in AWS AI or machine learning (desired)."
  ]
}