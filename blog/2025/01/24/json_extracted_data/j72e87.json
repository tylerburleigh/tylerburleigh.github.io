{
  "responsibilities": [
    "Lead and architect migration of data environments with performance and reliability.",
    "Assess and understand the ETL jobs, workflows, BI tools, and reports.",
    "Address technical inquiries concerning customization, integration, enterprise architecture, and general feature/functionality of data products.",
    "Support an Agile software development lifecycle.",
    "Contribute to the growth of the Data Exploitation Practice."
  ],
  "skills": [
    "Experience in crafting database/data warehouse solutions in cloud environments (preferably AWS, alternatively Azure, GCP).",
    "Proficiency in Microsoft data stack and Python.",
    "Advanced working SQL knowledge and experience with relational databases, query authoring, and optimization.",
    "Familiarity with big data tools such as Hadoop, Spark, Kafka, etc.",
    "Experience with relational SQL and NoSQL databases, including Postgres and Cassandra.",
    "Knowledge of data pipeline and workflow management tools like Azkaban, Luigi, Airflow, etc.",
    "Experience with AWS cloud services such as EC2, EMR, RDS, Redshift (or Azure equivalents).",
    "Experience with data streaming systems like Storm, Spark-Streaming, etc.",
    "Proficiency in search tools such as Solr, Lucene, Elasticsearch.",
    "Experience with object-oriented/object function scripting languages like Python, Java, C++, Scala, etc.",
    "Experience with message queuing, stream processing, and highly scalable ‘big data’ data stores.",
    "Experience manipulating, processing, and extracting value from large, disconnected datasets.",
    "Experience manipulating structured and unstructured data for analysis.",
    "Experience constructing complex queries to analyze results using databases or in a data processing development environment.",
    "Experience with data modeling tools and processes.",
    "Experience architecting data systems (transactional and warehouses).",
    "Experience aggregating results and/or compiling information for reporting from multiple datasets.",
    "Experience working in an Agile environment.",
    "Experience supporting project teams of developers and data scientists who build web-based interfaces, dashboards, reports, and analytics/machine learning models."
  ],
  "qualifications": [
    "Ability to hold a position of public trust with the US government.",
    "2-4 years of experience working with MS SQL Server and SSIS to build ETL pipelines.",
    "2-4 years of industry experience coding commercial software and a passion for solving complex problems.",
    "2-4 years of direct experience in Data Engineering with experience in tools such as big data tools, relational SQL and NoSQL databases, data pipeline and workflow management tools, AWS cloud services, data streaming systems, search tools, and object-oriented/object function scripting languages."
  ]
}