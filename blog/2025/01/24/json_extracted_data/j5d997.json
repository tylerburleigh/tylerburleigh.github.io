{
  "responsibilities": [
    "Develop LLM applications to evaluate data quality and solve problems of synthetic data capabilities.",
    "Execute business solutions using LLM applications.",
    "Identify and exploit vulnerabilities in LLMs and other generative AI models.",
    "Develop training materials for red teaming and adversarial analysis.",
    "Conduct training sessions with operation staff.",
    "Create data creation and vulnerability testing scripts in Python/TypeScript.",
    "Collaborate with ML Engineers and software engineers for robust implementation and deployment.",
    "Analyze and visualize experimental prompt results.",
    "Develop and teach new prompt engineering methods to ML engineers and software engineering staff."
  ],
  "skills": [
    "Proficiency in writing Python or TypeScript for API-enabled scripts.",
    "Ability to conduct analysis of model performance using statistics and data visualization.",
    "Experience with frontier-scale LLMs (GPT, Claude, PaLM) for specific applications or implementations.",
    "Familiarity with LLM evaluation metrics (BLUE, ROUGE, MAUVE, etc.) and statistics.",
    "Strong written and verbal communication skills.",
    "Creative mindset for experimentation and internal R&D."
  ],
  "qualifications": [
    "B.S. or higher in a quantitative major or one related to language models (linguistics, philosophy, etc.).",
    "Demonstrated ability to have built an LLM-based application or hacked an LLM for a novel purpose.",
    "Previous experience with AI/LLM developmental work or red teaming is a strong plus.",
    "Academic work in language models, particularly on adversarial robustness, is a plus.",
    "Previous disclosures of vulnerabilities or security issues in LLMs or other AI models are a plus.",
    "Experience working with cloud technology stack (e.g., AWS or GCP) and developing machine learning models in a cloud environment is a plus."
  ]
}