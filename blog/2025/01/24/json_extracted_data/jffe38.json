{
  "responsibilities": [
    "Build machine learning models to detect unwanted or anomalous behaviors from users and API partners, and integrate them into our production system.",
    "Improve automated detection and enforcement systems as needed.",
    "Analyze user reports of inappropriate accounts and build machine learning models to detect similar instances proactively.",
    "Surface abuse patterns to research teams to harden models at the training stage."
  ],
  "skills": [
    "Proficiency in SQL, Python, and data analysis/data mining tools.",
    "Proficiency in building trust and safety AI/ML systems, such as behavioral classifiers or anomaly detection.",
    "Strong communication skills and ability to explain complex technical concepts to non-technical stakeholders.",
    "Experience with machine learning frameworks like Scikit-Learn, TensorFlow, or PyTorch.",
    "Experience with high-performance, large-scale ML systems.",
    "Experience with language modeling with transformers.",
    "Experience with reinforcement learning.",
    "Experience with large-scale ETL."
  ],
  "qualifications": [
    "4+ years of experience in a research/ML engineering or an applied research scientist position, preferably with a focus on trust and safety.",
    "Care about the societal impacts and long-term implications of work."
  ]
}