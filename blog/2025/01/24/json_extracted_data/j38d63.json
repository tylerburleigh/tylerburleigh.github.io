{
  "responsibilities": [
    "Lead the design and implementation of scalable and reliable MLOps pipelines.",
    "Oversee the migration and management of monorepos, ensuring efficient dependency management, security compliance, and streamlined workflows across Python projects.",
    "Implement robust monitoring frameworks to ensure system observability and swift reaction to issues.",
    "Drive continuous improvements in the data science platform, integrating tools like Sagemaker into the workflow.",
    "Collaborate with data scientists to instill best practices in coding, testing, and version control.",
    "Establish processes for better data lineage, documentation, and ownership across datasets.",
    "Develop and refine systems for data versioning, model management, and deployment strategies."
  ],
  "skills": [
    "Strong proficiency in Python, containerization, and orchestration tools.",
    "Experience with data versioning and model management tools.",
    "Ability to tackle complex problems related to system integration, data consistency, and infrastructure scaling.",
    "Excellent communication skills for collaboration with data scientists, product managers, and engineers.",
    "Strong focus on mentoring and knowledge sharing.",
    "Passion for staying up-to-date with the latest trends in MLOps, machine learning, and software engineering."
  ],
  "qualifications": [
    "3+ years in software engineering with a focus on MLOps, Python, and cloud-based environments (AWS preferred).",
    "Proven experience in building and maintaining CI/CD pipelines, managing monorepos, and scaling machine learning models in production.",
    "Experience with distributed systems and microservices architecture is a plus."
  ]
}