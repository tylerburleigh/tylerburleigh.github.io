{
  "responsibilities": [
    "Develop and maintain APIs using NVIDIA Triton Inference Server for scalable deployment of Large Language Models (LLM).",
    "Implement and optimize pre-processing and post-processing pipelines tailored for LLMs to improve accuracy and efficiency.",
    "Work with Retrieval-Augmented Generation (RAG) frameworks to enhance the modelâ€™s response generation capabilities.",
    "Collaborate with data scientists, software engineers, and product teams to integrate and deploy ML solutions into production.",
    "Troubleshoot and resolve issues related to model inference, performance, and scalability."
  ],
  "skills": [
    "Proficient in Python and relevant ML frameworks (e.g., PyTorch, TensorFlow).",
    "Strong problem-solving skills.",
    "Ability to work in a fast-paced environment."
  ],
  "qualifications": [
    "Proven experience with NVIDIA Triton Inference Server and its APIs.",
    "Strong understanding of pre-processing and post-processing techniques for LLMs.",
    "Familiarity with Retrieval-Augmented Generation (RAG) and other LLM mechanisms."
  ]
}