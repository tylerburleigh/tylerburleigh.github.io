{
  "responsibilities": [
    "Partnering with other solution architects, engineering, product, and business teams to understand their strategies and technical needs and help define high-value solutions.",
    "Dynamically engaging with developers, scientific researchers, and data scientists across a range of technical areas.",
    "Strategically partnering with lighthouse customers and industry-specific solution partners targeting NVIDIA's computing platform.",
    "Working closely with customers to help them adopt and build solutions using NVIDIA technology.",
    "Analyzing performance and power efficiency of deep learning inference workloads.",
    "Traveling to conferences and customers as required."
  ],
  "skills": [
    "Strong fundamentals in programming, optimizations, and software design, especially in Python.",
    "Strong problem-solving and debugging skills.",
    "Excellent knowledge of theory and practice of Large Language Models and Deep Learning inference.",
    "Excellent presentation, communication, and collaboration skills.",
    "Experience with NVIDIA GPUs and software libraries, such as NVIDIA NeMo Framework, NVIDIA Triton Inference Server, TensorRT, TensorRT-LLM.",
    "Excellent C/C++ programming skills, including debugging, profiling, code optimization, performance analysis, and test design.",
    "Familiarity with parallel programming and distributed computing platforms."
  ],
  "qualifications": [
    "BS, MS, or PhD in Computer Science, Electrical/Computer Engineering, Physics, Mathematics, other Engineering or related fields (or equivalent experience).",
    "5+ years of hands-on experience with Deep Learning frameworks such as PyTorch and TensorFlow.",
    "Desire to be involved in multiple diverse and creative projects.",
    "Prior experience with DL training at scale, deploying or optimizing DL inference in production."
  ]
}