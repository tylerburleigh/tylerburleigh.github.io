{
  "responsibilities": [
    "Unlock the full potential of vast amounts of real-time and relational data.",
    "Provide the business with insights and customers with personalized experiences.",
    "Collaborate with engineering teams to build online applications and land necessary data for feature engineering.",
    "Work with Data Scientists and Analysts to productionize, analyze, and validate AI-powered insights.",
    "Organize, model, and present data as a coherent product for stakeholders.",
    "Offer a common information framework for intelligent reactions to market and field events."
  ],
  "skills": [
    "Scalable multi-layer serving and feature processing architectures for ML models.",
    "Proficiency with business intelligence tools (e.g., Tableau).",
    "Knowledge of data security and privacy (e.g., GDPR, CPP).",
    "Understanding of data governance and data testing frameworks.",
    "Experience with continuous integration and delivery of production data products.",
    "Ability to share findings in easy-to-consume formats, such as dashboards or data modeling.",
    "Solid understanding of algorithms, data structures, and computational complexity.",
    "Experience working in a cloud environment such as AWS, GCP, Azure.",
    "Experience with Databricks and their unity catalog is a plus.",
    "Building data pipelines and working with large-scale datasets for production-level ML infrastructure."
  ],
  "qualifications": [
    "2+ years of relevant experience developing code in one or more core programming languages (Python, Java, etc.).",
    "1+ years of experience designing and building various software architecture.",
    "Deep understanding and knowledge of data structures and software engineering principles.",
    "1+ years of experience working within data engineering teams and contributing to production ML initiatives.",
    "Experience with one or more relevant tools (Flink, Spark, Sqoop, Flume, Kafka, Amazon Kinesis)."
  ]
}