{
  "responsibilities": [
    "Build and maintain data lake and big data pipelines/services.",
    "Facilitate the movement of billions of messages each day.",
    "Work with business stakeholders and platform/engineering teams to enable growth and retention strategies.",
    "Help stakeholder teams ingest data faster into the data lake.",
    "Improve data pipelines for efficiency.",
    "Develop ideas for self-serve data engineering within the company.",
    "Build micro-services and architect/design self-serve capabilities at scale.",
    "Identify ways to make data usable and improve user experience."
  ],
  "skills": [
    "Strong programming skills in Python, Java, or Scala.",
    "Experience writing SQL and structuring data.",
    "Knowledge of data storage practices and data modeling.",
    "Experience with data warehousing concepts.",
    "Experience building data pipelines, platforms, micro-services, and REST APIs.",
    "Familiarity with Spark, Hive, Airflow, and other streaming technologies.",
    "Understanding of modern software development practices (Agile, TDD, CICD).",
    "Strong focus on data quality and experience with tools/frameworks for detecting data issues.",
    "Experience working on Amazon Web Services (EMR, Kinesis, RDS, S3, SQS).",
    "Open-mindedness and willingness to try unconventional solutions."
  ],
  "qualifications": [
    "BS in Computer Science or equivalent experience.",
    "At least 5+ years of professional experience as a Sr. Software Engineer or Sr. Data Engineer.",
    "Experience in managing and orchestrating a multi-petabyte scale data lake.",
    "Ability to transform vague requirements into solid solutions.",
    "Motivation to solve challenging problems with creativity and coding skills.",
    "Experience building self-service tooling and platforms (preferred).",
    "Experience with Kappa architecture platforms (preferred).",
    "Experience with Databricks and their APIs (preferred).",
    "Contribution to open source projects (preferred)."
  ]
}