{
  "responsibilities": [
    "Design, iterate, and build ML models to detect unwanted or anomalous behaviors from both users and LLM models",
    "Work with T&S ML engineers to review and iterate experiment ideations",
    "Co-author the experiment success criteria and production deployment roadmaps",
    "Partner with T&S Policy and Enforcement cross-functional teams to understand emerging and sustained abuse patterns from user prompts and behaviors",
    "Incorporate insights into T&S research datasets",
    "Surface abuse patterns to sibling research teams in the company",
    "Collaborate to harden Anthropicâ€™s LLMs at the pre/post training stages",
    "Stay current with state-of-the-art research in AI and machine learning",
    "Propose ways to apply advancements to T&S systems"
  ],
  "skills": [
    "Significant Python programming experience",
    "Machine learning experience",
    "Proficiency in building trustworthy and safe AI technology",
    "Strong communication skills",
    "Ability to explain complex technical concepts to non-technical stakeholders"
  ],
  "qualifications": [
    "4+ years of experience in a research engineering or an applied research scientist position, preferably with a focus on trust and safety",
    "Experience fine-tuning large language models with supervised learning or reinforcement learning (strong candidates)",
    "Experience with machine learning frameworks like Scikit-Learn, Tensorflow, or Pytorch (strong candidates)",
    "Experience authoring research papers in machine learning, NLP, or AI alignment or similar industry experience (strong candidates)",
    "Developed evaluations for language models (strong candidates)"
  ]
}