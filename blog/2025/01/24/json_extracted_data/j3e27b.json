{
  "responsibilities": [
    "Design, build, and launch data pipelines to move data across systems and build the next generation of data tools that generate business insights for a product.",
    "Analyze user needs and software requirements to determine workability and to offer support for end users on data usage.",
    "Design, architect, and develop software and data solutions that help product and business teams make data-driven decisions.",
    "Rethink and influence strategy and roadmap for building efficient data solutions and scalable data warehouse plans.",
    "Design, develop, test, and launch new data models and processes into production, and provide support.",
    "Leverage homegrown extract, transform, and load (ETL) framework as well as off-the-shelf ETL tools, as appropriate.",
    "Interface closely with data infrastructure, product, and engineering teams to build and extend cross platform ETL and reports generation framework.",
    "Identify data infrastructure issues and drive to resolution."
  ],
  "skills": [
    "Writing SQL statements",
    "Data warehousing architecture and plans",
    "Dimensional data modeling",
    "Schema Design",
    "Map Reduce",
    "MPP System",
    "Hadoop",
    "Hive",
    "Data Visualization",
    "Database System",
    "Scala",
    "R",
    "Data Analysis",
    "Machine Learning"
  ],
  "qualifications": [
    "Masterâ€™s degree in Data Analytics Engineering, Computer Science, Engineering, Statistics, Mathematics, Physics, or a related field.",
    "Completion of a university-level course, research project, thesis, or internship involving SQL, data warehousing, dimensional data modeling, schema design, Map Reduce, MPP System, Hadoop, Hive, data visualization, database systems, Scala, R, data analysis, and machine learning."
  ]
}