{
  "responsibilities": [
    "Design, develop, and optimize data pipelines to process large volumes of structured and unstructured data from various sources.",
    "Build and maintain data models using dimensional data modeling techniques.",
    "Create insightful reports and dashboards to support business performance analysis.",
    "Collaborate with cross-functional teams to gather business requirements and translate them into technical solutions.",
    "Support data architecture transformation efforts.",
    "Troubleshoot and resolve data issues in a timely manner.",
    "Optimize query performance and implement best practices.",
    "Partner with data scientists and analysts to support their data needs.",
    "Drive continuous improvement of data processes through automation and innovation.",
    "Take ownership of projects, ensuring successful delivery from initiation to completion."
  ],
  "skills": [
    "Strong background in Python and SQL.",
    "Experience with tools like Databricks, Airflow, and DBT.",
    "Expertise in cloud analytics databases like Redshift.",
    "Excellent communication and collaboration skills.",
    "Ability to work independently and as part of a team in a dynamic environment."
  ],
  "qualifications": [
    "4+ years of experience in data engineering.",
    "Expertise in SQL.",
    "Expertise in Databricks.",
    "Experience with Python and DBT.",
    "Experience having done data architecture transformations using layered architecture patterns in Databricks.",
    "Experience with compliance standards such as SOC2."
  ]
}