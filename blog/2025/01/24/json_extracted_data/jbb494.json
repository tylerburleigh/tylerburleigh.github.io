{
  "responsibilities": [
    "Design and implement robust data pipelines (batch and streaming) to ingest and process healthcare data from diverse EHR systems and data sources.",
    "Apply medallion architecture principles to develop scalable bronze, silver, and gold layers for advanced analytics and machine learning.",
    "Build and manage event-driven architectures with tools like Kafka or Kinesis for real-time data processing.",
    "Collaborate with healthcare IT teams and third-party vendors to integrate, normalize, and secure data from EHRs, HL7, and FHIR standards.",
    "Optimize data pipeline performance for throughput, latency, and cost-effectiveness.",
    "Ensure compliance with HIPAA, HITECH, and other regulations by implementing strong encryption, access controls, and patient privacy measures.",
    "Partner with data scientists, analysts, and developers to design data models and interfaces.",
    "Guide and mentor junior engineers in data engineering, cloud architecture, containerization, and orchestration tools."
  ],
  "skills": [
    "Proficiency in SQL and Python.",
    "Experience with frameworks such as Apache Spark, Databricks, or Hadoop.",
    "Hands-on experience with event-driven systems like Kafka or Kinesis.",
    "Expertise in medallion architecture for data transformations.",
    "Strong knowledge of ACID transaction principles.",
    "Familiarity with cloud platforms (AWS, Azure, or GCP) and orchestration tools such as Airflow or Step Functions.",
    "Strong problem-solving skills and attention to detail.",
    "Excellent communication abilities."
  ],
  "qualifications": [
    "5+ years of experience in data engineering or software engineering, with a focus on Big Data or real-time pipelines.",
    "Understanding of EHR workflows, HL7, FHIR standards, and integration with major vendors like EPIC, Cerner, or Meditech.",
    "Bachelor’s or Master’s degree in Computer Science, Data Engineering, Information Systems, or a related technical field."
  ]
}