{
  "responsibilities": [
    "Understand structure and rules of enterprise data to translate into database design.",
    "Develop and maintain ETL Data Flows using Azure Synapse.",
    "Develop and maintain SparkSQL, PySpark code within notebooks in Azure Synapse workspace.",
    "Develop and maintain Physical and Logical data Marts in Azure Synapse and SQL Server.",
    "Maintain Data Dictionary, Data Mapping and Design Documents.",
    "Work on Version control tools like Azure DevOps.",
    "Establish best practices for a growing team.",
    "Work and collaborate with Power BI and AI Automation resources.",
    "Collaborate with various Business Application Teams to understand the Source Data.",
    "Work in Agile framework/methodology."
  ],
  "skills": [
    "Proficient in PySpark, SparkSQL, Python, SQL.",
    "Experience with Data Lakes, Data warehousing, Data Mart concepts and Cloud Technologies.",
    "Excellent grasp of Data Modeling & Data Transformation concepts.",
    "Familiarity working with programming languages like R, and Java.",
    "Exceptional problem-solving and communication skills.",
    "Team Player, Reliable, flexible and dedicated."
  ],
  "qualifications": [
    "Min 2+ years of working in Azure Data Engineering projects.",
    "Experience in Azure Synapse, Data Factory, Data Lake, SQL Data Warehouse.",
    "Bachelorâ€™s degree in a related IT field.",
    "Proficiency in English; French is a plus.",
    "Nice to have Insurance Domain experience, e.g., Commercial insurance."
  ]
}