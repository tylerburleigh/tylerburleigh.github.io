{
  "responsibilities": [
    "Architecting, designing, and implementing advanced analytics capabilities.",
    "Dealing with large and complex data sets.",
    "Building self-service dashboards.",
    "Using visualization tools to generate insights.",
    "Creating and optimizing complex data processing and data transformation pipelines.",
    "Building processes supporting data transformation, data structures, metadata, dependency, and workload management.",
    "Supporting and working with cross-functional teams in a dynamic environment."
  ],
  "skills": [
    "Broad skills in database design.",
    "Experience with Python, SQL, and PySpark.",
    "Experience with Snowflake Cloud Datawarehouse and DBT tool.",
    "Advanced working SQL knowledge.",
    "Understanding of Datawarehouse (DWH) systems and migration to data lakes/Snowflake.",
    "Understanding of ELT and ETL patterns.",
    "Strong analytic skills related to working with unstructured datasets."
  ],
  "qualifications": [
    "8+ years of overall industry experience specifically in data engineering.",
    "5+ years of experience building and deploying large-scale data processing pipelines in a production environment."
  ]
}