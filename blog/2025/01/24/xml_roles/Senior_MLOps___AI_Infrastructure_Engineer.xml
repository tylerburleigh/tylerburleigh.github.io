
Identify the most common Responsibilities and Skills listed in the jobs below, returning a bulleted list in the format

# Responsibilities
- [responsibility]: [responsibility description]
- [responsibility]: [responsibility description]
...
# Skills
- [skill]: [skill description]
- [skill]: [skill description]
...
<Job>
<Responsibilities>['Provide continuous proactive and reactive engineering support for business partners using AI products, ensuring high satisfaction.', 'Apply AI and machine learning techniques to build and launch generative AI solutions using Meta’s Llama and other Large Language Models (LLM).', 'Develop and maintain performance monitoring systems for infrastructure and operations to ensure high availability of partner integrations.', 'Develop and troubleshoot large-scale distributed systems for business AI infrastructure and partner-specific integrations.', 'Analyze complex datasets for distributed systems to troubleshoot and improve systems.', 'Provide 24/7 on-call support coverage via rotation schedule, including weekends.', 'Work with Platform and Infrastructure teams to investigate and assess reported issues, agreeing on fixes for continuous improvements.', 'Proactively analyze information to identify trends/opportunities and recommend tactical improvements.', 'Deliver constructive feedback to peers to strengthen relationships and advance projects.', 'Create clear and concise documentation to communicate complex AI concepts to technical and non-technical stakeholders.', 'Evaluate priorities and project direction, identifying where to pause, remove roadblocks, or reprioritize resources.']</Responsibilities>
<Skills>['Proficiency in AI and machine learning techniques.', 'Experience with large-scale distributed systems.', 'Ability to analyze complex datasets.', 'Strong troubleshooting skills.', 'Experience with the full web stack, REST API, Python, PHP/Hack, JavaScript/React development.', 'Debugging and bug management support skills.', 'Knowledge of fine-tuning and optimizations of PyTorch models and LLMs.', 'Ability to communicate with technical and business audiences.', 'Technical documentation creation skills.']</Skills>
</Job>
<Job>
<Responsibilities>['Build and own the infrastructure and tools required for processing and storing data from a wide variety of data sources.', 'Design, develop, and optimize data pipelines, architectures, and data sets.', 'Collaborate with Data Engineers, Data Scientists, and other customers to understand complex data requirements.', 'Assist data users in defining requirements and refining existing processes.', 'Integrate new tools and solutions to empower the organization’s data consumers.', 'Implement data monitoring and alerting solutions to identify and address data issues.', 'Implement systems to monitor the performance of deployed AI models.', 'Design, develop, and implement AI solutions using GenAI, LLMs, and RAG methodologies.', 'Engineer prompts for AI models to improve their accuracy and utility.', 'Conduct comprehensive testing and validation of AI models.', 'Collaborate with data scientists, software developers, and other customers to integrate AI models into existing systems.', 'Maintain and optimize existing AI systems.', 'Stay updated with the latest advancements in AI and related technologies.', 'Initialize and manage cloud platforms with Azure.', 'Develop, maintain, and test data pipelines, application frameworks, and infrastructure for data generation.', 'Employ Azure Functions to deploy scalable cloud-based solutions.', 'Implement event-based architecture for real-time data processing and integration.', 'Build, code, test, and maintain high-quality software.', 'Translate user requirements into software requirements.', 'Develop and maintain applications using Python.', 'Use the Microsoft Power Platform to create custom business applications and workflows.', 'Participate in Agile sprints and ceremonies.', 'Work closely with information architects and data scientists.', 'Participate in functional demos using new technologies.', 'Collaborate with team members, participate in code reviews, and share skills and methods.', 'Stay abreast of developments in technical subject areas and experiment with emerging technologies.']</Responsibilities>
<Skills>['Experience maintaining and extending Infrastructure as Code (IaC) modules.', 'Ability to develop IaC scripts and modules for cloud infrastructure.', 'Ability to integrate IaC scripts with DevOps and Build pipelines.', 'Ability to implement CI/CD pipelines for IaC deployments.', 'Experience configuring RBAC and access controls via automation or CLI.', 'Experience in requirements, design, and solution discussions for application, architecture, networking, and infrastructure.', 'Proficiency in designing, developing, and implementing AI solutions.', 'Ability to engineer prompts for AI models.', 'Skills in testing and validating AI models.', 'Experience in collaborating with data scientists and software developers.', 'Proficiency in maintaining and optimizing AI systems.', 'Knowledge of cloud platform management, particularly with Azure.', 'Skills in developing, maintaining, and testing data pipelines and application frameworks.', 'Proficiency in using Azure Functions for scalable solutions.', 'Ability to implement event-based architecture.', 'Software development skills, particularly in Python.', 'Experience with the Microsoft Power Platform.', 'Participation in Agile methodologies.', 'Collaboration and communication skills.', 'Continuous learning and experimentation with emerging technologies.']</Skills>
</Job>
<Job>
<Responsibilities>['Deploy and optimize large generative models (e.g., diffusion, transformer-based) for real-time or batch inference.', 'Build and maintain end-to-end ML pipelines, from data ingestion to model serving in production environments.', 'Improve model performance through techniques like quantization, pruning, or distributed model inference.', 'Collaborate closely with cross-functional teams (infrastructure, product, research) to integrate advanced ML features into the video creation platform.', 'Implement MLOps best practices, including monitoring, logging, and robust CI/CD workflows for ML.']</Responsibilities>
<Skills>['Strong software engineering skills in Python (or similar).', 'Experience in cloud environments (AWS, GCP, or Azure).', 'Expertise in deep learning frameworks (e.g., PyTorch, TensorFlow).', 'Focus on inference optimization and high-throughput serving.', 'Familiarity with distributed training methods and large-scale data processing pipelines.']</Skills>
</Job>
<Job>
<Responsibilities>['Provide technical direction for the design and development of AI pipelines, ensuring scalability, robustness, and extensibility.', 'Serve as a mentor and guide for engineers on the AI Platform team, fostering growth and technical excellence.', 'Identify and drive high-impact projects aligned with business objectives and product needs.', 'Architect, design, and maintain AI pipelines for labeling, embeddings, training, and deploying models into production.', 'Lead the development and optimization of MLFlow pipelines for deployment.', 'Build and deploy foundational models that serve as the backbone for SnorkelFlow’s core product capabilities.', 'Partner with the Compute Platform team to ensure seamless integration with orchestration tools and infrastructure.', 'Develop and deploy LLM-based systems for production workflows, focusing on efficiency, scalability, and reproducibility.', 'Create AI training framework pipelines that will allow LLM usage in applications, including fine-tuning, pruning, distillation, and foundational model training.', 'Integrate APIs from providers such as OpenAI, Anthropic, and Gemini into SnorkelFlow’s pipelines.', 'Oversee the integration of backend services for managing LLM calls and API interactions.', 'Collaborate with the Data Platform team to define data requirements and ensure smooth interoperability.', 'Work with the Application team to design and implement APIs that power application workflows.', 'Establish observability standards for AI pipelines, including tools and dashboards for monitoring model performance and debugging.', 'Define key metrics for system health and optimization.', 'Act as a thought leader, collaborating with Data Platform, Compute Platform, Application, Product and other internal teams to deliver cohesive, scalable solutions.', 'Partner with stakeholders to translate product goals into technical roadmaps.']</Responsibilities>
<Skills>['Expertise in Python and deep learning frameworks such as PyTorch.', 'Proficiency with CI/CD pipelines for machine learning workflows.', 'Deep understanding of LLM architectures, fine-tuning, and deployment methodologies.', 'Strong communication skills, with an emphasis on scalable and reliable system design.', 'Familiarity with libraries such as Hugging Face Transformers, spaCy, scikit-learn, or XGBoost.', 'Knowledge of MLOps tools and practices, such as MLflow, Kubernetes, or Ray.', 'Experience building APIs or SDKs for AI services.']</Skills>
</Job>
<Job>
<Responsibilities>['Build and maintain core enterprise-wide AI infrastructure, integrating third-party AI models and tools.', 'Lead end-to-end delivery of AI solutions, from requirements gathering to production in collaboration with cross-functional partners.', 'Mentor colleagues to strengthen AI fluency, foster innovation, and influence roadmaps.', 'Act as a key contributor to AI strategy, identifying opportunities for impactful applications and enabling their delivery.', 'Ensure compliance with all applicable laws and regulations.', 'Perform other duties as assigned.']</Responsibilities>
<Skills>['Proficiency in Python and statistical fundamentals (e.g., bias-variance trade-offs, probability distributions).', 'Familiarity with widely used AI frameworks and tools (e.g., LangChain, LlamaIndex) and prototyping libraries (e.g., Streamlit, Replit, Tesseract).', 'Experience or an interest in prototyping full-stack applications.', 'Knowledge of containerization and deployment tools (e.g., Docker, Kubernetes) or full-stack development (e.g., React, Golang).', 'Experimental mindset: comfort with testing hypotheses and iterating on failures.']</Skills>
</Job>
<Job>
<Responsibilities>['Ensure that systems which power ChatGPT training and development run smoothly.', 'Dive into large ML codebases to understand and debug systems issues.', 'Work with researchers to build tools for data management, model configuration, evaluation, and more.', 'Create reusable Python libraries with great abstractions usable across ML projects.', 'Profile large model reinforcement learning training and identify and address bottlenecks.', 'Identify experiment failures in a new research cluster.', 'Redesign data pipelines to handle diverse multimodal data.', 'Build front-end evaluation tooling for use across the company.']</Responsibilities>
<Skills>['Experience working in complex technical environments.', 'Experience debugging ML systems.', 'Experience with reinforcement learning and/or transformers.', 'Proficiency in Python.', 'Experience with Kubernetes / distributed infrastructure.', 'Experience with GPUs.', 'Experience with one or more large-scale data systems such as Beam or Spark.']</Skills>
</Job>
<Job>
<Responsibilities>['Address end-to-end production challenges related to the AgentForce AI platform.', 'Lead the triaging of production issues for critical projects within the Generative AI platform.', 'Implement automated solutions to enhance reliability.', 'Maintain comprehensive documentation of production incidents.', 'Collaborate closely with AgentForce AI, product, and platform teams.', 'Establish the reliability process and collaborate closely with lead engineers.', 'Investigate alerts and customer-reported issues, analyze the end-to-end stack, identify root causes, and generate detailed reports.', 'Escalate issues to relevant engineering contacts and work to resolve them when necessary.', 'Lead and shape the production triage process for AgentForce, focusing on service, infrastructure deployment, configuration, performance, and latency issues.', 'Collaborate with cross-functional teams and external partners to ensure scalable and reliable services.', 'Maintain comprehensive documentation of production issues, workflows, and areas for improvement.', 'Understand and support capacity modeling and forecasting for AgentForce services in production.', 'Drive the scaling of Large Language Models (LLMs) and associated services in production.', 'Create and maintain playbooks and detailed knowledge articles for future analysis and troubleshooting.', 'Automate manual processes to maintain high availability and repeatability of production systems.', 'Utilize availability and trust dashboards, adjust SLOs and SLIs based on production feedback.', 'Identify automation gaps in production and compare established critical user journey (CUJ) benchmarks for reliability and trustworthiness.', 'Establish strong partnerships with Customer Support Groups (CSG) team to streamline escalations and minimize disruptions.', 'Be part of the 24x7 on-call support and multi-GEO coverage to maintain service reliability during peak periods.', 'Collaborate with business and engineering stakeholders for operational excellence, processes, and SLAs.', 'Drive improvements based on key metrics, KPIs, and customer feedback.']</Responsibilities>
<Skills>['Expertise in diagnosing and triaging performance and scalability issues across diverse systems and vendors.', 'Strong knowledge of feature provisioning, user permissions, and CRM licensing requirements.', 'Proficiency in scripting languages (Python, Shell, Golang).', 'Knowledge of AI model deployment and scaling.', 'Experience in DevOps or data center management roles with expertise in Linux system engineering.', 'Strong knowledge of cloud services (AWS preferred), container technologies (Docker, Kubernetes), and CI/CD tools (Jenkins, GitLab).', 'Experience in leading large-scale AI applications and services, including monitoring and diagnostic techniques.', 'Expertise in deploying and leading LLMs and technologies like Retrieval-Augmented Generation (RAG).', 'Background in monitoring tools such as Splunk, Prometheus, Grafana, and ELK stack.', 'Knowledge of Java profiler (e.g., Java Flight Recorder), open telemetry.', 'Knowledge of TCP/IP networking protocols and infrastructure services in IaaS environments.', 'Familiarity with MLOps tools and practices for supporting the machine learning lifecycle.']</Skills>
</Job>
<Job>
<Responsibilities>['Design and implement robust evaluation infrastructure to measure model capabilities and risks across multiple domains', 'Lead technical projects to build and scale evaluation systems that could become industry standards', 'Collaborate with domain experts to translate their insights into concrete evaluation frameworks', 'Build sandboxed testing environments and automated pipelines for continuous model assessment', 'Work closely with researchers to rapidly prototype and iterate on new evaluation approaches', "Partner with cross-functional teams to advance Anthropic's safety mission", 'Contribute to Capability Reports that inform critical deployment decisions']</Responsibilities>
<Skills>['Strong software engineering skills with extensive Python experience', 'Ability to write clean, well-structured code that others can build upon', 'Experience working with distributed systems', 'Ability to define technical specifications and execute towards them', 'Self-starter who thrives in fast-paced, collaborative environments', 'Ability to balance urgency with careful, methodical implementation']</Skills>
</Job>
<Job>
<Responsibilities>['Design, develop, and maintain the Cloud infrastructure for AI/ML-enabled applications using infrastructure-as-code software tools.', 'Setup and maintain CI/CD pipelines and other developer tools.', "Ensure Cloud infrastructure's security, availability, and reliability via monitoring, observability, and alerting.", 'Work closely with Software Engineers to optimize performance and scalability and deliver highly available customer-facing products.', 'Create infrastructure code and reference architectures for orchestrating environment creation, housekeeping, and deployment throughout the application and product life cycles.', 'Support pre-production and production environments, diagnose and troubleshoot problems in code and in the environment, conduct root cause analyses and incident response.', 'Act as a mentor for other members of the team.', 'Stay up to date with the latest developments in cloud technologies and operational tools.']</Responsibilities>
<Skills>['Strong foundation of internet engineering fundamentals.', 'Strong background in applying DevOps methodologies.', 'Deep understanding of cloud technologies.', 'Experience with infrastructure-as-code or configuration management tools (e.g., Terraform, Puppet, Ansible, Salt, Chef).', 'Deep knowledge of containerization and packaging using technologies such as Docker, Podman, or CRI-O, Helm, or Kustomize.', 'Expert Unix/Linux and networking skills.', 'Proficient in system integration.', 'Deep understanding of web app hosting and micro-service architecture.', 'Proficient in SRE activities.', 'Proficient in infrastructure automation and deployment processes.', 'Experience hosting and scaling data infrastructure and integrating multi-cloud environments.', 'Working experience with ML-OPS/LLM-OPS preferred.', 'Value culture and good relationship-building with cross-functional teams.']</Skills>
</Job>
<Job>
<Responsibilities>['Operationalize, deploy, manage, trouble-shoot, scale and evolve the GenAI based systems', 'Instrument the AI systems with observability and controllability', 'Monitor AI systems for performance and security', 'Analyze, fine-tune and optimize the performance of the AI systems', 'Manage, measure and improve the behavior of the AI systems', 'Automate AI deployments and operations', 'Ensure the security of AI systems by implementing standard methodologies and conducting regular security audits']</Responsibilities>
<Skills>['Proficiency with AI infrastructure components, automation tools, and scripting languages such as Python, Bash', 'Familiarity with one or more of the AI frameworks and tools such as AWS Bedrock and Sagemaker, HuggingFace TGI, TensorFlow, PyTorch, and Langchain/Llamaindex', 'Familiarity with open source LLM models, such as Llama, Mistral', 'Strong analytical and problem-solving skills', 'Superb communication and documentation skills', 'Knowledge of AI design patterns', 'Good interpersonal, negotiation, and influencing skills', 'DevOps experience is a big plus', 'Demonstrated expertise in the areas of accountability, critical thinking and emotional intelligence', 'Demonstrated effective change champion and ability to work effectively with others (including remote employees) to deliver complex, critical strategic IT initiatives']</Skills>
</Job>
<Job>
<Responsibilities>['Collaborate with a team of AI engineers to design, build, and enhance front-end tooling/products for LLM data collection using Angular and similar frameworks.', 'Focus on backend data engineering tasks involving curating, developing, and processing data samples essential for LLM training processes.', 'Implement robust backend services and workflows for efficient management of LLM training data collection and processing.', 'Oversee application deployment tasks utilizing Azure Kubernetes Service (AKS), Azure Machine Learning, and CI/CD pipelines with Jenkins.', 'Maintain high-quality code adhering to business objectives, software quality standards, and development guidelines.', 'Actively participate in code reviews and team discussions.', 'Adapt to shifting priorities and challenges while maintaining focus on delivering results within established deadlines.']</Responsibilities>
<Skills>['Expertise in Angular or similar front-end frameworks.', 'Strong foundation in back-end development, particularly in data engineering.', 'Experience in building AI products and systems.', 'Knowledge of developing data sets for LLMs.', 'Proficiency in deployment processes in Azure environments, including Azure Kubernetes Service (AKS) and Azure ML.', 'Knowledge of CI/CD practices using Jenkins.', 'High proficiency in Docker for containerization.', 'Strong Python programming skills for backend development.', 'Multi-disciplinary approach to problem solving.', 'Excellent interpersonal and communication skills.']</Skills>
</Job>
<Job>
<Responsibilities>['Design, implement, and maintain robust infrastructure to support the development and deployment of generative AI and machine learning tools for the AI Accelerator.', 'Evaluate and compare different technical approaches, presenting their trade-offs to guide architectural decisions for AI projects.', 'Design and develop tools, components, and processes to support public cloud service intake, CI/CD, and security.', 'Lead proof of concept efforts for candidate architectures, products, and tools.', 'Adopt and communicate new concepts, ideas, techniques, best practices, and technology assistance at all organizational levels.', 'Assist in the remediation of application stability and performance.', 'Work to establish required cloud infrastructures and frameworks.']</Responsibilities>
<Skills>['Extensive experience with Google Cloud Platform (GCP) or another cloud provider, including application hosting, BigQuery, and serverless computing.', 'Knowledge of cloud security principles and frameworks.', 'Hands-on experience with modern DevOps concepts and workflows.', 'Strong backend development expertise, particularly in building and integrating REST APIs with frameworks like FastAPI.', 'Practical experience in Python development, especially in data-driven environments and for building scalable applications.', 'Experience with cloud-native technologies such as Docker, Kubernetes, and Terraform for container orchestration and infrastructure as code.', 'Familiarity with CI/CD best practices, using tools such as GitHub Actions and Cloud Build.', 'Solid understanding of monitoring, alerting, and logging solutions within cloud-native ecosystems.', 'Confidence in communicating complex technical ideas to diverse audiences.', 'Development experience with Python and/or JavaScript/Typescript.']</Skills>
</Job>
<Job>
<Responsibilities>['Shape the architecture and scalability of the next-generation AI inference platform.', 'Lead the design and implementation of core systems for AI services, including resilient fault-tolerant queues, model catalogs, and scheduling mechanisms.', 'Build and scale infrastructure capable of handling millions of API requests per second.', 'Own critical subsystems for managed AI inference to serve large language models (LLMs) globally.', 'Collaborate cross-functionally to influence the long-term vision of the platform.', 'Develop a customer-facing API that serves real-world AI models.', 'Prototype rapidly, optimize performance on GPUs, and ensure high availability as part of MVP development.', 'Contribute to open-source AI frameworks and low-level performance optimizations.']</Responsibilities>
<Skills>['Strong background in distributed systems design and implementation.', 'Experience with cloud-based services that can handle millions of requests.', 'Problem-solving skills around performance optimizations, particularly for AI inference on GPU-based systems.', 'Proactive and collaborative approach with the ability to work autonomously.', 'Strong communication skills, both written and verbal.', 'Passion for open-source contributions and AI inference frameworks.', 'Keen interest in customer-facing product development and building user-friendly APIs.']</Skills>
</Job>
<Job>
<Responsibilities>["Design and build the platform for ML engineers and data scientists to understand and delight Discord's users and keep them safe.", 'Evaluate and integrate new machine learning frameworks and tools, including LLMs and generative AI.', 'Collaborate with model builders to ensure a smooth path from idea to production.', 'Set best practices in machine learning at Discord.', 'Create foundational datasets and models.', 'Lead projects and work directly with ML practitioners and other staff+ engineers.']</Responsibilities>
<Skills>['Experience with orchestration systems such as Airflow, Dagster, or Argo.', 'Experience with real-time data processing tools like Spark, Flink, Dataflow, Kafka, or Pulsar.', 'Experience debugging and maintaining live production systems on Kubernetes.', 'Experience building ML models using modern frameworks.']</Skills>
</Job>
<Job>
<Responsibilities>['Lead the development of novel algorithms and modeling techniques for large model training.', 'Develop and maintain key platforms for developing, evaluating, and deploying LLMs for real-world applications.', 'Investigate design approaches, prototype new technology, and evaluate technical feasibility.', 'Work closely with Applied scientists to process massive data and scale machine learning models.', 'Influence overall strategy and shape the future direction of AGI at Amazon.', 'Drive system architecture and champion best practices for high-quality infrastructure.', 'Work in an Agile/Scrum environment to deliver high-quality software.']</Responsibilities>
<Skills>['Ability to quickly learn cutting-edge technologies and algorithms in Generative AI.', 'Expertise in developing mind-blowing algorithms and modeling techniques.', 'Proficiency in leveraging large-scale computing resources and heterogeneous data sources.', 'Strong collaboration skills to work with team members and Applied scientists.', 'Ability to work in a fast-paced and innovative environment.', 'Strong communication skills to effectively influence strategy and practices.']</Skills>
</Job>
<Job>
<Responsibilities>['Develop test strategies and frameworks for AI/ML products.', 'Design and implement automated tests.', 'Create and carry out test plans.', 'Maintain and enhance test frameworks.', 'Participate in standard quality practices design reviews and automated testing.', 'Productize major product features and bug fixes.', 'Consider novel ways for testing non-deterministic systems and code.', 'Pay attention to potential sources of bias during model build and training.', 'Execute manual and automated tests for InstructLab.', 'Deliver clear status updates in a timely manner.', 'Explore, identify, and document unwanted behavior, output, and bias in InstructLab models.', 'Advocate for the resolution of critical issues and communicate the impact on customers to the development team(s).', 'Monitor and participate in upstream AI/ML communities.', 'Evaluate new AI/ML-related technologies and consider potential integrations and collaborations upstream.', 'Conduct new feature research and design test cases with emphasis on model performance, scalability, automation, and bias reduction.', 'Design, develop, and maintain automation frameworks, scripts, and performance benchmarking tools with Python.', 'Run technical initiatives to grow, improve, and scale existing processes.', 'Contribute to the development of open-source projects that comprise Red Hat’s AI family of products.', 'Regularly communicate with project stakeholders including other teams of Red Hat engineers, product managers, consultants, management, and senior leadership.']</Responsibilities>
<Skills>['Extensive experience scripting and creating automation in Python and Bash.', 'Experience with AI and Machine Learning platforms, tools, and frameworks such as PyTorch, LLaMA.cpp, vLLM, fsdp, deepspeed, Kubeflow, and Tensorflow.', 'Experience creating automation for GitHub, using GitHub Actions or related continuous integration tools.', 'Experience with hardware accelerators such as GPU, CUDA, and ROCm.', 'Experience developing unit, functional, and end-to-end (E2E) test cases and automation.', 'Ability to quickly learn and use new tools and technologies.', 'Experience working with Kubernetes/OpenShift and containers.', 'Troubleshooting issues with Kubernetes/OpenShift and working with YAML, Kubernetes controllers, and operators.', 'Understanding of DevOps methodology, scrum, and/or Jira.']</Skills>
</Job>
<Job>
<Responsibilities>['Develop high-performance GPU-based inference pipelines for large multimodal diffusion models.', 'Build, optimize, and maintain serving infrastructure to deliver low-latency predictions at large scale.', 'Collaborate with DevOps teams to containerize models, manage autoscaling, and ensure uptime SLAs.', 'Leverage techniques like quantization, pruning, and distillation to reduce latency and memory footprint without compromising quality.', 'Implement continuous fine-tuning workflows to adapt models based on real-world data and feedback.', 'Design and maintain automated CI/CD pipelines for model deployment, versioning, and rollback.', 'Implement robust monitoring (latency, throughput, concept drift) and alerting for critical production systems.', 'Explore cutting-edge GPU acceleration frameworks to continuously improve throughput and reduce costs.']</Responsibilities>
<Skills>['Proficiency with Python and at least one deep learning framework (PyTorch, TensorFlow).', 'Strong knowledge of containerization (Docker, Kubernetes) and microservice architectures for ML model serving.', 'Familiarity with compression techniques (quantization, pruning, distillation) for large-scale models.', 'Experience profiling and optimizing model inference (batching, concurrency, hardware utilization).', 'Hands-on experience with ML pipeline orchestration (Airflow, Kubeflow, Argo) and automated CI/CD for ML.', 'Strong grasp of logging, monitoring, and alerting tools (Prometheus, Grafana, etc.) in distributed systems.']</Skills>
</Job>
