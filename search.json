[
  {
    "objectID": "unknown/index.html",
    "href": "unknown/index.html",
    "title": "Analysis of the GenAI/LLM job market in January 2025",
    "section": "",
    "text": "As someone currently working in a “Prompt Engineering” role, I’ve been thinking a lot about how this title basically doesn’t exist outside of a handful of companies, how the title communicates a narrow range of skills and responsibilities,and how the work that I do day-to-day is much larger in scope than just writing prompts. I identify more as an AI Engineer or AI Research Scientist, and so I was interested to see what I could learn about other similar roles that work with GenAI and LLMs.\nSo with that motivation, I set about to collect some data and look at the job market for these sorts of roles. What responsibilities and skills are being advertised most often, what kinds of titles are being used for these roles, and what kind of compensation is being offered at different levels of seniority?\nTo accomplish this, I built a custom web scraper to collect ~1000 job postings from ai-jobs.net. My code gathers job details like the title, company, location, salary, and posting date – from a range of U.S. and Canadian cities, covering entry-level, mid-level, and senior positions. I then use a Large Language Model (LLM) to extract each job’s key responsibilities, required skills, and qualifications. Afterwards, I classify each position to see whether it involves working with Generative AI or large language models, and if so, categorize it further into four major AI roles: (1) AI Research Scientist, (2) AI/ML Engineer, (3) MLOps/AI Infrastructure Engineer, and (4) AI Solution Architect. I believe this set of roles is a good representation of different areas of focus.\nFinally, I integrate the various metadata and classifications into a comprehensive dataset. I observe that GenAI/LLM positions command consistently high salary ranges across the four different roles, particularly at more senior levels. Senior-level roles tended to offer median salaries in the $195K–$210K range, while mid-level roles generally clustered around $165K–$180K. Entry-level salaries showed greater variation (likely due to the small sample size) but still landed in competitive ranges of roughly $155K–$205K in many postings. These roles often share common technical demands—like proficiency with large-scale model training, distributed computing, and LLM-specific knowledge—though each role emphasizes distinct priorities (research vs. production, for example).\nOf course, this analysis is not without limitations. For example, I am relying on a single job board, and I scraped jobs during a limited window of time. I also have not rigorously validated the LLM classifications – although I have implemented many prompt engineering best practices, and have used some of the more powerful LLMs (4o and o1). To some extent, the responsibilities and skills that were recovered from the original job postings classified into the four pre-defined roles do speak to the relative accuracy of the role classifications. The salary analysis also does not distinguish between base salary and total compensation, remote vs. in-person opportunities, large vs. small companies, and so on. But overall, I think this gives some sense of the job market for these roles."
  },
  {
    "objectID": "unknown/index.html#classify-jobs-as-relevant-to-genaillm-work-or-not",
    "href": "unknown/index.html#classify-jobs-as-relevant-to-genaillm-work-or-not",
    "title": "Analysis of the GenAI/LLM job market in January 2025",
    "section": "Classify jobs as relevant to GenAI/LLM work or not",
    "text": "Classify jobs as relevant to GenAI/LLM work or not\n\n\nClick to view the code for job classification as GenAI/LLM relevant or not\nimport nest_asyncio\nimport re\nimport asyncio\nimport logging\nfrom typing import List, Dict, Set\nfrom bs4 import BeautifulSoup\nimport pandas as pd\nfrom tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type\nfrom openai import AsyncOpenAI\nimport os\nfrom openai import RateLimitError\nimport json\n\nclass JobClassifierGenAI:\n    \"\"\"Handles classification of jobs for GenAI/LLM work\"\"\"\n    \n    PROMPT = \"\"\"\n    You will be given a list of Responsibilities and\n    Skills listed for a job. Your task is to determine\n    if the job involves working with Generative AI (GenAI)\n    or language models (a.k.a. Large Language Models (LLMs)).\n\n    &lt;Job&gt;\n    &lt;Responsibilities&gt;\n    {responsibilities}\n    &lt;/Responsibilities&gt;\n    &lt;Skills&gt;\n    {skills}\n    &lt;/Skills&gt;\n    &lt;/Job&gt;\n\n    Start by thinking step-by-step about the Job and its \n    Responsibilities and Skills, and whether it involves\n    working with Generative AI (GenAI) or language models\n    (a.k.a. Large Language Models (LLMs)).\n\n    Return your response in the following format:\n    &lt;Analysis&gt;\n    [Your analysis of the job and its Responsibilities and Skills]\n    &lt;/Analysis&gt;\n    &lt;FinalAnswer&gt;\n    true|false\n    &lt;/FinalAnswer&gt;\n    \"\"\"\n\n    def __init__(self, output_dir='role_genai_classifications', batch_size=3):\n        self.output_dir = output_dir\n        self.batch_size = batch_size\n        self.semaphore = asyncio.Semaphore(batch_size)\n        os.makedirs(output_dir, exist_ok=True)\n\n    async def classify_job(self, job: Dict) -&gt; Dict:\n        \"\"\"Classify a single job listing\"\"\"\n        logging.info(f\"Classifying job '{job['filename']}'\")\n        \n        prompt = self.PROMPT.format(\n            responsibilities=job['responsibilities'],\n            skills=job.get('skills', '')\n        )\n        \n        try:\n            response = await get_completion(prompt)\n            await asyncio.sleep(2)  # Rate limiting\n        except Exception as e:\n            logging.error(f\"Failed to classify job '{job['filename']}': {str(e)}\")\n            return {\n                **job,\n                'analysis': f'Failed to process: {str(e)}',\n                'is_genai_role': None\n            }\n        \n        return self._parse_response(job, response)\n\n    def _parse_response(self, job: Dict, response: str) -&gt; Dict:\n        \"\"\"Parse LLM response into structured format\"\"\"\n        soup = BeautifulSoup(f\"&lt;root&gt;{response}&lt;/root&gt;\", 'lxml-xml')\n        \n        analysis = soup.find('Analysis')\n        final_answer = soup.find('FinalAnswer')\n        is_genai_role = None\n        \n        if final_answer:\n            answer_text = final_answer.text.strip().lower()\n            is_genai_role = True if answer_text == 'true' else False if answer_text == 'false' else None\n        \n        return {\n            **job,\n            'analysis': analysis.text.strip() if analysis else '',\n            'is_genai_role': is_genai_role\n        }\n\n    def save_classification(self, job_id: str, result: Dict) -&gt; None:\n        \"\"\"Save classification results to file\"\"\"\n        filename = os.path.join(self.output_dir, f\"{job_id}.json\")\n        with open(filename, 'w') as f:\n            json.dump(result, f, indent=2)\n        logging.info(f\"Saved classification for job {job_id}\")\n\n    def get_classified_jobs(self) -&gt; Set[str]:\n        \"\"\"Get set of already classified job IDs\"\"\"\n        if not os.path.exists(self.output_dir):\n            return set()\n        return {f[:-5] for f in os.listdir(self.output_dir) if f.endswith('.json')}\n\n    async def process_jobs_batch(self, jobs: List[Dict]) -&gt; None:\n        \"\"\"Process a batch of jobs concurrently\"\"\"\n        async def process_with_semaphore(job: Dict) -&gt; None:\n            async with self.semaphore:\n                result = await self.classify_job(job)\n                job_id = str(result['filename'])\n                self.save_classification(job_id, result)\n        \n        await asyncio.gather(*[process_with_semaphore(job) for job in jobs])\n\n    async def classify_jobs_async(self, df: pd.DataFrame) -&gt; None:\n        \"\"\"Process all unclassified jobs in the DataFrame\"\"\"\n        total_jobs = len(df)\n        logging.info(f\"Starting classification of {total_jobs} jobs\")\n        \n        classified_jobs = self.get_classified_jobs()\n        jobs_to_process = [\n            job.to_dict() for idx, job in df.iterrows() \n            if str(job['filename']) not in classified_jobs\n        ]\n        \n        await self.process_jobs_batch(jobs_to_process)\n        logging.info(f\"Completed classification of all {total_jobs} jobs\")\n\n    def classify_jobs(self, df: pd.DataFrame) -&gt; None:\n        \"\"\"Main entry point for job classification\"\"\"\n        if df.empty:\n            logging.warning(\"Empty DataFrame provided\")\n            return\n            \n        if 'filename' not in df.columns:\n            logging.error(\"DataFrame missing required 'filename' column\")\n            return\n        \n        classified_jobs = self.get_classified_jobs()\n        logging.info(f\"Found {len(classified_jobs)} previously classified jobs\")\n        \n        new_jobs = df[~df['filename'].isin(classified_jobs)]\n        if new_jobs.empty:\n            logging.info(\"No new jobs to classify\")\n            return\n        \n        logging.info(f\"Processing {len(new_jobs)} new jobs\")\n        logging.info(f\"Skipping {len(df) - len(new_jobs)} existing jobs\")\n        \n        loop = asyncio.get_event_loop()\n        loop.run_until_complete(self.classify_jobs_async(new_jobs))\n\nclass JobDataLoader:\n    \"\"\"Handles loading and preprocessing of job data\"\"\"\n    \n    @staticmethod\n    def read_json_files(json_dir='json_extracted_data') -&gt; List[Dict]:\n        \"\"\"Read job data from JSON files\"\"\"\n        result = []\n        \n        for filename in os.listdir(json_dir):\n            if filename.endswith('.json'):\n                file_path = os.path.join(json_dir, filename)\n                try:\n                    with open(file_path, 'r') as f:\n                        data = json.load(f)\n                        name = filename[:-5]\n                        if 'responsibilities' in data and 'skills' in data:\n                            result.append({\n                                'filename': name,\n                                'responsibilities': data['responsibilities'],\n                                'skills': data['skills']\n                            })\n                except json.JSONDecodeError:\n                    logging.error(f\"Invalid JSON in {filename}\")\n                except Exception as e:\n                    logging.error(f\"Error processing {filename}: {str(e)}\")\n        \n        return result\n\n    @staticmethod\n    def load_classifications(input_dir='role_genai_classifications') -&gt; pd.DataFrame:\n        \"\"\"Load classification results into DataFrame\"\"\"\n        if not os.path.exists(input_dir):\n            return pd.DataFrame()\n            \n        all_results = []\n        for filename in os.listdir(input_dir):\n            if filename.endswith('.json'):\n                with open(os.path.join(input_dir, filename), 'r') as f:\n                    classification = json.load(f)\n                    all_results.append(classification)\n        \n        return pd.DataFrame(all_results)\n\n\n\nloader = JobDataLoader()\njobs = loader.read_json_files()\ndf = pd.DataFrame(jobs)\n\n#classifier = JobClassifierGenAI()\n#classifier.classify_jobs(df)\n\n# Load results\n#results_df = loader.load_classifications()"
  },
  {
    "objectID": "unknown/index.html#classify-genaillm-jobs-into-pre-defined-categories",
    "href": "unknown/index.html#classify-genaillm-jobs-into-pre-defined-categories",
    "title": "Analysis of the GenAI/LLM job market in January 2025",
    "section": "Classify GenAI/LLM jobs into pre-defined categories",
    "text": "Classify GenAI/LLM jobs into pre-defined categories\nFor this next classification task, I’ll make the assumption that there are four types of AI engineering and science roles that are relevant to work with GenAI systems. These are:\n\nAI Research Scientist\nAI/ML Engineer\nMLOps / AI Infrastructure Engineer\nAI Solution Architect\n\nI’ll also include other categories that are not of interest, but may improve classification accuracy. These are:\n\nData Scientist\nData Engineer\nProduct Manager\nSoftware Engineer\n\nThe code below implements an automated job classification system that uses an LLM to categorize job postings into the eight predefined roles listed above (four GenAI-focused and four related roles). It consists of several classes that work together: JobClassifier handles the core classification logic by comparing job descriptions against detailed role templates, JobData and ClassificationResult provide structured data containers, and JobProcessor manages the overall pipeline from loading jobs to saving results. The system processes jobs concurrently using asyncio, includes error handling and rate limiting, and outputs both an analysis explaining the classification and a final numerical category (0-8) for each job, with all results saved as JSON files for further analysis.\nDefinitions of the roles can be found in the JOB_DESCRIPTIONS variable.\n\n\nClick to view the code for job classification into pre-defined roles\nfrom dataclasses import dataclass\nfrom typing import List, Dict, Set, Optional\nimport logging\nimport json\nimport asyncio\nimport os\nfrom bs4 import BeautifulSoup\nimport pandas as pd\nimport nest_asyncio\n\nJOB_DESCRIPTIONS = \"\"\"\n&lt;Option title=\"AI Research Scientist\" number=\"1\"&gt;\n  &lt;PrimaryFocus&gt;\n    Investigate and adapt cutting-edge AI methodologies (e.g., generative models, advanced prompt engineering) for applications.\n  &lt;/PrimaryFocus&gt;\n  &lt;KeyResponsibilities&gt;\n    Conduct experiments to evaluate the performance (e.g., quality, accuracy) of new AI approaches and refine existing models.\n    Collaborate with AI/ML Engineers to transition successful prototypes into production.\n    Stay current with the latest AI research and emerging trends in generative AI.\n    Develop human-annotated datasets for training and evaluation of AI models.\n  &lt;/KeyResponsibilities&gt;\n  &lt;SkillsAndTools&gt;\n    Deep understanding of LLMs and prompt engineering.\n    Strong background in statistics, optimization, or related fields.\n    Knowledge of experimental methods (e.g., A/B testing) and hypothesis testing.\n    Knowledge of LLM evaluation methods, including algorithmic evals, human evals, or LLM-as-a-judge evals.\n  &lt;/SkillsAndTools&gt;\n&lt;/Option&gt;\n&lt;Option title=\"AI/ML Engineer\" number=\"2\"&gt;\n  &lt;PrimaryFocus&gt;\n    Transform research output into robust, scalable AI solutions for the product or internal use.\n  &lt;/PrimaryFocus&gt;\n  &lt;KeyResponsibilities&gt;\n    Productionize AI models, ensuring they meet performance and reliability requirements.\n    Develop and maintain data pipelines for model training, inference, and monitoring.\n    Collaborate closely with Research Scientists to optimize and refine model implementations.\n  &lt;/KeyResponsibilities&gt;\n  &lt;SkillsAndTools&gt;\n    Proficiency in Python, Go, or similar languages.\n    Experience with API development and integration (REST, GraphQL).\n    Working knowledge of software engineering best practices (version control, testing, CI/CD).\n  &lt;/SkillsAndTools&gt;\n&lt;/Option&gt;\n&lt;Option title=\"MLOps / AI Infrastructure Engineer\" number=\"3\"&gt;\n  &lt;PrimaryFocus&gt;\n    Ensure reliable deployment, scaling, and monitoring of AI systems in production.\n  &lt;/PrimaryFocus&gt;\n  &lt;KeyResponsibilities&gt;\n    Set up CI/CD pipelines tailored for AI workflows, including model versioning and data governance.\n    Monitor production models for performance, latency, and data drift, implementing necessary updates.\n    Manage infrastructure for scalable AI deployments (Docker, Kubernetes, cloud services).\n  &lt;/KeyResponsibilities&gt;\n  &lt;SkillsAndTools&gt;\n    Strong DevOps background, with tools like Docker, Kubernetes, and Terraform.\n    Familiarity with ML orchestration/monitoring tools (MLflow, Airflow, Prometheus).\n    Experience optimizing compute usage (GPU/TPU) for cost-effective scaling.\n  &lt;/SkillsAndTools&gt;\n&lt;/Option&gt;\n&lt;Option title=\"AI Solution Architect\" number=\"4\"&gt;\n  &lt;PrimaryFocus&gt;\n    Design and orchestrate AI solutions leveraging generative models and LLM technologies to create impactful experiences and solutions that align with business objectives.\n  &lt;/PrimaryFocus&gt;\n  &lt;KeyResponsibilities&gt;\n    Collaborate with subject matter experts (SMEs) to identify and refine opportunities for generative AI/LLM-based use cases.\n    Assess feasibility and define high-level solution architectures, ensuring they address core business and user requirements.\n    Develop technical proposals and roadmaps, translating complex requirements into actionable plans.\n    Provide thought leadership on conversational design, user experience flow, and model interaction strategies.\n    Ensure solutions comply with relevant data governance, privacy, and security considerations.\n    Facilitate cross-functional collaboration, guiding teams through solution conceptualization and implementation phases.\n  &lt;/KeyResponsibilities&gt;\n  &lt;SkillsAndTools&gt;\n    Strong understanding of LLM capabilities and prompt engineering principles.\n    Experience with conversational experience design (e.g., chatbots, voice interfaces) and user journey mapping.\n    Ability to analyze business needs and translate them into feasible AI solution proposals.\n    Familiarity with data privacy and security best practices, especially as they pertain to AI solutions.\n    Excellent communication and stakeholder management skills to align technical and non-technical teams.\n  &lt;/SkillsAndTools&gt;\n&lt;/Option&gt;\n&lt;Option title=\"Data Scientist\" number=\"5\"&gt; \n  &lt;PrimaryFocus&gt;\n    Leverage statistical analysis, machine learning, and data visualization to derive actionable insights and guide data-informed decisions.\n  &lt;/PrimaryFocus&gt; \n  &lt;KeyResponsibilities&gt; \n    Perform exploratory data analysis (EDA) to identify trends and patterns in large, complex datasets. \n    Develop and validate predictive and prescriptive models, collaborating with cross-functional teams to implement these solutions. \n    Design and execute experiments to test hypotheses, measure impact, and inform business strategies. \n    Present findings and recommendations to stakeholders in a clear, concise manner using visualizations and dashboards. \n    Work with data engineers to ensure data quality, governance, and availability. \n  &lt;/KeyResponsibilities&gt; \n  &lt;SkillsAndTools&gt; \n    Proficiency in Python, R, or SQL for data manipulation and analysis. \n    Experience with common ML libraries (e.g., scikit-learn, XGBoost) and deep learning frameworks (e.g., PyTorch, TensorFlow). \n    Solid grounding in statistics, probability, and experimental design. \n    Familiarity with data visualization tools (e.g., Tableau, Power BI) for communicating insights. \n    Strong analytical thinking and ability to translate complex data problems into business solutions. \n  &lt;/SkillsAndTools&gt; \n&lt;/Option&gt;\n&lt;Option title=\"Data Engineer\" number=\"6\"&gt;\n  &lt;PrimaryFocus&gt;\n    Design, build, and maintain scalable data pipelines and architectures that enable efficient data collection, storage, and analysis.\n  &lt;/PrimaryFocus&gt;\n  &lt;KeyResponsibilities&gt;\n    Develop and optimize data ingestion and transformation processes (ETL/ELT), ensuring high performance and reliability.\n    Implement and manage data workflows, integrating internal and external data sources.\n    Collaborate with Data Scientists, AI/ML Engineers, and other stakeholders to ensure data readiness for analytics and model training.\n    Monitor data pipelines for performance, reliability, and cost-effectiveness, taking corrective actions when needed.\n    Maintain data quality and governance standards, including metadata management and data cataloging.\n  &lt;/KeyResponsibilities&gt;\n  &lt;SkillsAndTools&gt;\n    Proficiency in Python, SQL, and distributed data processing frameworks (e.g., Spark, Kafka).\n    Experience with cloud-based data ecosystems (AWS, GCP, or Azure), and related storage/processing services (e.g., S3, BigQuery, Dataflow).\n    Familiarity with infrastructure-as-code and DevOps tools (Terraform, Docker, Kubernetes) for automating data platform deployments.\n    Strong understanding of database systems (relational, NoSQL) and data modeling principles.\n    Knowledge of data orchestration and workflow management tools (Airflow, Luigi, Dagster).\n  &lt;/SkillsAndTools&gt;\n&lt;/Option&gt;\n&lt;Option title=\"Product Manager\" number=\"7\"&gt;\n  &lt;PrimaryFocus&gt;\n    Drive the product vision and strategy, ensuring alignment with business goals and user needs while delivering impactful AI-driven solutions.\n  &lt;/PrimaryFocus&gt;\n  &lt;KeyResponsibilities&gt;\n    Conduct user and market research to identify opportunities, define product requirements, and set success metrics.\n    Collaborate with cross-functional teams (Engineering, Data Science, Design) to prioritize features and plan releases.\n    Develop and communicate product roadmaps, ensuring stakeholders are aligned on goals and timelines.\n    Monitor product performance through data analysis and user feedback, iterating on improvements and new feature ideas.\n    Facilitate agile development practices, writing clear user stories and acceptance criteria.\n  &lt;/KeyResponsibilities&gt;\n  &lt;SkillsAndTools&gt;\n    Strong understanding of product lifecycle management and agile methodologies (Scrum/Kanban).\n    Excellent communication, negotiation, and stakeholder management skills.\n    Experience with product management and collaboration tools (e.g., Jira, Confluence, Trello).\n    Analytical mindset for leveraging metrics, A/B testing, and user feedback in decision-making.\n    Familiarity with AI/ML concepts and the ability to translate technical possibilities into viable product features.\n  &lt;/SkillsAndTools&gt;\n&lt;/Option&gt;\n&lt;Option title=\"Software Engineer\" number=\"8\"&gt;\n  &lt;PrimaryFocus&gt;\n  Design, develop, and maintain high-quality software applications and services that address user needs and align with overall business objectives.\n  &lt;/PrimaryFocus&gt;\n  &lt;KeyResponsibilities&gt;\n    Collaborate with cross-functional teams (Product, Design, QA) to interpret requirements and deliver robust solutions.\n    Write clean, efficient, and testable code following best practices and coding standards.\n    Participate in system architecture and design discussions, contributing to the evolution of technical roadmaps.\n    Perform code reviews and provide constructive feedback to peers, maintaining a high bar for code quality.\n    Implement and maintain CI/CD pipelines to streamline deployment and reduce manual interventions.\n    Continuously improve system performance and scalability through profiling and optimization.\n  &lt;/KeyResponsibilities&gt;\n  &lt;SkillsAndTools&gt;\n    Proficiency in one or more programming languages (e.g., Java, Python, JavaScript, C++).\n    Experience with modern frameworks/libraries (e.g., Spring Boot, Node.js, React, Django).\n    Solid understanding of software design principles (e.g., SOLID, DRY) and architectural patterns (e.g., microservices).\n    Familiarity with version control systems (Git), testing frameworks, and agile methodologies.\n    Working knowledge of containerization (Docker), orchestration (Kubernetes), and cloud platforms (AWS, Azure, GCP).\n  &lt;/SkillsAndTools&gt;\n&lt;/Option&gt;\n\"\"\"\n\nPROMPTS = {\n\"prompt\": \"\"\"\nYou will be given a list of Responsibilities and\nSkills listed for a job. Your task is to determine\nif the job is a good fit with any of the Options,\nand if so, which one.\n\n&lt;Job&gt;\n&lt;Responsibilities&gt;\n{responsibilities}\n&lt;/Responsibilities&gt;\n&lt;Skills&gt;\n{skills}\n&lt;/Skills&gt;\n&lt;/Job&gt;\n\n&lt;Options&gt;\n{Options}\n&lt;/Options&gt;\n\nStart by thinking step-by-step about the Job and its \nResponsibilities and Skills, in relation to each of the \nOptions.\n\nDecide if the Job is a good fit with ANY of the Options.\nIf NONE of the Options are relevant to the Job, say so and \nreturn a 0 as your FinalAnswer.\n\nOtherwise, decide which of the Options is the most similar\nto the Job and return its number as your FinalAnswer.\n\nReturn your response in the following format:\n&lt;Analysis&gt;\n[Your analysis of the job and its Responsibilities and Skills, in relation each of the Options]\n&lt;/Analysis&gt;\n&lt;FinalAnswer&gt;\n0|1|2|3|4|5|6|7|8\n&lt;/FinalAnswer&gt;\n\"\"\"\n}\n\n# Enable nested event loops\nnest_asyncio.apply()\n\n@dataclass\nclass JobData:\n    \"\"\"Represents a job posting with extracted information.\"\"\"\n    filename: str\n    responsibilities: List[str]\n    skills: List[str]\n\n@dataclass\nclass ClassificationResult:\n    \"\"\"Represents the result of a job classification.\"\"\"\n    filename: str\n    responsibilities: List[str]\n    skills: List[str]\n    analysis: str\n    role_classification: Optional[int]\n    role_title: Optional[str]\n\nclass JobClassifier:\n    \"\"\"Handles classification of jobs into predefined roles.\"\"\"\n    \n    def __init__(self, output_dir: str = 'role_classifications', batch_size: int = 3):\n        self.output_dir = output_dir\n        self.batch_size = batch_size\n        self.semaphore = asyncio.Semaphore(batch_size)\n        os.makedirs(output_dir, exist_ok=True)\n        \n    async def classify_job(self, job: JobData) -&gt; ClassificationResult:\n        \"\"\"Classify a single job listing.\"\"\"\n        logging.info(f\"Classifying job '{job.filename}'\")\n        \n        prompt = PROMPTS[\"prompt\"].format(\n            responsibilities=job.responsibilities,  # Access as attribute instead of dict\n            skills=job.skills,  # Access as attribute instead of dict\n            Options=JOB_DESCRIPTIONS\n        )\n        \n        try:\n            response = await get_completion(prompt)\n            await asyncio.sleep(5)  # Rate limiting\n            return self._parse_response(job, response)\n        except Exception as e:\n            logging.error(f\"Failed to classify job '{job.filename}': {str(e)}\")\n            return ClassificationResult(\n                filename=job.filename,\n                responsibilities=job.responsibilities,\n                skills=job.skills,\n                analysis=f'Failed to process: {str(e)}',\n                role_classification=None,\n                role_title=None\n            )\n    \n    def _parse_response(self, job: JobData, response: str) -&gt; ClassificationResult:\n        \"\"\"Parse LLM response into structured format.\"\"\"\n        soup = BeautifulSoup(f\"&lt;root&gt;{response}&lt;/root&gt;\", 'lxml-xml')\n        \n        analysis = soup.find('Analysis')\n        role_choice = soup.find('FinalAnswer')\n        role_number = int(role_choice.text.strip()) if role_choice else None\n        \n        role_title = self._get_role_title(role_number)\n        \n        return ClassificationResult(\n            filename=job.filename,\n            responsibilities=job.responsibilities,\n            skills=job.skills,\n            analysis=analysis.text.strip() if analysis else '',\n            role_classification=role_number,\n            role_title=role_title\n        )\n    \n    def _get_role_title(self, role_number: Optional[int]) -&gt; Optional[str]:\n        \"\"\"Get the title for a role number.\"\"\"\n        if role_number is None:\n            return None\n        if role_number == 0:\n            return \"Other\"\n            \n        wrapped_xml = f\"&lt;root&gt;{JOB_DESCRIPTIONS}&lt;/root&gt;\"\n        job_descriptions_soup = BeautifulSoup(wrapped_xml, 'lxml-xml')\n        matching_job = job_descriptions_soup.find('Option', {'number': str(role_number)})\n        \n        if matching_job:\n            return matching_job['title']\n        logging.error(f\"No matching job found for role number {role_number}\")\n        return None\n\nclass JobProcessor:\n    \"\"\"Handles the processing of job data files.\"\"\"\n    \n    def __init__(self, input_dir: str = 'json_extracted_data'):\n        self.input_dir = input_dir\n        self.classifier = JobClassifier()\n        \n    def load_jobs(self) -&gt; List[JobData]:\n        \"\"\"Load jobs from JSON files.\"\"\"\n        jobs = []\n        # Get list of all JSON files\n        total_files = len([f for f in os.listdir(self.input_dir) if f.endswith('.json')])\n        # Get files that were classified as GenAI-relevant\n        classified_files = self._get_classified_files()\n        # Get files that have already been processed\n        processed_files = {\n            f[:-5] for f in os.listdir(self.classifier.output_dir) \n            if f.endswith('.json')\n        }\n        # Get relevant files that haven't been processed yet\n        files_to_process = classified_files - processed_files\n        \n        logging.info(f\"Found {total_files} total files\")\n        logging.info(f\"Found {len(classified_files)} relevant GenAI files\")\n        logging.info(f\"Already processed: {len(processed_files)} files\")\n        logging.info(f\"Remaining to process: {len(files_to_process)} files\")\n        \n        # Only process files that are both relevant and unprocessed\n        for filename in os.listdir(self.input_dir):\n            if not filename.endswith('.json'):\n                continue\n                \n            name = filename[:-5]\n            if name not in files_to_process:\n                continue\n                \n            try:\n                job = self._load_job_file(filename)\n                if job:\n                    jobs.append(job)\n            except Exception as e:\n                logging.error(f\"Error processing {filename}: {str(e)}\")\n        \n        logging.info(f\"Processing {len(jobs)} remaining jobs\")\n        return jobs\n    \n    def _load_job_file(self, filename: str) -&gt; Optional[JobData]:\n        \"\"\"Load and parse a single job file.\"\"\"\n        file_path = os.path.join(self.input_dir, filename)\n        try:\n            with open(file_path, 'r') as f:\n                data = json.load(f)\n                if 'responsibilities' in data and 'skills' in data:\n                    return JobData(\n                        filename=filename[:-5],\n                        responsibilities=data['responsibilities'],\n                        skills=data['skills']\n                    )\n        except json.JSONDecodeError:\n            logging.error(f\"Invalid JSON in {filename}\")\n        return None\n    \n    def _get_classified_files(self) -&gt; Set[str]:\n        \"\"\"Get set of files that have been previously classified as GenAI-related.\"\"\"\n        genai_dir = 'role_genai_classifications'\n        if not os.path.exists(genai_dir):\n            return set()\n        \n        genai_files = set()\n        for f in os.listdir(genai_dir):\n            if f.endswith('.json'):\n                try:\n                    with open(os.path.join(genai_dir, f), 'r') as file:\n                        data = json.load(file)\n                        if data.get('is_genai_role') is True:  # Explicitly check for True\n                            genai_files.add(f[:-5])\n                except Exception as e:\n                    logging.error(f\"Error reading {f}: {e}\")\n        return genai_files\n    \n    async def process_jobs(self) -&gt; None:\n        \"\"\"Process all jobs.\"\"\"\n        jobs = self.load_jobs()\n        if not jobs:\n            return\n            \n        logging.info(f\"Processing {len(jobs)} relevant jobs\")\n        await self._process_jobs_batch(jobs)\n        logging.info(\"Job classification complete\")\n    \n    async def _process_jobs_batch(self, jobs: List[JobData]) -&gt; None:\n        \"\"\"Process a batch of jobs concurrently.\"\"\"\n        async def process_with_semaphore(job: JobData) -&gt; None:\n            async with self.classifier.semaphore:\n                result = await self.classifier.classify_job(job)\n                self._save_result(result)\n        \n        await asyncio.gather(*[process_with_semaphore(job) for job in jobs])\n    \n    def _save_result(self, result: ClassificationResult) -&gt; None:\n        \"\"\"Save classification result to file.\"\"\"\n        filename = os.path.join(self.classifier.output_dir, f\"{result.filename}.json\")\n        with open(filename, 'w') as f:\n            json.dump(vars(result), f, indent=2)\n        logging.info(f\"Saved classification for job {result.filename}\")\n\ndef classify_job_roles(df: pd.DataFrame) -&gt; None:\n    \"\"\"Main entry point for job classification.\"\"\"\n    if df.empty:\n        logging.warning(\"Empty DataFrame provided\")\n        return\n        \n    processor = JobProcessor()\n    loop = asyncio.get_event_loop()\n    loop.run_until_complete(processor.process_jobs())\n\n\n\nimport logging\nlogging.basicConfig(level=logging.INFO)\nloader = JobDataLoader()\njobs = loader.read_json_files()\ndf = pd.DataFrame(jobs)\nclassify_job_roles(df)\n\n2025-02-02 11:09:54,741 - INFO - Found 862 total files\n2025-02-02 11:09:54,741 - INFO - Found 284 relevant GenAI files\n2025-02-02 11:09:54,742 - INFO - Already processed: 249 files\n2025-02-02 11:09:54,742 - INFO - Remaining to process: 35 files\n2025-02-02 11:09:54,745 - INFO - Processing 35 remaining jobs\n2025-02-02 11:09:54,745 - INFO - Processing 35 relevant jobs\n2025-02-02 11:09:54,746 - INFO - Classifying job 'j0b848'\n2025-02-02 11:09:54,779 - INFO - Classifying job 'j910b7'\n2025-02-02 11:09:54,809 - INFO - Classifying job 'j542d8'\n2025-02-02 11:10:03,263 - INFO - Processing job ID: j06758\n2025-02-02 11:10:03,263 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,264 - INFO - Processing job ID: j9c2d4\n2025-02-02 11:10:03,264 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,265 - INFO - Processing job ID: j692fd\n2025-02-02 11:10:03,266 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,267 - INFO - Processing job ID: j5adae\n2025-02-02 11:10:03,267 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,268 - INFO - Processing job ID: jf3085\n2025-02-02 11:10:03,269 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,269 - INFO - Processing job ID: j47004\n2025-02-02 11:10:03,273 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,273 - INFO - Processing job ID: j0f67c\n2025-02-02 11:10:03,274 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,275 - INFO - Processing job ID: jcc952\n2025-02-02 11:10:03,275 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,276 - INFO - Processing job ID: j709a2\n2025-02-02 11:10:03,276 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,277 - INFO - Processing job ID: jb59a3\n2025-02-02 11:10:03,277 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,278 - INFO - Processing job ID: je1e51\n2025-02-02 11:10:03,279 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,279 - INFO - Processing job ID: jd6ca2\n2025-02-02 11:10:03,280 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,280 - INFO - Processing job ID: j3551e\n2025-02-02 11:10:03,281 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,281 - INFO - Processing job ID: j98253\n2025-02-02 11:10:03,282 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,283 - INFO - Processing job ID: j81e1a\n2025-02-02 11:10:03,283 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,284 - INFO - Processing job ID: j92226\n2025-02-02 11:10:03,285 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,289 - INFO - Processing job ID: jde156\n2025-02-02 11:10:03,290 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,290 - INFO - Processing job ID: j32ed8\n2025-02-02 11:10:03,291 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,293 - INFO - Processing job ID: ja71c8\n2025-02-02 11:10:03,294 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,296 - INFO - Processing job ID: jf429d\n2025-02-02 11:10:03,297 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,298 - INFO - Processing job ID: j740b4\n2025-02-02 11:10:03,299 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,303 - INFO - Processing job ID: j5c5fc\n2025-02-02 11:10:03,304 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,305 - INFO - Processing job ID: j154f9\n2025-02-02 11:10:03,306 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,308 - INFO - Processing job ID: jafd84\n2025-02-02 11:10:03,309 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,309 - INFO - Processing job ID: j61b8e\n2025-02-02 11:10:03,310 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,311 - INFO - Processing job ID: j9b9fc\n2025-02-02 11:10:03,312 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,313 - INFO - Processing job ID: jb0b36\n2025-02-02 11:10:03,314 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,314 - INFO - Processing job ID: jc5818\n2025-02-02 11:10:03,316 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,317 - INFO - Processing job ID: j52713\n2025-02-02 11:10:03,318 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,318 - INFO - Processing job ID: jb8ba8\n2025-02-02 11:10:03,320 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,321 - INFO - Processing job ID: j4584e\n2025-02-02 11:10:03,321 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,322 - INFO - Processing job ID: j4215b\n2025-02-02 11:10:03,323 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,323 - INFO - Processing job ID: jda7d7\n2025-02-02 11:10:03,324 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,325 - INFO - Processing job ID: j81c6e\n2025-02-02 11:10:03,325 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,326 - INFO - Processing job ID: j05901\n2025-02-02 11:10:03,327 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,327 - INFO - Processing job ID: j1571c\n2025-02-02 11:10:03,328 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,329 - INFO - Processing job ID: jac2b4\n2025-02-02 11:10:03,329 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,330 - INFO - Processing job ID: jeed4f\n2025-02-02 11:10:03,333 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,333 - INFO - Processing job ID: je192e\n2025-02-02 11:10:03,334 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,335 - INFO - Processing job ID: ja27a3\n2025-02-02 11:10:03,335 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,336 - INFO - Processing job ID: jc23ec\n2025-02-02 11:10:03,337 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,338 - INFO - Processing job ID: j017b6\n2025-02-02 11:10:03,340 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,341 - INFO - Processing job ID: jb86b6\n2025-02-02 11:10:03,342 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,343 - INFO - Processing job ID: j5181a\n2025-02-02 11:10:03,343 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,344 - INFO - Processing job ID: jfb5fd\n2025-02-02 11:10:03,345 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,346 - INFO - Processing job ID: j2307d\n2025-02-02 11:10:03,346 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,346 - INFO - Processing job ID: jc20c5\n2025-02-02 11:10:03,347 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,348 - INFO - Processing job ID: j392d7\n2025-02-02 11:10:03,350 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,351 - INFO - Processing job ID: j733dd\n2025-02-02 11:10:03,351 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,353 - INFO - Processing job ID: jd7e83\n2025-02-02 11:10:03,353 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,354 - INFO - Processing job ID: j97730\n2025-02-02 11:10:03,355 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,356 - INFO - Processing job ID: j4d650\n2025-02-02 11:10:03,357 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,357 - INFO - Processing job ID: jcf8f6\n2025-02-02 11:10:03,358 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,359 - INFO - Processing job ID: jb33cb\n2025-02-02 11:10:03,360 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,361 - INFO - Processing job ID: j05e1a\n2025-02-02 11:10:03,362 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,362 - INFO - Processing job ID: j43198\n2025-02-02 11:10:03,363 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,364 - INFO - Processing job ID: j1d67b\n2025-02-02 11:10:03,365 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,366 - INFO - Processing job ID: j5406e\n2025-02-02 11:10:03,367 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,370 - INFO - Processing job ID: j722dd\n2025-02-02 11:10:03,372 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,373 - INFO - Processing job ID: j00cb4\n2025-02-02 11:10:03,374 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,375 - INFO - Processing job ID: j52ca1\n2025-02-02 11:10:03,376 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,377 - INFO - Processing job ID: j6c50c\n2025-02-02 11:10:03,378 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,379 - INFO - Processing job ID: j63505\n2025-02-02 11:10:03,380 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,380 - INFO - Processing job ID: j6a6e9\n2025-02-02 11:10:03,382 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,382 - INFO - Processing job ID: j579cd\n2025-02-02 11:10:03,383 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,384 - INFO - Processing job ID: ja2db2\n2025-02-02 11:10:03,384 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,385 - INFO - Processing job ID: j9d81d\n2025-02-02 11:10:03,386 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,386 - INFO - Processing job ID: j6e922\n2025-02-02 11:10:03,387 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,388 - INFO - Processing job ID: jc7fba\n2025-02-02 11:10:03,389 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,389 - INFO - Processing job ID: jdfe11\n2025-02-02 11:10:03,390 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,391 - INFO - Processing job ID: j5cb97\n2025-02-02 11:10:03,392 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,393 - INFO - Processing job ID: j9c85d\n2025-02-02 11:10:03,393 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,394 - INFO - Processing job ID: jf8953\n2025-02-02 11:10:03,394 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,395 - INFO - Processing job ID: j92a25\n2025-02-02 11:10:03,398 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,398 - INFO - Processing job ID: j0a336\n2025-02-02 11:10:03,399 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,400 - INFO - Processing job ID: j7ff3e\n2025-02-02 11:10:03,401 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,402 - INFO - Processing job ID: j9a732\n2025-02-02 11:10:03,403 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,404 - INFO - Processing job ID: j1c5db\n2025-02-02 11:10:03,404 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,405 - INFO - Processing job ID: j4b9f6\n2025-02-02 11:10:03,405 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,406 - INFO - Processing job ID: jdb635\n2025-02-02 11:10:03,407 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,407 - INFO - Processing job ID: j79967\n2025-02-02 11:10:03,408 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,409 - INFO - Processing job ID: j289be\n2025-02-02 11:10:03,409 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,410 - INFO - Processing job ID: jffd3d\n2025-02-02 11:10:03,410 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,411 - INFO - Processing job ID: jc36f2\n2025-02-02 11:10:03,411 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,414 - INFO - Processing job ID: jbe3e9\n2025-02-02 11:10:03,414 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,414 - INFO - Processing job ID: j92e88\n2025-02-02 11:10:03,415 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,415 - INFO - Processing job ID: jff76b\n2025-02-02 11:10:03,416 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,416 - INFO - Processing job ID: ja7ea0\n2025-02-02 11:10:03,418 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,419 - INFO - Processing job ID: j45e53\n2025-02-02 11:10:03,419 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,421 - INFO - Processing job ID: j12f0b\n2025-02-02 11:10:03,421 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,424 - INFO - Processing job ID: j533ab\n2025-02-02 11:10:03,425 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,426 - INFO - Processing job ID: jbad0e\n2025-02-02 11:10:03,426 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,427 - INFO - Processing job ID: j5a983\n2025-02-02 11:10:03,428 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,428 - INFO - Processing job ID: jd1d69\n2025-02-02 11:10:03,429 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,430 - INFO - Processing job ID: jd3d8c\n2025-02-02 11:10:03,431 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,431 - INFO - Processing job ID: j286a9\n2025-02-02 11:10:03,432 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,433 - INFO - Processing job ID: j13a76\n2025-02-02 11:10:03,435 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,436 - INFO - Processing job ID: jea48a\n2025-02-02 11:10:03,436 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,437 - INFO - Processing job ID: j06715\n2025-02-02 11:10:03,437 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,438 - INFO - Processing job ID: j991c8\n2025-02-02 11:10:03,440 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,441 - INFO - Processing job ID: j1bf5e\n2025-02-02 11:10:03,441 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,442 - INFO - Processing job ID: j2f77a\n2025-02-02 11:10:03,442 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,444 - INFO - Processing job ID: j6f9bd\n2025-02-02 11:10:03,445 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,446 - INFO - Processing job ID: j7ba99\n2025-02-02 11:10:03,447 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,448 - INFO - Processing job ID: je5505\n2025-02-02 11:10:03,450 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,451 - INFO - Processing job ID: j3eba4\n2025-02-02 11:10:03,452 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,453 - INFO - Processing job ID: j86215\n2025-02-02 11:10:03,454 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,456 - INFO - Processing job ID: jd25b2\n2025-02-02 11:10:03,457 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,458 - INFO - Processing job ID: j5462d\n2025-02-02 11:10:03,458 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,459 - INFO - Processing job ID: j7641b\n2025-02-02 11:10:03,459 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,460 - INFO - Processing job ID: ja754d\n2025-02-02 11:10:03,460 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,462 - INFO - Processing job ID: jb3322\n2025-02-02 11:10:03,462 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,463 - INFO - Processing job ID: j928a8\n2025-02-02 11:10:03,463 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,464 - INFO - Processing job ID: j442fd\n2025-02-02 11:10:03,464 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,466 - INFO - Processing job ID: j2d360\n2025-02-02 11:10:03,467 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,468 - INFO - Processing job ID: jb760c\n2025-02-02 11:10:03,469 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,470 - INFO - Processing job ID: j8bb96\n2025-02-02 11:10:03,471 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,471 - INFO - Processing job ID: j295eb\n2025-02-02 11:10:03,472 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,473 - INFO - Processing job ID: j1a80f\n2025-02-02 11:10:03,473 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,474 - INFO - Processing job ID: j9f7d4\n2025-02-02 11:10:03,475 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,477 - INFO - Processing job ID: j69e63\n2025-02-02 11:10:03,477 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,478 - INFO - Processing job ID: j88ddf\n2025-02-02 11:10:03,479 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,480 - INFO - Processing job ID: j87ba0\n2025-02-02 11:10:03,481 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,482 - INFO - Processing job ID: j16780\n2025-02-02 11:10:03,483 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,484 - INFO - Processing job ID: j6ee8e\n2025-02-02 11:10:03,485 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,486 - INFO - Processing job ID: j7e441\n2025-02-02 11:10:03,487 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,488 - INFO - Processing job ID: j84365\n2025-02-02 11:10:03,489 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,490 - INFO - Processing job ID: j6ef19\n2025-02-02 11:10:03,493 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,493 - INFO - Processing job ID: j460c5\n2025-02-02 11:10:03,494 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,494 - INFO - Processing job ID: j7dadb\n2025-02-02 11:10:03,497 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,498 - INFO - Processing job ID: jfba6d\n2025-02-02 11:10:03,499 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,499 - INFO - Processing job ID: j417fd\n2025-02-02 11:10:03,500 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,501 - INFO - Processing job ID: j02159\n2025-02-02 11:10:03,502 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,503 - INFO - Processing job ID: jc3a2c\n2025-02-02 11:10:03,504 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,504 - INFO - Processing job ID: jdde0d\n2025-02-02 11:10:03,507 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,508 - INFO - Processing job ID: j35719\n2025-02-02 11:10:03,508 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,510 - INFO - Processing job ID: j0fb04\n2025-02-02 11:10:03,511 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,512 - INFO - Processing job ID: jdf3cd\n2025-02-02 11:10:03,513 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,514 - INFO - Processing job ID: j6d0d0\n2025-02-02 11:10:03,515 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,515 - INFO - Processing job ID: j36892\n2025-02-02 11:10:03,516 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,516 - INFO - Processing job ID: j9413b\n2025-02-02 11:10:03,517 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,518 - INFO - Processing job ID: j772b4\n2025-02-02 11:10:03,520 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,521 - INFO - Processing job ID: j96e4e\n2025-02-02 11:10:03,521 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,522 - INFO - Processing job ID: ja56ed\n2025-02-02 11:10:03,522 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,524 - INFO - Processing job ID: jd2fba\n2025-02-02 11:10:03,524 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,525 - INFO - Processing job ID: j6928a\n2025-02-02 11:10:03,525 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,526 - INFO - Processing job ID: j2a176\n2025-02-02 11:10:03,526 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,527 - INFO - Processing job ID: j42c08\n2025-02-02 11:10:03,527 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,528 - INFO - Processing job ID: jd78e7\n2025-02-02 11:10:03,528 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,528 - INFO - Processing job ID: j97db4\n2025-02-02 11:10:03,529 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,530 - INFO - Processing job ID: j6ac4b\n2025-02-02 11:10:03,530 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,531 - INFO - Processing job ID: jecbc3\n2025-02-02 11:10:03,531 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,534 - INFO - Processing job ID: j6f3a6\n2025-02-02 11:10:03,534 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,536 - INFO - Processing job ID: j17f82\n2025-02-02 11:10:03,537 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,538 - INFO - Processing job ID: j12635\n2025-02-02 11:10:03,539 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,540 - INFO - Processing job ID: j8ea2b\n2025-02-02 11:10:03,540 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,541 - INFO - Processing job ID: jd4ae5\n2025-02-02 11:10:03,541 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,542 - INFO - Processing job ID: j9439c\n2025-02-02 11:10:03,542 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,543 - INFO - Processing job ID: j2be84\n2025-02-02 11:10:03,543 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,544 - INFO - Processing job ID: j2503e\n2025-02-02 11:10:03,544 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,546 - INFO - Processing job ID: j6f698\n2025-02-02 11:10:03,546 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,547 - INFO - Processing job ID: jcde3f\n2025-02-02 11:10:03,547 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,548 - INFO - Processing job ID: j9f97d\n2025-02-02 11:10:03,548 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,549 - INFO - Processing job ID: je04a9\n2025-02-02 11:10:03,550 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,550 - INFO - Processing job ID: j13bd4\n2025-02-02 11:10:03,551 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,552 - INFO - Processing job ID: j08373\n2025-02-02 11:10:03,553 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,554 - INFO - Processing job ID: j1f236\n2025-02-02 11:10:03,555 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,556 - INFO - Processing job ID: j4b1ea\n2025-02-02 11:10:03,558 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,558 - INFO - Processing job ID: jc9ecc\n2025-02-02 11:10:03,559 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,560 - INFO - Processing job ID: j2f64f\n2025-02-02 11:10:03,560 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,561 - INFO - Processing job ID: j3bb38\n2025-02-02 11:10:03,561 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,563 - INFO - Processing job ID: j35c38\n2025-02-02 11:10:03,563 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,564 - INFO - Processing job ID: jca207\n2025-02-02 11:10:03,564 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,565 - INFO - Processing job ID: jcda25\n2025-02-02 11:10:03,566 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,567 - INFO - Processing job ID: j950c8\n2025-02-02 11:10:03,568 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,568 - INFO - Processing job ID: j3a057\n2025-02-02 11:10:03,569 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,569 - INFO - Processing job ID: j47f94\n2025-02-02 11:10:03,570 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,571 - INFO - Processing job ID: j1fa13\n2025-02-02 11:10:03,571 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,572 - INFO - Processing job ID: jf2b8d\n2025-02-02 11:10:03,572 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,573 - INFO - Processing job ID: j4380a\n2025-02-02 11:10:03,573 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,574 - INFO - Processing job ID: j2943e\n2025-02-02 11:10:03,576 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,577 - INFO - Processing job ID: jd7d69\n2025-02-02 11:10:03,578 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,578 - INFO - Processing job ID: j05805\n2025-02-02 11:10:03,579 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,580 - INFO - Processing job ID: j18699\n2025-02-02 11:10:03,580 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,581 - INFO - Processing job ID: j1c200\n2025-02-02 11:10:03,581 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,582 - INFO - Processing job ID: jb3fa4\n2025-02-02 11:10:03,582 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,583 - INFO - Processing job ID: je89b6\n2025-02-02 11:10:03,584 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,587 - INFO - Processing job ID: jea4bf\n2025-02-02 11:10:03,588 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,588 - INFO - Processing job ID: ja381c\n2025-02-02 11:10:03,589 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,589 - INFO - Processing job ID: j0c5e0\n2025-02-02 11:10:03,590 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,590 - INFO - Processing job ID: j587fb\n2025-02-02 11:10:03,591 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,591 - INFO - Processing job ID: j9a68d\n2025-02-02 11:10:03,592 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,592 - INFO - Processing job ID: jd839e\n2025-02-02 11:10:03,592 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,593 - INFO - Processing job ID: j6fc3a\n2025-02-02 11:10:03,594 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,595 - INFO - Processing job ID: je38db\n2025-02-02 11:10:03,595 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,596 - INFO - Processing job ID: j1c235\n2025-02-02 11:10:03,596 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,597 - INFO - Processing job ID: jb13d0\n2025-02-02 11:10:03,597 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,597 - INFO - Processing job ID: jf1cb5\n2025-02-02 11:10:03,598 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,598 - INFO - Processing job ID: j2dd0d\n2025-02-02 11:10:03,599 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,599 - INFO - Processing job ID: jf88b8\n2025-02-02 11:10:03,600 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,600 - INFO - Processing job ID: ja4844\n2025-02-02 11:10:03,602 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,603 - INFO - Processing job ID: j94120\n2025-02-02 11:10:03,603 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,604 - INFO - Processing job ID: j9c977\n2025-02-02 11:10:03,604 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,605 - INFO - Processing job ID: jc5113\n2025-02-02 11:10:03,605 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,606 - INFO - Processing job ID: j02aa2\n2025-02-02 11:10:03,606 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,606 - INFO - Processing job ID: ja4f18\n2025-02-02 11:10:03,607 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,607 - INFO - Processing job ID: jca609\n2025-02-02 11:10:03,607 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,608 - INFO - Processing job ID: j83ace\n2025-02-02 11:10:03,608 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,609 - INFO - Processing job ID: j5f657\n2025-02-02 11:10:03,609 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,609 - INFO - Processing job ID: j8867b\n2025-02-02 11:10:03,610 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,610 - INFO - Processing job ID: j9014b\n2025-02-02 11:10:03,610 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,610 - INFO - Processing job ID: ja9b01\n2025-02-02 11:10:03,611 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,611 - INFO - Processing job ID: j17e39\n2025-02-02 11:10:03,612 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,612 - INFO - Processing job ID: ja3bdc\n2025-02-02 11:10:03,612 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,613 - INFO - Processing job ID: jfde04\n2025-02-02 11:10:03,613 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,613 - INFO - Processing job ID: jb4c73\n2025-02-02 11:10:03,614 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,614 - INFO - Processing job ID: j02c97\n2025-02-02 11:10:03,614 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,615 - INFO - Processing job ID: jb0f36\n2025-02-02 11:10:03,616 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,617 - INFO - Processing job ID: j686b8\n2025-02-02 11:10:03,617 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,618 - INFO - Processing job ID: jd2eb7\n2025-02-02 11:10:03,618 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,619 - INFO - Processing job ID: j3214f\n2025-02-02 11:10:03,619 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,620 - INFO - Processing job ID: j11255\n2025-02-02 11:10:03,620 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,621 - INFO - Processing job ID: jbadd8\n2025-02-02 11:10:03,621 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,622 - INFO - Processing job ID: jcdb10\n2025-02-02 11:10:03,623 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,623 - INFO - Processing job ID: jf2227\n2025-02-02 11:10:03,624 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,624 - INFO - Processing job ID: je5297\n2025-02-02 11:10:03,625 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,626 - INFO - Processing job ID: jddf63\n2025-02-02 11:10:03,626 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,627 - INFO - Processing job ID: j96f54\n2025-02-02 11:10:03,627 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,628 - INFO - Processing job ID: jd14ef\n2025-02-02 11:10:03,628 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,629 - INFO - Processing job ID: jc3bc5\n2025-02-02 11:10:03,629 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,630 - INFO - Processing job ID: j24436\n2025-02-02 11:10:03,630 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,630 - INFO - Processing job ID: j7f84d\n2025-02-02 11:10:03,631 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,631 - INFO - Processing job ID: j2c41f\n2025-02-02 11:10:03,632 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,632 - INFO - Processing job ID: j0c39c\n2025-02-02 11:10:03,633 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,634 - INFO - Processing job ID: jbe8e9\n2025-02-02 11:10:03,634 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,635 - INFO - Processing job ID: j93375\n2025-02-02 11:10:03,635 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,636 - INFO - Processing job ID: jabd9c\n2025-02-02 11:10:03,636 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,637 - INFO - Processing job ID: j7af7f\n2025-02-02 11:10:03,637 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,637 - INFO - Processing job ID: j258ec\n2025-02-02 11:10:03,638 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,638 - INFO - Processing job ID: j310f7\n2025-02-02 11:10:03,639 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,639 - INFO - Processing job ID: jfa37c\n2025-02-02 11:10:03,640 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,640 - INFO - Processing job ID: j1fbbe\n2025-02-02 11:10:03,641 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,641 - INFO - Processing job ID: j35139\n2025-02-02 11:10:03,641 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,642 - INFO - Processing job ID: jb593a\n2025-02-02 11:10:03,642 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,643 - INFO - Processing job ID: j537cf\n2025-02-02 11:10:03,643 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,645 - INFO - Processing job ID: j53629\n2025-02-02 11:10:03,645 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,645 - INFO - Processing job ID: j523af\n2025-02-02 11:10:03,650 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,650 - INFO - Processing job ID: j22da7\n2025-02-02 11:10:03,651 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,651 - INFO - Processing job ID: j4a946\n2025-02-02 11:10:03,652 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,653 - INFO - Processing job ID: j3889f\n2025-02-02 11:10:03,653 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,654 - INFO - Processing job ID: j15644\n2025-02-02 11:10:03,654 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,654 - INFO - Processing job ID: j4d1b2\n2025-02-02 11:10:03,655 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,655 - INFO - Processing job ID: jb3681\n2025-02-02 11:10:03,655 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,656 - INFO - Processing job ID: j6c719\n2025-02-02 11:10:03,656 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,656 - INFO - Processing job ID: jc126c\n2025-02-02 11:10:03,657 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,657 - INFO - Processing job ID: j3eae1\n2025-02-02 11:10:03,658 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,658 - INFO - Processing job ID: j8a5b6\n2025-02-02 11:10:03,658 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,659 - INFO - Processing job ID: j62e39\n2025-02-02 11:10:03,659 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,660 - INFO - Processing job ID: j14e04\n2025-02-02 11:10:03,660 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,661 - INFO - Processing job ID: j906b1\n2025-02-02 11:10:03,661 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,661 - INFO - Processing job ID: j777eb\n2025-02-02 11:10:03,662 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,664 - INFO - Processing job ID: j88a0a\n2025-02-02 11:10:03,665 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,666 - INFO - Processing job ID: j7bbdf\n2025-02-02 11:10:03,666 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,667 - INFO - Processing job ID: j2d412\n2025-02-02 11:10:03,667 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,668 - INFO - Processing job ID: je960a\n2025-02-02 11:10:03,668 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,668 - INFO - Processing job ID: j3d430\n2025-02-02 11:10:03,669 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,669 - INFO - Processing job ID: je32c7\n2025-02-02 11:10:03,670 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,670 - INFO - Processing job ID: ja62ac\n2025-02-02 11:10:03,671 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,673 - INFO - Processing job ID: j9d487\n2025-02-02 11:10:03,674 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,675 - INFO - Processing job ID: jbd69b\n2025-02-02 11:10:03,675 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,676 - INFO - Processing job ID: j7e506\n2025-02-02 11:10:03,676 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,677 - INFO - Processing job ID: je099a\n2025-02-02 11:10:03,678 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,679 - INFO - Processing job ID: jdeb7c\n2025-02-02 11:10:03,680 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,681 - INFO - Processing job ID: jef5a5\n2025-02-02 11:10:03,681 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,683 - INFO - Processing job ID: je55fe\n2025-02-02 11:10:03,683 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,684 - INFO - Processing job ID: jd2ff3\n2025-02-02 11:10:03,685 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,685 - INFO - Processing job ID: jdc467\n2025-02-02 11:10:03,686 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,687 - INFO - Processing job ID: j5200a\n2025-02-02 11:10:03,688 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,688 - INFO - Processing job ID: je5e1f\n2025-02-02 11:10:03,690 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,690 - INFO - Processing job ID: jd04b0\n2025-02-02 11:10:03,691 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,691 - INFO - Processing job ID: jbf8a5\n2025-02-02 11:10:03,692 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,693 - INFO - Processing job ID: j20cfa\n2025-02-02 11:10:03,693 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,695 - INFO - Processing job ID: j4ee58\n2025-02-02 11:10:03,695 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,696 - INFO - Processing job ID: j3e4ab\n2025-02-02 11:10:03,696 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,697 - INFO - Processing job ID: j46983\n2025-02-02 11:10:03,697 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,698 - INFO - Processing job ID: j1ee25\n2025-02-02 11:10:03,698 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,699 - INFO - Processing job ID: jef846\n2025-02-02 11:10:03,700 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,700 - INFO - Processing job ID: j59a66\n2025-02-02 11:10:03,703 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,704 - INFO - Processing job ID: jb10ca\n2025-02-02 11:10:03,705 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,705 - INFO - Processing job ID: j6bee0\n2025-02-02 11:10:03,706 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,707 - INFO - Processing job ID: j09678\n2025-02-02 11:10:03,708 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,708 - INFO - Processing job ID: j5d37c\n2025-02-02 11:10:03,709 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,709 - INFO - Processing job ID: jf8144\n2025-02-02 11:10:03,710 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,710 - INFO - Processing job ID: j10c1a\n2025-02-02 11:10:03,711 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,711 - INFO - Processing job ID: j56762\n2025-02-02 11:10:03,712 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,712 - INFO - Processing job ID: j5115c\n2025-02-02 11:10:03,713 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,713 - INFO - Processing job ID: jf7b23\n2025-02-02 11:10:03,714 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,715 - INFO - Processing job ID: j948e7\n2025-02-02 11:10:03,715 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,716 - INFO - Processing job ID: jb81a4\n2025-02-02 11:10:03,716 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,717 - INFO - Processing job ID: j0fe47\n2025-02-02 11:10:03,718 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,721 - INFO - Processing job ID: j3c25d\n2025-02-02 11:10:03,721 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,722 - INFO - Processing job ID: j3a9f6\n2025-02-02 11:10:03,723 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,724 - INFO - Processing job ID: jdf351\n2025-02-02 11:10:03,725 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,725 - INFO - Processing job ID: j78ad0\n2025-02-02 11:10:03,726 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,727 - INFO - Processing job ID: j6d7c4\n2025-02-02 11:10:03,728 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,729 - INFO - Processing job ID: j8fc13\n2025-02-02 11:10:03,729 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,731 - INFO - Processing job ID: j595d0\n2025-02-02 11:10:03,731 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,732 - INFO - Processing job ID: je24f8\n2025-02-02 11:10:03,733 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,733 - INFO - Processing job ID: j91b3d\n2025-02-02 11:10:03,734 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,735 - INFO - Processing job ID: j9f466\n2025-02-02 11:10:03,736 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,736 - INFO - Processing job ID: jc6209\n2025-02-02 11:10:03,737 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,737 - INFO - Processing job ID: j04091\n2025-02-02 11:10:03,738 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,738 - INFO - Processing job ID: jcbd72\n2025-02-02 11:10:03,739 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,740 - INFO - Processing job ID: j47929\n2025-02-02 11:10:03,740 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,742 - INFO - Processing job ID: j982b9\n2025-02-02 11:10:03,743 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,744 - INFO - Processing job ID: j40fe4\n2025-02-02 11:10:03,744 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,745 - INFO - Processing job ID: j3f682\n2025-02-02 11:10:03,745 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,746 - INFO - Processing job ID: jaa44d\n2025-02-02 11:10:03,746 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,747 - INFO - Processing job ID: jc0974\n2025-02-02 11:10:03,747 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,748 - INFO - Processing job ID: j6ce7b\n2025-02-02 11:10:03,748 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,749 - INFO - Processing job ID: jdff44\n2025-02-02 11:10:03,750 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,751 - INFO - Processing job ID: jc6043\n2025-02-02 11:10:03,751 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,752 - INFO - Processing job ID: j562e0\n2025-02-02 11:10:03,752 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,753 - INFO - Processing job ID: jdeb9e\n2025-02-02 11:10:03,753 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,754 - INFO - Processing job ID: jf00fc\n2025-02-02 11:10:03,754 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,755 - INFO - Processing job ID: jea6de\n2025-02-02 11:10:03,755 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,756 - INFO - Processing job ID: jfb5d1\n2025-02-02 11:10:03,756 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,759 - INFO - Processing job ID: jad31a\n2025-02-02 11:10:03,760 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,760 - INFO - Processing job ID: j19f63\n2025-02-02 11:10:03,760 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,761 - INFO - Processing job ID: j4c6b3\n2025-02-02 11:10:03,761 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,762 - INFO - Processing job ID: j0d87b\n2025-02-02 11:10:03,762 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,763 - INFO - Processing job ID: j1376b\n2025-02-02 11:10:03,763 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,764 - INFO - Processing job ID: j434b1\n2025-02-02 11:10:03,764 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,765 - INFO - Processing job ID: jbd069\n2025-02-02 11:10:03,765 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,766 - INFO - Processing job ID: jb815d\n2025-02-02 11:10:03,766 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,767 - INFO - Processing job ID: j6e481\n2025-02-02 11:10:03,767 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,768 - INFO - Processing job ID: j9f22f\n2025-02-02 11:10:03,768 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,769 - INFO - Processing job ID: jcdccd\n2025-02-02 11:10:03,769 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,770 - INFO - Processing job ID: jbf26b\n2025-02-02 11:10:03,770 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,771 - INFO - Processing job ID: j9243b\n2025-02-02 11:10:03,771 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,775 - INFO - Processing job ID: j7fc84\n2025-02-02 11:10:03,775 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,776 - INFO - Processing job ID: j92415\n2025-02-02 11:10:03,777 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,777 - INFO - Processing job ID: j9c682\n2025-02-02 11:10:03,777 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,778 - INFO - Processing job ID: j6a660\n2025-02-02 11:10:03,778 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,779 - INFO - Processing job ID: j3b5b4\n2025-02-02 11:10:03,779 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,780 - INFO - Processing job ID: j7a1b5\n2025-02-02 11:10:03,780 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,781 - INFO - Processing job ID: jaf5ce\n2025-02-02 11:10:03,781 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,781 - INFO - Processing job ID: jcee43\n2025-02-02 11:10:03,782 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,782 - INFO - Processing job ID: j82713\n2025-02-02 11:10:03,783 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,783 - INFO - Processing job ID: ja1048\n2025-02-02 11:10:03,787 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,787 - INFO - Processing job ID: j8e76a\n2025-02-02 11:10:03,788 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,788 - INFO - Processing job ID: jf5378\n2025-02-02 11:10:03,789 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,789 - INFO - Processing job ID: j9d67e\n2025-02-02 11:10:03,789 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,790 - INFO - Processing job ID: jc3eee\n2025-02-02 11:10:03,790 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,791 - INFO - Processing job ID: j62dff\n2025-02-02 11:10:03,791 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,792 - INFO - Processing job ID: jb3cd2\n2025-02-02 11:10:03,792 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,792 - INFO - Processing job ID: jd5538\n2025-02-02 11:10:03,793 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,793 - INFO - Processing job ID: jd766e\n2025-02-02 11:10:03,794 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,794 - INFO - Processing job ID: jd34e4\n2025-02-02 11:10:03,794 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,795 - INFO - Processing job ID: j450f6\n2025-02-02 11:10:03,795 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,796 - INFO - Processing job ID: j49c38\n2025-02-02 11:10:03,796 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,797 - INFO - Processing job ID: j412f7\n2025-02-02 11:10:03,797 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,801 - INFO - Processing job ID: j1e9f0\n2025-02-02 11:10:03,802 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,803 - INFO - Processing job ID: j3648f\n2025-02-02 11:10:03,803 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,804 - INFO - Processing job ID: j98d06\n2025-02-02 11:10:03,804 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,805 - INFO - Processing job ID: j2b3b1\n2025-02-02 11:10:03,806 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,806 - INFO - Processing job ID: jf11f7\n2025-02-02 11:10:03,807 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,807 - INFO - Processing job ID: j150df\n2025-02-02 11:10:03,807 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,808 - INFO - Processing job ID: jc5ab8\n2025-02-02 11:10:03,808 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,808 - INFO - Processing job ID: jcefd3\n2025-02-02 11:10:03,809 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,809 - INFO - Processing job ID: j69044\n2025-02-02 11:10:03,810 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,810 - INFO - Processing job ID: j3fc98\n2025-02-02 11:10:03,810 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,811 - INFO - Processing job ID: j6d232\n2025-02-02 11:10:03,811 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,812 - INFO - Processing job ID: ja717e\n2025-02-02 11:10:03,812 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,812 - INFO - Processing job ID: j3a75a\n2025-02-02 11:10:03,813 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,813 - INFO - Processing job ID: j14fbc\n2025-02-02 11:10:03,816 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,817 - INFO - Processing job ID: jbb918\n2025-02-02 11:10:03,818 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,818 - INFO - Processing job ID: j3ee88\n2025-02-02 11:10:03,819 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,820 - INFO - Processing job ID: j763ff\n2025-02-02 11:10:03,820 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,821 - INFO - Processing job ID: ja4b4c\n2025-02-02 11:10:03,821 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,821 - INFO - Processing job ID: jfa186\n2025-02-02 11:10:03,822 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,822 - INFO - Processing job ID: j695d0\n2025-02-02 11:10:03,823 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,823 - INFO - Processing job ID: j1557b\n2025-02-02 11:10:03,823 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,824 - INFO - Processing job ID: j1f101\n2025-02-02 11:10:03,826 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,826 - INFO - Processing job ID: jcb0b5\n2025-02-02 11:10:03,826 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,827 - INFO - Processing job ID: j6b89a\n2025-02-02 11:10:03,827 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,828 - INFO - Processing job ID: j8a54a\n2025-02-02 11:10:03,828 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,828 - INFO - Processing job ID: jf9560\n2025-02-02 11:10:03,829 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,829 - INFO - Processing job ID: ja0cf5\n2025-02-02 11:10:03,830 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,830 - INFO - Processing job ID: j72696\n2025-02-02 11:10:03,830 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,831 - INFO - Processing job ID: jf2243\n2025-02-02 11:10:03,831 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,831 - INFO - Processing job ID: jd26be\n2025-02-02 11:10:03,832 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,832 - INFO - Processing job ID: ja12d9\n2025-02-02 11:10:03,833 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,833 - INFO - Processing job ID: j6ae8f\n2025-02-02 11:10:03,836 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,836 - INFO - Processing job ID: je639d\n2025-02-02 11:10:03,836 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,837 - INFO - Processing job ID: j996f5\n2025-02-02 11:10:03,837 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,837 - INFO - Processing job ID: j75c6f\n2025-02-02 11:10:03,838 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,838 - INFO - Processing job ID: jff24f\n2025-02-02 11:10:03,839 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:03,839 - INFO - Processing job ID: jce17f\n2025-02-02 11:10:03,843 - ERROR - Error extracting job details: 'responsibilities'\n2025-02-02 11:10:07,770 - INFO - Saved classification for job j910b7\n2025-02-02 11:10:07,771 - INFO - Classifying job 'j03a44'\n2025-02-02 11:10:07,812 - INFO - Saved classification for job j542d8\n2025-02-02 11:10:07,813 - INFO - Classifying job 'j445e9'\n2025-02-02 11:10:07,850 - INFO - Saved classification for job j0b848\n2025-02-02 11:10:07,851 - INFO - Classifying job 'j1a69d'\n\n\n\nProcessing complete:\n- New jobs processed: 402\n- Skipped jobs (already processed): 750\n\n\n2025-02-02 11:10:19,428 - INFO - Saved classification for job j445e9\n2025-02-02 11:10:19,428 - INFO - Classifying job 'jad973'\n2025-02-02 11:10:20,631 - INFO - Saved classification for job j1a69d\n2025-02-02 11:10:20,631 - INFO - Classifying job 'j13a46'\n2025-02-02 11:10:21,584 - INFO - Saved classification for job j03a44\n2025-02-02 11:10:21,587 - INFO - Classifying job 'j65e37'\n2025-02-02 11:10:36,111 - INFO - Saved classification for job j65e37\n2025-02-02 11:10:36,111 - INFO - Classifying job 'j4b5d3'\n2025-02-02 11:10:37,453 - INFO - Saved classification for job j13a46\n2025-02-02 11:10:37,455 - INFO - Classifying job 'jf88d5'\n2025-02-02 11:10:52,510 - INFO - Saved classification for job jf88d5\n2025-02-02 11:10:52,511 - INFO - Classifying job 'j9bed6'\n2025-02-02 11:10:53,698 - INFO - Saved classification for job j4b5d3\n2025-02-02 11:10:53,699 - INFO - Classifying job 'j37544'\n2025-02-02 11:10:57,238 - INFO - Saved classification for job jad973\n2025-02-02 11:10:57,239 - INFO - Classifying job 'j5fc51'\n2025-02-02 11:11:06,329 - INFO - Saved classification for job j9bed6\n2025-02-02 11:11:06,329 - INFO - Classifying job 'jc9f2e'\n2025-02-02 11:11:07,583 - INFO - Saved classification for job j37544\n2025-02-02 11:11:07,584 - INFO - Classifying job 'j022db'\n2025-02-02 11:11:08,570 - INFO - Saved classification for job j5fc51\n2025-02-02 11:11:08,570 - INFO - Classifying job 'j8c176'\n2025-02-02 11:11:19,684 - INFO - Saved classification for job jc9f2e\n2025-02-02 11:11:19,685 - INFO - Classifying job 'j14012'\n2025-02-02 11:11:21,624 - INFO - Saved classification for job j022db\n2025-02-02 11:11:21,624 - INFO - Classifying job 'j7b0af'\n2025-02-02 11:11:24,198 - INFO - Saved classification for job j8c176\n2025-02-02 11:11:24,199 - INFO - Classifying job 'j70e10'\n2025-02-02 11:11:31,049 - INFO - Saved classification for job j7b0af\n2025-02-02 11:11:31,049 - INFO - Classifying job 'j04898'\n2025-02-02 11:11:36,686 - INFO - Saved classification for job j14012\n2025-02-02 11:11:36,687 - INFO - Classifying job 'j220d9'\n2025-02-02 11:11:40,058 - INFO - Saved classification for job j70e10\n2025-02-02 11:11:40,059 - INFO - Classifying job 'jd31c6'\n2025-02-02 11:11:43,576 - INFO - Saved classification for job j04898\n2025-02-02 11:11:43,578 - INFO - Classifying job 'j8f1d4'\n2025-02-02 11:11:52,052 - INFO - Saved classification for job j220d9\n2025-02-02 11:11:52,052 - INFO - Classifying job 'j3174e'\n2025-02-02 11:11:55,013 - INFO - Saved classification for job j8f1d4\n2025-02-02 11:11:55,014 - INFO - Classifying job 'j99c64'\n2025-02-02 11:11:58,609 - INFO - Saved classification for job jd31c6\n2025-02-02 11:11:58,610 - INFO - Classifying job 'jf16d4'\n2025-02-02 11:12:05,280 - INFO - Saved classification for job j3174e\n2025-02-02 11:12:05,280 - INFO - Classifying job 'j6505d'\n2025-02-02 11:12:06,232 - INFO - Saved classification for job j99c64\n2025-02-02 11:12:06,233 - INFO - Classifying job 'jd6b14'\n2025-02-02 11:12:12,121 - INFO - Saved classification for job jf16d4\n2025-02-02 11:12:12,121 - INFO - Classifying job 'jef120'\n2025-02-02 11:12:18,541 - INFO - Saved classification for job j6505d\n2025-02-02 11:12:18,542 - INFO - Classifying job 'j3eca8'\n2025-02-02 11:12:20,232 - INFO - Saved classification for job jd6b14\n2025-02-02 11:12:20,234 - INFO - Classifying job 'j16a45'\n2025-02-02 11:12:23,524 - INFO - Saved classification for job jef120\n2025-02-02 11:12:23,524 - INFO - Classifying job 'j8ab08'\n2025-02-02 11:12:30,380 - INFO - Saved classification for job j3eca8\n2025-02-02 11:12:30,380 - INFO - Classifying job 'j39805'\n2025-02-02 11:12:30,569 - INFO - Saved classification for job j16a45\n2025-02-02 11:12:30,570 - INFO - Classifying job 'j3b1b4'\n2025-02-02 11:12:35,286 - INFO - Saved classification for job j8ab08\n2025-02-02 11:12:41,424 - INFO - Saved classification for job j3b1b4\n2025-02-02 11:12:45,197 - INFO - Saved classification for job j39805\n2025-02-02 11:12:45,198 - INFO - Job classification complete"
  },
  {
    "objectID": "unknown/index.html#o1-generated-senior-ai-research-scientist",
    "href": "unknown/index.html#o1-generated-senior-ai-research-scientist",
    "title": "Analysis of the GenAI/LLM job market in January 2025",
    "section": "o1-generated Senior AI Research Scientist",
    "text": "o1-generated Senior AI Research Scientist\nHere’s what o1 said about the Responsibilities and Skills observed in Senior AI Research Scientist roles:\n\nResponsibilities\n\nConduct advanced AI research\nMany roles require pushing the state-of-the-art in Generative AI, LLMs, and related areas (e.g., video/multimodal models, diffusion models) through novel algorithms, architectures, and experimental studies.\nTrain and fine-tune large-scale models\nCommonly involves working with massive datasets and distributed training setups (thousands of GPUs, HPC environments) to develop foundation models and advanced AI systems.\nDevelop and implement new algorithms or architectures\nSpans designing novel model architectures (e.g., diffusion, transformer-based, multimodal fusion) and creating robust data processing or simulation pipelines to support AI solutions.\nCollaborate with cross-functional teams\nEmphasizes close work with engineering, product management, research, and external stakeholders to integrate AI breakthroughs into real-world applications and products.\nEvaluate and measure AI performance\nEntails building rigorous evaluation frameworks, designing new metrics, and systematically analyzing model behavior to ensure quality and reliability.\nPublish and communicate research findings\nMany positions highlight writing influential papers, presenting at conferences, and sharing innovative results both internally and with the broader AI community.\nBuild and maintain data pipelines\nInvolves constructing high-quality, scalable data pipelines or tooling to support training, fine-tuning, and inference of large models.\nEnsure production-grade implementation\nRequires writing clean, efficient, and maintainable code as well as optimizing models and pipelines to meet performance, reliability, and quality standards.\n\n\n\nSkills\n\nProficiency in Python and deep learning frameworks\nStrong coding skills in Python and hands-on experience with libraries such as PyTorch, TensorFlow, or JAX appear in nearly every role.\nExpertise with LLMs and Generative AI\nDeep understanding of transformer architectures, diffusion models, multimodal systems, prompt engineering, and other advanced AI techniques is frequently mentioned.\nExperience with large-scale/distributed training\nMany roles emphasize knowledge of HPC, GPU optimization, model parallelism (e.g., FSDP, DeepSpeed, Megatron-LM), and handling massive datasets.\nStrong software engineering practices\nTesting, code review, debugging, version control, and producing clean, modular research or production code are consistently important.\nCollaboration and communication skills\nClear written and verbal communication, along with cross-functional teamwork, is vital for integrating AI solutions into products and relaying complex ideas.\nResearch acumen and adaptability\nAbility to read, interpret, and prototype cutting-edge AI literature, publish findings, and rapidly iterate on experiments.\nMachine Learning fundamentals\nSolid grounding in ML theory (e.g., optimization, statistics, data structures) and experience with model evaluation, data manipulation, and pipeline design.\nFamiliarity with prompt engineering and advanced NLP concepts\nMany roles highlight crafting effective prompts, aligning model outputs with user needs, and leveraging text-generation or conversational AI techniques."
  },
  {
    "objectID": "unknown/index.html#o1-generated-senior-ai-ml-engineer",
    "href": "unknown/index.html#o1-generated-senior-ai-ml-engineer",
    "title": "Analysis of the GenAI/LLM job market in January 2025",
    "section": "o1-generated Senior AI ML Engineer",
    "text": "o1-generated Senior AI ML Engineer\nAnd here’s what o1 said about the Responsibilities and Skills observed in Senior AI ML Engineer roles:\n\nResponsibilities\n\nDesign, develop, and deploy AI/ML solutions\nEnd-to-end creation of machine learning systems, from initial prototypes to production-ready deployments.\nCollaborate with cross-functional teams\nWork closely with product managers, data scientists, engineers, and other stakeholders to align technical solutions with business goals.\nMonitor and optimize model performance\nTrack key metrics, fine-tune models, and iterate to ensure continuous improvement and reliability in production.\nStay current with AI research and emerging technologies\nKeep up-to-date with the latest breakthroughs in areas like LLMs, generative AI, and deep learning.\nMentor and coach team members\nProvide guidance on best practices, design patterns, code quality, and career development for junior or peer engineers.\nDevelop scalable data/ML pipelines\nBuild robust infrastructure for data collection, preprocessing, model training, and deployment at scale.\nImplement and maintain CI/CD and coding best practices\nEnsure code quality, streamline release processes, and enforce testing discipline for AI/ML components.\nIntegrate and leverage LLMs/generative AI\nIncorporate large language models or generative methods into products and workflows.\nPrototype and experiment\nConduct R&D, proof-of-concepts, and pilot programs to explore emerging AI techniques and validate new product ideas.\nDocument and communicate findings\nProduce clear technical documentation, share results with stakeholders, and provide actionable insights for decision-making.\n\n\n\nSkills\n\nProficiency in Python\nCommonly required for AI/ML development, data manipulation, and scripting.\nExperience with ML/DL frameworks\nHands-on expertise in tools like PyTorch, TensorFlow, or JAX for building and training models.\nFamiliarity with cloud platforms\nWorking knowledge of AWS, GCP, or Azure for deploying and scaling AI solutions.\nExpertise in LLMs/generative AI\nUnderstanding of transformer architectures, prompt engineering, retrieval-augmented generation (RAG), and related libraries.\nStrong software engineering fundamentals\nSolid grasp of algorithms, data structures, design patterns, and best practices for production code.\nKnowledge of MLOps and CI/CD\nExperience with containerization (Docker, Kubernetes), version control (Git), and automated testing/monitoring.\nData processing and SQL\nSkills in handling large datasets, working with Spark or similar frameworks, and writing performant SQL queries.\nEffective communication and collaboration\nAbility to translate complex technical concepts for non-technical stakeholders and work well in diverse teams.\nProblem-solving and debugging\nTrack record of diagnosing issues in production environments and implementing reliable fixes.\nContinuous learning mindset\nEagerness to stay on top of new AI research, frameworks, and technologies to innovate and improve solutions."
  },
  {
    "objectID": "research/articles/wood-et-al-2018/index.html",
    "href": "research/articles/wood-et-al-2018/index.html",
    "title": "Reasons for sex and relational outcomes in consensually nonmonogamous and monogamous relationships: A self-determination theory approach",
    "section": "",
    "text": "Approximately 4% of individuals in North America participate in consensually nonmonogamous (CNM) relationships, wherein all partners have agreed to additional sexual and/or emotional partnerships. The CNM relationships are stigmatized and viewed as less stable and satisfying than monogamous relationships, a perception that persists despite research evidence. In our study, we assess the legitimacy of this negative perception by using a self-determination theory (SDT) framework to explore how sexual motivation impacts relational and sexual satisfaction among CNM and monogamous participants in romantic relationships. A total of 348 CNM (n = 142) and monogamous participants (n = 206) were recruited from Amazon’s Mechanical Turk (MTurk. (2016). www.mturk.com) to complete a cross-sectional survey. Participants reported on their sexual motivations during their most recent sexual event, their level of sexual need fulfillment, and measures of sexual and relational satisfaction with their current (primary) partner. The CNM and monogamous participants reported similar reasons for engaging in sex, though CNM participants were significantly more likely to have sex for personal intrinsic motives. No differences in mean levels of relationship and sexual satisfaction were found between CNM and monogamous individuals. Participants who engaged in sex for more self-determined reasons reported increased relational and sexual satisfaction. This relationship was mediated by sexual need fulfillment; participants who reported more self-determined motives reported higher levels of need fulfillment and, in turn, greater relationship and sexual satisfaction. This study indicates that CNM and monogamous individuals report similar levels of satisfaction within their relationship(s) and that the mechanisms that affect relational and sexual satisfaction are similar for both CNM and monogamous individuals. Our research extends theoretical understandings of motivation within romantic relationships and suggests that SDT is a useful framework for considering the impact of sexual motivation on relational outcomes."
  },
  {
    "objectID": "research/articles/wood-et-al-2018/index.html#abstract",
    "href": "research/articles/wood-et-al-2018/index.html#abstract",
    "title": "Reasons for sex and relational outcomes in consensually nonmonogamous and monogamous relationships: A self-determination theory approach",
    "section": "",
    "text": "Approximately 4% of individuals in North America participate in consensually nonmonogamous (CNM) relationships, wherein all partners have agreed to additional sexual and/or emotional partnerships. The CNM relationships are stigmatized and viewed as less stable and satisfying than monogamous relationships, a perception that persists despite research evidence. In our study, we assess the legitimacy of this negative perception by using a self-determination theory (SDT) framework to explore how sexual motivation impacts relational and sexual satisfaction among CNM and monogamous participants in romantic relationships. A total of 348 CNM (n = 142) and monogamous participants (n = 206) were recruited from Amazon’s Mechanical Turk (MTurk. (2016). www.mturk.com) to complete a cross-sectional survey. Participants reported on their sexual motivations during their most recent sexual event, their level of sexual need fulfillment, and measures of sexual and relational satisfaction with their current (primary) partner. The CNM and monogamous participants reported similar reasons for engaging in sex, though CNM participants were significantly more likely to have sex for personal intrinsic motives. No differences in mean levels of relationship and sexual satisfaction were found between CNM and monogamous individuals. Participants who engaged in sex for more self-determined reasons reported increased relational and sexual satisfaction. This relationship was mediated by sexual need fulfillment; participants who reported more self-determined motives reported higher levels of need fulfillment and, in turn, greater relationship and sexual satisfaction. This study indicates that CNM and monogamous individuals report similar levels of satisfaction within their relationship(s) and that the mechanisms that affect relational and sexual satisfaction are similar for both CNM and monogamous individuals. Our research extends theoretical understandings of motivation within romantic relationships and suggests that SDT is a useful framework for considering the impact of sexual motivation on relational outcomes."
  },
  {
    "objectID": "research/articles/sparks-et-al-2016/index.html",
    "href": "research/articles/sparks-et-al-2016/index.html",
    "title": "We can see inside: Accurate prediction of Prisoner’s Dilemma decisions in announced games following a face-to-face interaction",
    "section": "",
    "text": "Humans form impressions and make social judgments about others based on information that is quickly and easily available, such as facial and vocal traits. The evolutionary function of impression formation and social judgment mechanisms have received limited attention in psychology research; we argue that their function is to accurately forecast the behavior of others. There is some evidence for the predictive accuracy of social judgments, but much of it comes from situations where there is little incentive to deceive, which limits applicability to questions of the function of such mechanisms. A classic experiment that avoids this problem was conducted by R. H. Frank, T. Gilovich, and D. T. Regan (1993); their participants predicted each other’s Prisoner’s Dilemma Game decisions with above-chance accuracy after a short interaction period, knowing the game would follow. We report three original studies that replicate these aspects of the methods of Frank et al. (1993) and reanalyze data from all known replications. Our meta-analysis of these studies confirms the original report: humans can predict each other’s Prisoner’s Dilemma decisions after a brief interaction with people who have incentive to deceive."
  },
  {
    "objectID": "research/articles/sparks-et-al-2016/index.html#abstract",
    "href": "research/articles/sparks-et-al-2016/index.html#abstract",
    "title": "We can see inside: Accurate prediction of Prisoner’s Dilemma decisions in announced games following a face-to-face interaction",
    "section": "",
    "text": "Humans form impressions and make social judgments about others based on information that is quickly and easily available, such as facial and vocal traits. The evolutionary function of impression formation and social judgment mechanisms have received limited attention in psychology research; we argue that their function is to accurately forecast the behavior of others. There is some evidence for the predictive accuracy of social judgments, but much of it comes from situations where there is little incentive to deceive, which limits applicability to questions of the function of such mechanisms. A classic experiment that avoids this problem was conducted by R. H. Frank, T. Gilovich, and D. T. Regan (1993); their participants predicted each other’s Prisoner’s Dilemma Game decisions with above-chance accuracy after a short interaction period, knowing the game would follow. We report three original studies that replicate these aspects of the methods of Frank et al. (1993) and reanalyze data from all known replications. Our meta-analysis of these studies confirms the original report: humans can predict each other’s Prisoner’s Dilemma decisions after a brief interaction with people who have incentive to deceive."
  },
  {
    "objectID": "research/articles/sparks-et-al-2016/index.html#important-figure",
    "href": "research/articles/sparks-et-al-2016/index.html#important-figure",
    "title": "We can see inside: Accurate prediction of Prisoner’s Dilemma decisions in announced games following a face-to-face interaction",
    "section": "Important figure",
    "text": "Important figure\n\n\n\nFig. 1. Forest plot—marker size indicates a study’s weight in the combined estimate."
  },
  {
    "objectID": "research/articles/schoenherr-burleigh-2015/index.html",
    "href": "research/articles/schoenherr-burleigh-2015/index.html",
    "title": "Uncanny sociocultural categories",
    "section": "",
    "text": "Considered individually, folkbiological categories, biological anomalies and monsters, as well as human categories represent individual cultural products of human categorization. Instead, we suggest that the uncanny valley might reflect a primary response to unfamiliar or covert categories. In the absence of having prior knowledge of an individual or group, the relative distinctiveness of a category, due to a lower frequency of exposure, will produce negative affect—an inversion of the mere-exposure effect. The deceptive simplicity of learning mechanisms can lead to important individual and social consequences."
  },
  {
    "objectID": "research/articles/schoenherr-burleigh-2015/index.html#abstract",
    "href": "research/articles/schoenherr-burleigh-2015/index.html#abstract",
    "title": "Uncanny sociocultural categories",
    "section": "",
    "text": "Considered individually, folkbiological categories, biological anomalies and monsters, as well as human categories represent individual cultural products of human categorization. Instead, we suggest that the uncanny valley might reflect a primary response to unfamiliar or covert categories. In the absence of having prior knowledge of an individual or group, the relative distinctiveness of a category, due to a lower frequency of exposure, will produce negative affect—an inversion of the mere-exposure effect. The deceptive simplicity of learning mechanisms can lead to important individual and social consequences."
  },
  {
    "objectID": "research/articles/kennedy-et-al-2020/index.html",
    "href": "research/articles/kennedy-et-al-2020/index.html",
    "title": "The shape of and solutions to the MTurk quality crisis",
    "section": "",
    "text": "Amazon’s Mechanical Turk is widely used for data collection; however, data quality may be declining due to the use of virtual private servers to fraudulently gain access to studies. Unfortunately, we know little about the scale and consequence of this fraud, and tools for social scientists to detect and prevent this fraud are underdeveloped. We first analyze 38 studies and show that this fraud is not new, but has increased recently. We then show that these fraudulent respondents provide particularly low-quality data and can weaken treatment effects. Finally, we provide two solutions: an easy-to-use application for identifying fraud in the existing datasets and a method for blocking fraudulent respondents in Qualtrics surveys."
  },
  {
    "objectID": "research/articles/kennedy-et-al-2020/index.html#abstract",
    "href": "research/articles/kennedy-et-al-2020/index.html#abstract",
    "title": "The shape of and solutions to the MTurk quality crisis",
    "section": "",
    "text": "Amazon’s Mechanical Turk is widely used for data collection; however, data quality may be declining due to the use of virtual private servers to fraudulently gain access to studies. Unfortunately, we know little about the scale and consequence of this fraud, and tools for social scientists to detect and prevent this fraud are underdeveloped. We first analyze 38 studies and show that this fraud is not new, but has increased recently. We then show that these fraudulent respondents provide particularly low-quality data and can weaken treatment effects. Finally, we provide two solutions: an easy-to-use application for identifying fraud in the existing datasets and a method for blocking fraudulent respondents in Qualtrics surveys."
  },
  {
    "objectID": "research/articles/kennedy-et-al-2020/index.html#important-figure",
    "href": "research/articles/kennedy-et-al-2020/index.html#important-figure",
    "title": "The shape of and solutions to the MTurk quality crisis",
    "section": "Important figure",
    "text": "Important figure\n\n\n\nFigure 5. Path diagram of screening protocol."
  },
  {
    "objectID": "research/articles/burleigh-schoenherr-2015/index.html",
    "href": "research/articles/burleigh-schoenherr-2015/index.html",
    "title": "A reappraisal of the Uncanny Valley: Categorical perception or frequency-based sensitization?",
    "section": "",
    "text": "The uncanny valley (UCV) hypothesis describes a non-linear relationship between perceived human-likeness and affective response. The “uncanny valley” refers to an intermediate level of human-likeness that is associated with strong negative affect. Recent studies have suggested that the uncanny valley might result from the categorical perception of human-like stimuli during identification. When presented with stimuli sharing human-like traits, participants attempt to segment the continuum in “human” and “non-human” categories. Due to the ambiguity of stimuli located at a category boundary, categorization difficulty gives rise to a strong, negative affective response. Importantly, researchers who have studied the UCV in terms of categorical perception have focused on categorization responses rather than affective ratings. In the present study, we examined whether the negative affect associated with the UCV might be explained in terms of an individual’s degree of exposure to stimuli. In two experiments, we tested a frequency-based model against a categorical perception model using a category-learning paradigm. We manipulated the frequency of exemplars that were presented to participants from two categories during a training phase. We then examined categorization and affective responses functions, as well as the relationship between categorization and affective responses. Supporting previous findings, categorization responses suggested that participants acquired novel category structures that reflected a category boundary. These category structures appeared to influence affective ratings of eeriness. Crucially, participants’ ratings of eeriness were additionally affected by exemplar frequency. Taken together, these findings suggest that the UCV is determined by both categorical properties as well as the frequency of individual exemplars retained in memory."
  },
  {
    "objectID": "research/articles/burleigh-schoenherr-2015/index.html#abstract",
    "href": "research/articles/burleigh-schoenherr-2015/index.html#abstract",
    "title": "A reappraisal of the Uncanny Valley: Categorical perception or frequency-based sensitization?",
    "section": "",
    "text": "The uncanny valley (UCV) hypothesis describes a non-linear relationship between perceived human-likeness and affective response. The “uncanny valley” refers to an intermediate level of human-likeness that is associated with strong negative affect. Recent studies have suggested that the uncanny valley might result from the categorical perception of human-like stimuli during identification. When presented with stimuli sharing human-like traits, participants attempt to segment the continuum in “human” and “non-human” categories. Due to the ambiguity of stimuli located at a category boundary, categorization difficulty gives rise to a strong, negative affective response. Importantly, researchers who have studied the UCV in terms of categorical perception have focused on categorization responses rather than affective ratings. In the present study, we examined whether the negative affect associated with the UCV might be explained in terms of an individual’s degree of exposure to stimuli. In two experiments, we tested a frequency-based model against a categorical perception model using a category-learning paradigm. We manipulated the frequency of exemplars that were presented to participants from two categories during a training phase. We then examined categorization and affective responses functions, as well as the relationship between categorization and affective responses. Supporting previous findings, categorization responses suggested that participants acquired novel category structures that reflected a category boundary. These category structures appeared to influence affective ratings of eeriness. Crucially, participants’ ratings of eeriness were additionally affected by exemplar frequency. Taken together, these findings suggest that the UCV is determined by both categorical properties as well as the frequency of individual exemplars retained in memory."
  },
  {
    "objectID": "research/articles/burleigh-schoenherr-2015/index.html#important-figure",
    "href": "research/articles/burleigh-schoenherr-2015/index.html#important-figure",
    "title": "A reappraisal of the Uncanny Valley: Categorical perception or frequency-based sensitization?",
    "section": "Important figure",
    "text": "Important figure\n\n\n\nFIGURE 12: Test categorization response accuracy in the unequal frequency, unequal distribution condition. Stimulus values correspond to stimuli selected from the training range (i.e., stimuli 3–13). Error bars represent 1 standard error of the mean (N = 60)."
  },
  {
    "objectID": "research/articles/burleigh-meegan-2013/index.html",
    "href": "research/articles/burleigh-meegan-2013/index.html",
    "title": "Keeping up with the Joneses affects perceptions of distributive justice",
    "section": "",
    "text": "An experimental field study investigated why people of higher social standing might jump to the conclusion that an injustice has occurred when an authority implements a program that benefits some constituents but not others. High-status individuals are uniquely vulnerable to downward mobility, especially in the event that a situation does not benefit them, but does benefit their high-status peers. In our study, students in a university course were asked to judge a bonus program by which the grades for some would increase and the grades for others would remain the same. Two framing conditions were used, each providing an example in which only one of two students would benefit from the program. In the peer-gets-ahead condition, the two students were of equal status before the program acted to differentiate them, and in the inferior-catches-up condition, the two students differed in status before the program acted to equate them. A majority of students responded favorably to the program, although this number was affected strongly by framing, with almost unanimous approval in the inferior-catches-up condition and comparatively modest approval in the peer-gets-ahead condition. Objections in the latter condition were most frequent among high-status students, who were implicitly uncomfortable with the possibility that their status could decrease relative to some of their high-status peers. Explicitly, their objections used the language of social injustice, especially claims of distributive unfairness. We argue that these perceptions of injustice are a cognitive manifestation of an aversion to any situation that could result in downward mobility."
  },
  {
    "objectID": "research/articles/burleigh-meegan-2013/index.html#abstract",
    "href": "research/articles/burleigh-meegan-2013/index.html#abstract",
    "title": "Keeping up with the Joneses affects perceptions of distributive justice",
    "section": "",
    "text": "An experimental field study investigated why people of higher social standing might jump to the conclusion that an injustice has occurred when an authority implements a program that benefits some constituents but not others. High-status individuals are uniquely vulnerable to downward mobility, especially in the event that a situation does not benefit them, but does benefit their high-status peers. In our study, students in a university course were asked to judge a bonus program by which the grades for some would increase and the grades for others would remain the same. Two framing conditions were used, each providing an example in which only one of two students would benefit from the program. In the peer-gets-ahead condition, the two students were of equal status before the program acted to differentiate them, and in the inferior-catches-up condition, the two students differed in status before the program acted to equate them. A majority of students responded favorably to the program, although this number was affected strongly by framing, with almost unanimous approval in the inferior-catches-up condition and comparatively modest approval in the peer-gets-ahead condition. Objections in the latter condition were most frequent among high-status students, who were implicitly uncomfortable with the possibility that their status could decrease relative to some of their high-status peers. Explicitly, their objections used the language of social injustice, especially claims of distributive unfairness. We argue that these perceptions of injustice are a cognitive manifestation of an aversion to any situation that could result in downward mobility."
  },
  {
    "objectID": "research/articles/burleigh-et-al-2017/index.html",
    "href": "research/articles/burleigh-et-al-2017/index.html",
    "title": "Wanting ‘the whole loaf’: Zero-sum thinking about love is associated with prejudice against consensual non-monogamists",
    "section": "",
    "text": "Consensual non-monogamy (CNM) is a relationship in which individuals agree that romantic or sexual relationships with others are permissible or desirable (e.g. polyamory or open relationships). Although anti-CNM prejudice is prevalent, it is not well understood. We propose that one of the bases of anti-CNM prejudice is zero-sum thinking about love – the perception that one person’s love gained is another’s love lost. We outline our theory and then present three studies that test our predictions. In these studies, participants read a vignette that depicted characters who were in a CNM or monogamous relationship, and then judged aspects of the characters and their relationship. In Study 1, participants who read the CNM vignette judged the protagonist’s love for their initial romantic partner before and after they became involved with a second partner. Zero-sum thinking was operationally defined as the within-subject change in love ratings. In Studies 2 and 3, participants rated their agreement with items from a new preliminary measure of zero-sum romantic beliefs. We measured CNM devaluation by asking for ratings of the relationships and of individuals in the relationships. Supporting our predictions, in all three studies we found that zero-sum thinking about love was associated with increased CNM devaluation. We end by briefly discussing the implications of our findings."
  },
  {
    "objectID": "research/articles/burleigh-et-al-2017/index.html#abstract",
    "href": "research/articles/burleigh-et-al-2017/index.html#abstract",
    "title": "Wanting ‘the whole loaf’: Zero-sum thinking about love is associated with prejudice against consensual non-monogamists",
    "section": "",
    "text": "Consensual non-monogamy (CNM) is a relationship in which individuals agree that romantic or sexual relationships with others are permissible or desirable (e.g. polyamory or open relationships). Although anti-CNM prejudice is prevalent, it is not well understood. We propose that one of the bases of anti-CNM prejudice is zero-sum thinking about love – the perception that one person’s love gained is another’s love lost. We outline our theory and then present three studies that test our predictions. In these studies, participants read a vignette that depicted characters who were in a CNM or monogamous relationship, and then judged aspects of the characters and their relationship. In Study 1, participants who read the CNM vignette judged the protagonist’s love for their initial romantic partner before and after they became involved with a second partner. Zero-sum thinking was operationally defined as the within-subject change in love ratings. In Studies 2 and 3, participants rated their agreement with items from a new preliminary measure of zero-sum romantic beliefs. We measured CNM devaluation by asking for ratings of the relationships and of individuals in the relationships. Supporting our predictions, in all three studies we found that zero-sum thinking about love was associated with increased CNM devaluation. We end by briefly discussing the implications of our findings."
  },
  {
    "objectID": "research/articles/burleigh-et-al-2017/index.html#important-figure",
    "href": "research/articles/burleigh-et-al-2017/index.html#important-figure",
    "title": "Wanting ‘the whole loaf’: Zero-sum thinking about love is associated with prejudice against consensual non-monogamists",
    "section": "Important figure",
    "text": "Important figure\n\n\n\nFigure 2. This figure shows that increased zero-sum romantic beliefs were associated with greater devaluation of CNM (steeper slopes) in Study 2. It represents a simple slopes analysis of relationship vignette (monogamous, CNM) predicting evaluative judgment scores at 1 SD above the mean of zero-sum romantic beliefs, at the mean of zero-sum romantic beliefs, and 1 SD below the mean of zero-sum romantic beliefs."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Hello there!",
    "section": "",
    "text": "Hi! I’m an AI Research Scientist with a multidisciplinary background in experimental psychology and data science. At Khan Academy, I work with Generative AI technologies like Large Language Models (LLMs), engaging in the full lifecycle of AI development – from research and solution architecture to engineering and evaluation. I aim to build high-quality, reliable AI experiences that will transform learning and support the next generation of learners. I’m passionate about using AI to make education more accessible, engaging, and effective for learners worldwide."
  },
  {
    "objectID": "index.html#about-me",
    "href": "index.html#about-me",
    "title": "Hello there!",
    "section": "",
    "text": "Hi! I’m an AI Research Scientist with a multidisciplinary background in experimental psychology and data science. At Khan Academy, I work with Generative AI technologies like Large Language Models (LLMs), engaging in the full lifecycle of AI development – from research and solution architecture to engineering and evaluation. I aim to build high-quality, reliable AI experiences that will transform learning and support the next generation of learners. I’m passionate about using AI to make education more accessible, engaging, and effective for learners worldwide."
  },
  {
    "objectID": "index.html#my-latest-blog-posts",
    "href": "index.html#my-latest-blog-posts",
    "title": "Hello there!",
    "section": "My latest blog posts",
    "text": "My latest blog posts\n\n\n\n\n\n\n\n\n\n\nRAG-Powered LLM Longevity Coach\n\n\n\n\n\nA simple RAG-powered ‘Longevity Coach’ that uses a vector store and an LLM to deliver targeted health insights informed by user-provided health data (including genetics, lab results, supplements/medications taken, etc.). By using RAG, the app reduces token usage and ensures only the most relevant data is used to respond to user queries.\n\n\n\n\n\nFeb 2, 2025\n\n\nTyler Burleigh\n\n\n\n\n\n\n\n\n\n\n\n\nAnalysis of the GenAI/LLM job market in January 2025\n\n\n\n\n\nA data-driven exploration of the GenAI/LLM job market for science and engineering roles in January 2025. I scrape ~1000 job postings from ai-jobs.net, perform data extraction and classification using LLMs, and then analyze the data to identify patterns and insights about the GenAI/LLM job market, including salary ranges, skill requirements, and role distribution.\n\n\n\n\n\nJan 24, 2025\n\n\nTyler Burleigh\n\n\n\n\n\n\n\n\n\n\n\n\nChallenging SAMRE: Comparing multi-round debate-style LLM evaluation to a robust (and much simpler) baseline\n\n\n\n\n\nIn this post, I re-evaluate a method that was recently published in arXiv, critiquing their baseline model and then designing a new baseline model that implements standard best practices for comparison with the new method. I find that the new evaluation method proposed in the paper does not perform better than this robust baseline. This serves to highlight the importance of implementing best practices in baseline models for comparison with new methods, as well as being skeptical of claims in research papers that compare new methods to baseline.\n\n\n\n\n\nJan 12, 2025\n\n\nTyler Burleigh\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog/index.html",
    "href": "blog/index.html",
    "title": "Blog",
    "section": "",
    "text": "February 2, 2025\n        \n        \n            RAG-Powered LLM Longevity Coach\n\n            \n            \n                \n                \n                    RAG\n                \n                \n                \n                    LLM\n                \n                \n                \n                    python\n                \n                \n            \n            \n\n            A simple RAG-powered 'Longevity Coach' that uses a vector store and an LLM to deliver targeted health insights informed by user-provided health data (including genetics, lab results, supplements/medications taken, etc.). By using RAG, the app reduces token usage and ensures only the most relevant data is used to respond to user queries.\n            \n            \n        \n        \n    \n    \n    \n                  \n            January 24, 2025\n        \n        \n            Analysis of the GenAI/LLM job market in January 2025\n\n            \n            \n                \n                \n                    prompt-engineering\n                \n                \n                \n                    python\n                \n                \n                \n                    job-market\n                \n                \n                \n                    GenAI\n                \n                \n                \n                    LLM\n                \n                \n            \n            \n\n            A data-driven exploration of the  GenAI/LLM job market for science and engineering roles in January 2025. I scrape ~1000 job postings from ai-jobs.net, perform data extraction and classification using LLMs, and then analyze the data to identify patterns and insights about the GenAI/LLM job market, including salary ranges, skill requirements, and role distribution.\n            \n            \n        \n        \n    \n    \n    \n                  \n            January 12, 2025\n        \n        \n            Challenging SAMRE: Comparing multi-round debate-style LLM evaluation to a robust (and much simpler) baseline\n\n            \n            \n                \n                \n                    prompt-engineering\n                \n                \n                \n                    python\n                \n                \n                \n                    LLM-as-judge\n                \n                \n                \n                    LLM-evals\n                \n                \n            \n            \n\n            In this post, I re-evaluate a method that was recently published in arXiv, critiquing their baseline model and then designing a new baseline model that implements standard best practices for comparison with the new method. I find that the new evaluation method proposed in the paper does not perform better than this robust baseline. This serves to highlight the importance of implementing best practices in baseline models for comparison with new methods, as well as being skeptical of claims in research papers that compare new methods to baseline.\n            \n            \n        \n        \n    \n    \n\n\nNo matching items"
  },
  {
    "objectID": "blog/index.html#section",
    "href": "blog/index.html#section",
    "title": "Blog",
    "section": "",
    "text": "February 2, 2025\n        \n        \n            RAG-Powered LLM Longevity Coach\n\n            \n            \n                \n                \n                    RAG\n                \n                \n                \n                    LLM\n                \n                \n                \n                    python\n                \n                \n            \n            \n\n            A simple RAG-powered 'Longevity Coach' that uses a vector store and an LLM to deliver targeted health insights informed by user-provided health data (including genetics, lab results, supplements/medications taken, etc.). By using RAG, the app reduces token usage and ensures only the most relevant data is used to respond to user queries.\n            \n            \n        \n        \n    \n    \n    \n                  \n            January 24, 2025\n        \n        \n            Analysis of the GenAI/LLM job market in January 2025\n\n            \n            \n                \n                \n                    prompt-engineering\n                \n                \n                \n                    python\n                \n                \n                \n                    job-market\n                \n                \n                \n                    GenAI\n                \n                \n                \n                    LLM\n                \n                \n            \n            \n\n            A data-driven exploration of the  GenAI/LLM job market for science and engineering roles in January 2025. I scrape ~1000 job postings from ai-jobs.net, perform data extraction and classification using LLMs, and then analyze the data to identify patterns and insights about the GenAI/LLM job market, including salary ranges, skill requirements, and role distribution.\n            \n            \n        \n        \n    \n    \n    \n                  \n            January 12, 2025\n        \n        \n            Challenging SAMRE: Comparing multi-round debate-style LLM evaluation to a robust (and much simpler) baseline\n\n            \n            \n                \n                \n                    prompt-engineering\n                \n                \n                \n                    python\n                \n                \n                \n                    LLM-as-judge\n                \n                \n                \n                    LLM-evals\n                \n                \n            \n            \n\n            In this post, I re-evaluate a method that was recently published in arXiv, critiquing their baseline model and then designing a new baseline model that implements standard best practices for comparison with the new method. I find that the new evaluation method proposed in the paper does not perform better than this robust baseline. This serves to highlight the importance of implementing best practices in baseline models for comparison with new methods, as well as being skeptical of claims in research papers that compare new methods to baseline.\n            \n            \n        \n        \n    \n    \n\n\nNo matching items"
  },
  {
    "objectID": "blog/index.html#section-1",
    "href": "blog/index.html#section-1",
    "title": "Blog",
    "section": "2023",
    "text": "2023\n\n\n    \n    \n                  \n            December 9, 2023\n        \n        \n            AI Math Tutoring: Using GPT to generate \"step-by-step guidance\"\n\n            \n            \n                \n                \n                    GPT\n                \n                \n                \n                    prompt-engineering\n                \n                \n                \n                    python\n                \n                \n                \n                    R\n                \n                \n            \n            \n\n            In this post, I show how an AI Tutor feature like \"step-by-step guidance\" can be built to help students on multi-step math problems, and how this guidance can be validated.\n            \n            \n        \n        \n        \n            \n        \n        \n    \n    \n    \n                  \n            December 4, 2023\n        \n        \n            Tackling the GSM8K (grade school math) with GPT-3.5 and self-consistency prompting\n\n            \n            \n                \n                \n                    GPT\n                \n                \n                \n                    prompt-engineering\n                \n                \n                \n                    python\n                \n                \n                \n                    R\n                \n                \n            \n            \n\n            In this post, I use the \"Self-Consistency\" prompt engineering strategy to improve the performance of a GPT-3.5 based model tasked with solving problems from the GSM8K (grade school math) dataset. I explore two implementations of this strategy, finding that one is more effective than the other. Overall, I find that this strategy is effective, leading to an increase in the percentage of correct answers from 75% at baseline to 93% with the strongest implementation of the strategy.\n            \n            \n        \n        \n        \n            \n        \n        \n    \n    \n    \n                  \n            October 8, 2023\n        \n        \n            Using GPT-4 for classification\n\n            \n            \n                \n                \n                    GPT\n                \n                \n                \n                    R\n                \n                \n            \n            \n\n            In this post, I use GPT-4 to classify US grant-funding agencies into 10 categories using government agency names. Then I summarize funding by category.\n            \n            \n        \n        \n        \n            \n        \n        \n    \n    \n    \n                  \n            September 19, 2023\n        \n        \n            Encoding high cardinality features with \"embeddings\"\n\n            \n            \n                \n                \n                    machine-learning\n                \n                \n                \n                    R\n                \n                \n            \n            \n\n            In this post I show how the performance of an ML model can be improved by encoding high cardinality features using \"embeddings\", a method that uses deep learning to represent categorical features as vectors. I compare the performance of embedding encoding with other common categorical encoding methods: one-hot, label, frequency, and target encoding.\n            \n            \n        \n        \n        \n            \n        \n        \n    \n    \n    \n                  \n            September 8, 2023\n        \n        \n            Using random forest based outlier detection to clean a training dataset\n\n            \n            \n                \n                \n                    machine-learning\n                \n                \n                \n                    R\n                \n                \n            \n            \n\n            In this post, I explore whether a random forest model can be improved by using random forest based multivariate outlier detection and imputation methods, and by reducing feature multicollinearity. Supporting the common wisdom that random forest models are robust to outliers and multicollinearity, these data cleaning steps led to only marginal improvements in out-of-sample model performance.\n            \n            \n        \n        \n        \n            \n        \n        \n    \n    \n    \n                  \n            August 31, 2023\n        \n        \n            Joining messy dataframes using fuzzy joining, string cleaning, and column binding\n\n            \n            \n                \n                \n                    R\n                \n                \n            \n            \n\n            Tidy Tuesday this week presented a challenge: \"There are two datasets this week for which the rows align, but the values might not precisely line up for a clean join.\" In this post I walkthrough my solution that uses a combination of fuzzy joining, string cleaning, and column binding.\n            \n            \n        \n        \n        \n            \n        \n        \n    \n    \n    \n                  \n            August 25, 2023\n        \n        \n            Using data normalization to better compare change over time in regions with different population sizes\n\n            \n            \n                \n                \n                    R\n                \n                \n            \n            \n\n            I use data normalization to better compare the changes in refugee outflows in different regions from 2010 to 2022. Four regions are identified with large increases over their 2010 baseline.\n            \n            \n        \n        \n        \n            \n        \n        \n    \n    \n    \n                  \n            August 19, 2023\n        \n        \n            Building a prediction model to detect spam email\n\n            \n            \n                \n                \n                    machine-learning\n                \n                \n                \n                    R\n                \n                \n            \n            \n\n            Using the spam email dataset from Tidy Tuesday Week 33, I walk through the process of building and evaluating a prediction model using decision tree and random forest machine learning algorithms.\n            \n            \n        \n        \n        \n            \n        \n        \n    \n    \n\n\nNo matching items"
  },
  {
    "objectID": "blog/index.html#section-2",
    "href": "blog/index.html#section-2",
    "title": "Blog",
    "section": "2020",
    "text": "2020\n\n\n    \n    \n                  \n            May 12, 2020\n        \n        \n            Modeling cognitive impairment using NHANES data\n\n            \n            \n                \n                \n                    python\n                \n                \n            \n            \n\n            I build a machine learning model to predict possible cases of cognitive impairment / dementia in a population of individuals over the age of 60. My data for this model comes from the 2013-2014 NHANES (National Health and Nutrition Examination Survey) study cohort, which is a nationally representative, longitudinal study of health in the US.\n            \n            \n        \n        \n        \n            \n        \n        \n    \n    \n    \n                  \n            April 11, 2020\n        \n        \n            Estimating how many people live near a landmark / point-of-interest\n\n            \n            \n                \n                \n                    python\n                \n                \n            \n            \n\n            In this post, I start with a point-of-interest, \"Times Square, NYC\", and using the Census API I find out how many people live within the census tract that contains this POI (a tract is one of the smallest sub-divisions for which the Census provides population estimates).\n            \n            \n        \n        \n        \n            \n        \n        \n    \n    \n    \n                  \n            April 4, 2020\n        \n        \n            Identifying pneumonia from chest x-rays using EfficientNet\n\n            \n            \n                \n                \n                    machine-learning\n                \n                \n                \n                    python\n                \n                \n            \n            \n\n            I was interested in trying tensorflow + EfficientNet on another image classification task. This time, I used it to predict pneumonia on chest x-ray images. Using this model, I achieved 97% out of sample accuracy.\n            \n            \n        \n        \n        \n            \n        \n        \n    \n    \n    \n                  \n            April 1, 2020\n        \n        \n            Using tensorflow with EfficientNet to predict plant diseases\n\n            \n            \n                \n                \n                    machine-learning\n                \n                \n                \n                    python\n                \n                \n            \n            \n\n            I use tensorflow with an EfficientNet base model (via transfer learning) to predict plant diseases for the Plant Pathology 2020 Kaggle challenge. Using this model, I achieved 94% out of sample accuracy.\n            \n            \n        \n        \n        \n            \n        \n        \n    \n    \n    \n                  \n            March 21, 2020\n        \n        \n            COVID-19 case growth and the Big 5 Personality traits\n\n            \n            \n                \n                \n                    python\n                \n                \n            \n            \n\n            Does the growth in COVID-19 cases have anything to do with Big 5 Personality traits? To answer this question, I compute country-level aggregates on the Big 5 test, and a country-level aggregate that represents for \"growth\" over time in coronavirus cases, using data current as of March 20, 2020.\n            \n            \n        \n        \n        \n            \n        \n        \n    \n    \n    \n                  \n            March 20, 2020\n        \n        \n            Using a logistic regression model to predict heart disease\n\n            \n            \n                \n                \n                    machine-learning\n                \n                \n                \n                    python\n                \n                \n            \n            \n\n            I trained a logistic regression model to predict heart disease, using 14 attributes and 303 observations (e.g., age, sex, chest pain, resting ECG). Then I evaluated its performance.\n            \n            \n        \n        \n        \n            \n        \n        \n    \n    \n\n\nNo matching items"
  },
  {
    "objectID": "blog/index.html#section-3",
    "href": "blog/index.html#section-3",
    "title": "Blog",
    "section": "2019",
    "text": "2019\n\n\n    \n    \n                  \n            September 27, 2019\n        \n        \n            Predicting t-shirt size from height and weight\n\n            \n            \n                \n                \n                    machine-learning\n                \n                \n                \n                    R\n                \n                \n            \n            \n\n            Using body measurement data from the National Health and Nutrition Examination Survey (NHANES), I created a model that predicts Gildan t-shirt sizes from height and weight.\n            \n            \n        \n        \n        \n            \n        \n        \n    \n    \n\n\nNo matching items"
  },
  {
    "objectID": "blog/2025/01/24/index.html",
    "href": "blog/2025/01/24/index.html",
    "title": "Analysis of the GenAI/LLM job market in January 2025",
    "section": "",
    "text": "As someone currently working in a “Prompt Engineering” role, I’ve been thinking a lot about how this title basically doesn’t exist outside of a handful of companies, how the title communicates a narrow range of skills and responsibilities,and how the work that I do day-to-day is much larger in scope than just writing prompts. I identify more as an AI Engineer or AI Research Scientist, and so I was interested to see what I could learn about other similar roles that work with GenAI and LLMs.\nSo with that motivation, I set about to collect some data and look at the job market for these sorts of roles. What responsibilities and skills are being advertised most often, what kinds of titles are being used for these roles, and what kind of compensation is being offered at different levels of seniority?\nTo accomplish this, I built a custom web scraper to collect ~1000 job postings from ai-jobs.net. My code gathers job details like the title, company, location, salary, and posting date – from a range of U.S. and Canadian cities, covering entry-level, mid-level, and senior positions. I then use a Large Language Model (LLM) to extract each job’s key responsibilities, required skills, and qualifications. Afterwards, I classify each position to see whether it involves working with Generative AI or large language models, and if so, categorize it further into four major AI roles: (1) AI Research Scientist, (2) AI/ML Engineer, (3) MLOps/AI Infrastructure Engineer, and (4) AI Solution Architect. I believe this set of roles is a good representation of different areas of focus.\nFinally, I integrate the various metadata and classifications into a comprehensive dataset. I observe that GenAI/LLM positions command consistently high salary ranges across the four different roles, particularly at more senior levels. Senior-level roles tended to offer median salaries in the $195K–$210K range, while mid-level roles generally clustered around $165K–$180K. Entry-level salaries showed greater variation (likely due to the small sample size) but still landed in competitive ranges of roughly $155K–$205K in many postings. These roles often share common technical demands—like proficiency with large-scale model training, distributed computing, and LLM-specific knowledge—though each role emphasizes distinct priorities (research vs. production, for example).\nOf course, this analysis is not without limitations. For example, I am relying on a single job board, and I scraped jobs during a limited window of time. I also have not rigorously validated the LLM classifications – although I have implemented many prompt engineering best practices, and have used some of the more powerful LLMs (4o and o1). To some extent, the responsibilities and skills that were recovered from the original job postings classified into the four pre-defined roles do speak to the relative accuracy of the role classifications. The salary analysis also does not distinguish between base salary and total compensation, remote vs. in-person opportunities, large vs. small companies, and so on. But overall, I think this gives some sense of the job market for these roles."
  },
  {
    "objectID": "blog/2025/01/24/index.html#classify-jobs-as-relevant-to-genaillm-work-or-not",
    "href": "blog/2025/01/24/index.html#classify-jobs-as-relevant-to-genaillm-work-or-not",
    "title": "Analysis of the GenAI/LLM job market in January 2025",
    "section": "Classify jobs as relevant to GenAI/LLM work or not",
    "text": "Classify jobs as relevant to GenAI/LLM work or not\n\n\nClick to view the code for job classification as GenAI/LLM relevant or not\nimport nest_asyncio\nimport re\nimport asyncio\nimport logging\nfrom typing import List, Dict, Set\nfrom bs4 import BeautifulSoup\nimport pandas as pd\nfrom tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type\nfrom openai import AsyncOpenAI\nimport os\nfrom openai import RateLimitError\nimport json\n\nclass JobClassifierGenAI:\n    \"\"\"Handles classification of jobs for GenAI/LLM work\"\"\"\n    \n    PROMPT = \"\"\"\n    You will be given a list of Responsibilities and\n    Skills listed for a job. Your task is to determine\n    if the job involves working with Generative AI (GenAI)\n    or language models (a.k.a. Large Language Models (LLMs)).\n\n    &lt;Job&gt;\n    &lt;Responsibilities&gt;\n    {responsibilities}\n    &lt;/Responsibilities&gt;\n    &lt;Skills&gt;\n    {skills}\n    &lt;/Skills&gt;\n    &lt;/Job&gt;\n\n    Start by thinking step-by-step about the Job and its \n    Responsibilities and Skills, and whether it involves\n    working with Generative AI (GenAI) or language models\n    (a.k.a. Large Language Models (LLMs)).\n\n    Return your response in the following format:\n    &lt;Analysis&gt;\n    [Your analysis of the job and its Responsibilities and Skills]\n    &lt;/Analysis&gt;\n    &lt;FinalAnswer&gt;\n    true|false\n    &lt;/FinalAnswer&gt;\n    \"\"\"\n\n    def __init__(self, output_dir='role_genai_classifications', batch_size=3):\n        self.output_dir = output_dir\n        self.batch_size = batch_size\n        self.semaphore = asyncio.Semaphore(batch_size)\n        os.makedirs(output_dir, exist_ok=True)\n\n    async def classify_job(self, job: Dict) -&gt; Dict:\n        \"\"\"Classify a single job listing\"\"\"\n        logging.info(f\"Classifying job '{job['filename']}'\")\n        \n        prompt = self.PROMPT.format(\n            responsibilities=job['responsibilities'],\n            skills=job.get('skills', '')\n        )\n        \n        try:\n            response = await get_completion(prompt)\n            await asyncio.sleep(2)  # Rate limiting\n        except Exception as e:\n            logging.error(f\"Failed to classify job '{job['filename']}': {str(e)}\")\n            return {\n                **job,\n                'analysis': f'Failed to process: {str(e)}',\n                'is_genai_role': None\n            }\n        \n        return self._parse_response(job, response)\n\n    def _parse_response(self, job: Dict, response: str) -&gt; Dict:\n        \"\"\"Parse LLM response into structured format\"\"\"\n        soup = BeautifulSoup(f\"&lt;root&gt;{response}&lt;/root&gt;\", 'lxml-xml')\n        \n        analysis = soup.find('Analysis')\n        final_answer = soup.find('FinalAnswer')\n        is_genai_role = None\n        \n        if final_answer:\n            answer_text = final_answer.text.strip().lower()\n            is_genai_role = True if answer_text == 'true' else False if answer_text == 'false' else None\n        \n        return {\n            **job,\n            'analysis': analysis.text.strip() if analysis else '',\n            'is_genai_role': is_genai_role\n        }\n\n    def save_classification(self, job_id: str, result: Dict) -&gt; None:\n        \"\"\"Save classification results to file\"\"\"\n        filename = os.path.join(self.output_dir, f\"{job_id}.json\")\n        with open(filename, 'w') as f:\n            json.dump(result, f, indent=2)\n        logging.info(f\"Saved classification for job {job_id}\")\n\n    def get_classified_jobs(self) -&gt; Set[str]:\n        \"\"\"Get set of already classified job IDs\"\"\"\n        if not os.path.exists(self.output_dir):\n            return set()\n        return {f[:-5] for f in os.listdir(self.output_dir) if f.endswith('.json')}\n\n    async def process_jobs_batch(self, jobs: List[Dict]) -&gt; None:\n        \"\"\"Process a batch of jobs concurrently\"\"\"\n        async def process_with_semaphore(job: Dict) -&gt; None:\n            async with self.semaphore:\n                result = await self.classify_job(job)\n                job_id = str(result['filename'])\n                self.save_classification(job_id, result)\n        \n        await asyncio.gather(*[process_with_semaphore(job) for job in jobs])\n\n    async def classify_jobs_async(self, df: pd.DataFrame) -&gt; None:\n        \"\"\"Process all unclassified jobs in the DataFrame\"\"\"\n        total_jobs = len(df)\n        logging.info(f\"Starting classification of {total_jobs} jobs\")\n        \n        classified_jobs = self.get_classified_jobs()\n        jobs_to_process = [\n            job.to_dict() for idx, job in df.iterrows() \n            if str(job['filename']) not in classified_jobs\n        ]\n        \n        await self.process_jobs_batch(jobs_to_process)\n        logging.info(f\"Completed classification of all {total_jobs} jobs\")\n\n    def classify_jobs(self, df: pd.DataFrame) -&gt; None:\n        \"\"\"Main entry point for job classification\"\"\"\n        if df.empty:\n            logging.warning(\"Empty DataFrame provided\")\n            return\n            \n        if 'filename' not in df.columns:\n            logging.error(\"DataFrame missing required 'filename' column\")\n            return\n        \n        classified_jobs = self.get_classified_jobs()\n        logging.info(f\"Found {len(classified_jobs)} previously classified jobs\")\n        \n        new_jobs = df[~df['filename'].isin(classified_jobs)]\n        if new_jobs.empty:\n            logging.info(\"No new jobs to classify\")\n            return\n        \n        logging.info(f\"Processing {len(new_jobs)} new jobs\")\n        logging.info(f\"Skipping {len(df) - len(new_jobs)} existing jobs\")\n        \n        loop = asyncio.get_event_loop()\n        loop.run_until_complete(self.classify_jobs_async(new_jobs))\n\nclass JobDataLoader:\n    \"\"\"Handles loading and preprocessing of job data\"\"\"\n    \n    @staticmethod\n    def read_json_files(json_dir='json_extracted_data') -&gt; List[Dict]:\n        \"\"\"Read job data from JSON files\"\"\"\n        result = []\n        \n        for filename in os.listdir(json_dir):\n            if filename.endswith('.json'):\n                file_path = os.path.join(json_dir, filename)\n                try:\n                    with open(file_path, 'r') as f:\n                        data = json.load(f)\n                        name = filename[:-5]\n                        if 'responsibilities' in data and 'skills' in data:\n                            result.append({\n                                'filename': name,\n                                'responsibilities': data['responsibilities'],\n                                'skills': data['skills']\n                            })\n                except json.JSONDecodeError:\n                    logging.error(f\"Invalid JSON in {filename}\")\n                except Exception as e:\n                    logging.error(f\"Error processing {filename}: {str(e)}\")\n        \n        return result\n\n    @staticmethod\n    def load_classifications(input_dir='role_genai_classifications') -&gt; pd.DataFrame:\n        \"\"\"Load classification results into DataFrame\"\"\"\n        if not os.path.exists(input_dir):\n            return pd.DataFrame()\n            \n        all_results = []\n        for filename in os.listdir(input_dir):\n            if filename.endswith('.json'):\n                with open(os.path.join(input_dir, filename), 'r') as f:\n                    classification = json.load(f)\n                    all_results.append(classification)\n        \n        return pd.DataFrame(all_results)\n\n\n\nloader = JobDataLoader()\njobs = loader.read_json_files()\ndf = pd.DataFrame(jobs)\n\n#classifier = JobClassifierGenAI()\n#classifier.classify_jobs(df)\n\n# Load results\n#results_df = loader.load_classifications()"
  },
  {
    "objectID": "blog/2025/01/24/index.html#classify-genaillm-jobs-into-pre-defined-categories",
    "href": "blog/2025/01/24/index.html#classify-genaillm-jobs-into-pre-defined-categories",
    "title": "Analysis of the GenAI/LLM job market in January 2025",
    "section": "Classify GenAI/LLM jobs into pre-defined categories",
    "text": "Classify GenAI/LLM jobs into pre-defined categories\nFor this next classification task, I’ll make the assumption that there are four types of AI engineering and science roles that are relevant to work with GenAI systems. These are:\n\nAI Research Scientist\nAI/ML Engineer\nMLOps / AI Infrastructure Engineer\nAI Solution Architect\n\nI’ll also include other categories that are not of interest, but may improve classification accuracy. These are:\n\nData Scientist\nData Engineer\nProduct Manager\nSoftware Engineer\n\nThe code below implements an automated job classification system that uses an LLM to categorize job postings into the eight predefined roles listed above (four GenAI-focused and four related roles). It consists of several classes that work together: JobClassifier handles the core classification logic by comparing job descriptions against detailed role templates, JobData and ClassificationResult provide structured data containers, and JobProcessor manages the overall pipeline from loading jobs to saving results. The system processes jobs concurrently using asyncio, includes error handling and rate limiting, and outputs both an analysis explaining the classification and a final numerical category (0-8) for each job, with all results saved as JSON files for further analysis.\nDefinitions of the roles can be found in the JOB_DESCRIPTIONS variable.\n\n\nClick to view the code for job classification into pre-defined roles\nfrom dataclasses import dataclass\nfrom typing import List, Dict, Set, Optional\nimport logging\nimport json\nimport asyncio\nimport os\nfrom bs4 import BeautifulSoup\nimport pandas as pd\nimport nest_asyncio\n\nJOB_DESCRIPTIONS = \"\"\"\n&lt;Option title=\"AI Research Scientist\" number=\"1\"&gt;\n  &lt;PrimaryFocus&gt;\n    Investigate and adapt cutting-edge AI methodologies (e.g., generative models, advanced prompt engineering) for applications.\n  &lt;/PrimaryFocus&gt;\n  &lt;KeyResponsibilities&gt;\n    Conduct experiments to evaluate the performance (e.g., quality, accuracy) of new AI approaches and refine existing models.\n    Collaborate with AI/ML Engineers to transition successful prototypes into production.\n    Stay current with the latest AI research and emerging trends in generative AI.\n    Develop human-annotated datasets for training and evaluation of AI models.\n  &lt;/KeyResponsibilities&gt;\n  &lt;SkillsAndTools&gt;\n    Deep understanding of LLMs and prompt engineering.\n    Strong background in statistics, optimization, or related fields.\n    Knowledge of experimental methods (e.g., A/B testing) and hypothesis testing.\n    Knowledge of LLM evaluation methods, including algorithmic evals, human evals, or LLM-as-a-judge evals.\n  &lt;/SkillsAndTools&gt;\n&lt;/Option&gt;\n&lt;Option title=\"AI/ML Engineer\" number=\"2\"&gt;\n  &lt;PrimaryFocus&gt;\n    Transform research output into robust, scalable AI solutions for the product or internal use.\n  &lt;/PrimaryFocus&gt;\n  &lt;KeyResponsibilities&gt;\n    Productionize AI models, ensuring they meet performance and reliability requirements.\n    Develop and maintain data pipelines for model training, inference, and monitoring.\n    Collaborate closely with Research Scientists to optimize and refine model implementations.\n  &lt;/KeyResponsibilities&gt;\n  &lt;SkillsAndTools&gt;\n    Proficiency in Python, Go, or similar languages.\n    Experience with API development and integration (REST, GraphQL).\n    Working knowledge of software engineering best practices (version control, testing, CI/CD).\n  &lt;/SkillsAndTools&gt;\n&lt;/Option&gt;\n&lt;Option title=\"MLOps / AI Infrastructure Engineer\" number=\"3\"&gt;\n  &lt;PrimaryFocus&gt;\n    Ensure reliable deployment, scaling, and monitoring of AI systems in production.\n  &lt;/PrimaryFocus&gt;\n  &lt;KeyResponsibilities&gt;\n    Set up CI/CD pipelines tailored for AI workflows, including model versioning and data governance.\n    Monitor production models for performance, latency, and data drift, implementing necessary updates.\n    Manage infrastructure for scalable AI deployments (Docker, Kubernetes, cloud services).\n  &lt;/KeyResponsibilities&gt;\n  &lt;SkillsAndTools&gt;\n    Strong DevOps background, with tools like Docker, Kubernetes, and Terraform.\n    Familiarity with ML orchestration/monitoring tools (MLflow, Airflow, Prometheus).\n    Experience optimizing compute usage (GPU/TPU) for cost-effective scaling.\n  &lt;/SkillsAndTools&gt;\n&lt;/Option&gt;\n&lt;Option title=\"AI Solution Architect\" number=\"4\"&gt;\n  &lt;PrimaryFocus&gt;\n    Design and orchestrate AI solutions leveraging generative models and LLM technologies to create impactful experiences and solutions that align with business objectives.\n  &lt;/PrimaryFocus&gt;\n  &lt;KeyResponsibilities&gt;\n    Collaborate with subject matter experts (SMEs) to identify and refine opportunities for generative AI/LLM-based use cases.\n    Assess feasibility and define high-level solution architectures, ensuring they address core business and user requirements.\n    Develop technical proposals and roadmaps, translating complex requirements into actionable plans.\n    Provide thought leadership on conversational design, user experience flow, and model interaction strategies.\n    Ensure solutions comply with relevant data governance, privacy, and security considerations.\n    Facilitate cross-functional collaboration, guiding teams through solution conceptualization and implementation phases.\n  &lt;/KeyResponsibilities&gt;\n  &lt;SkillsAndTools&gt;\n    Strong understanding of LLM capabilities and prompt engineering principles.\n    Experience with conversational experience design (e.g., chatbots, voice interfaces) and user journey mapping.\n    Ability to analyze business needs and translate them into feasible AI solution proposals.\n    Familiarity with data privacy and security best practices, especially as they pertain to AI solutions.\n    Excellent communication and stakeholder management skills to align technical and non-technical teams.\n  &lt;/SkillsAndTools&gt;\n&lt;/Option&gt;\n&lt;Option title=\"Data Scientist\" number=\"5\"&gt; \n  &lt;PrimaryFocus&gt;\n    Leverage statistical analysis, machine learning, and data visualization to derive actionable insights and guide data-informed decisions.\n  &lt;/PrimaryFocus&gt; \n  &lt;KeyResponsibilities&gt; \n    Perform exploratory data analysis (EDA) to identify trends and patterns in large, complex datasets. \n    Develop and validate predictive and prescriptive models, collaborating with cross-functional teams to implement these solutions. \n    Design and execute experiments to test hypotheses, measure impact, and inform business strategies. \n    Present findings and recommendations to stakeholders in a clear, concise manner using visualizations and dashboards. \n    Work with data engineers to ensure data quality, governance, and availability. \n  &lt;/KeyResponsibilities&gt; \n  &lt;SkillsAndTools&gt; \n    Proficiency in Python, R, or SQL for data manipulation and analysis. \n    Experience with common ML libraries (e.g., scikit-learn, XGBoost) and deep learning frameworks (e.g., PyTorch, TensorFlow). \n    Solid grounding in statistics, probability, and experimental design. \n    Familiarity with data visualization tools (e.g., Tableau, Power BI) for communicating insights. \n    Strong analytical thinking and ability to translate complex data problems into business solutions. \n  &lt;/SkillsAndTools&gt; \n&lt;/Option&gt;\n&lt;Option title=\"Data Engineer\" number=\"6\"&gt;\n  &lt;PrimaryFocus&gt;\n    Design, build, and maintain scalable data pipelines and architectures that enable efficient data collection, storage, and analysis.\n  &lt;/PrimaryFocus&gt;\n  &lt;KeyResponsibilities&gt;\n    Develop and optimize data ingestion and transformation processes (ETL/ELT), ensuring high performance and reliability.\n    Implement and manage data workflows, integrating internal and external data sources.\n    Collaborate with Data Scientists, AI/ML Engineers, and other stakeholders to ensure data readiness for analytics and model training.\n    Monitor data pipelines for performance, reliability, and cost-effectiveness, taking corrective actions when needed.\n    Maintain data quality and governance standards, including metadata management and data cataloging.\n  &lt;/KeyResponsibilities&gt;\n  &lt;SkillsAndTools&gt;\n    Proficiency in Python, SQL, and distributed data processing frameworks (e.g., Spark, Kafka).\n    Experience with cloud-based data ecosystems (AWS, GCP, or Azure), and related storage/processing services (e.g., S3, BigQuery, Dataflow).\n    Familiarity with infrastructure-as-code and DevOps tools (Terraform, Docker, Kubernetes) for automating data platform deployments.\n    Strong understanding of database systems (relational, NoSQL) and data modeling principles.\n    Knowledge of data orchestration and workflow management tools (Airflow, Luigi, Dagster).\n  &lt;/SkillsAndTools&gt;\n&lt;/Option&gt;\n&lt;Option title=\"Product Manager\" number=\"7\"&gt;\n  &lt;PrimaryFocus&gt;\n    Drive the product vision and strategy, ensuring alignment with business goals and user needs while delivering impactful AI-driven solutions.\n  &lt;/PrimaryFocus&gt;\n  &lt;KeyResponsibilities&gt;\n    Conduct user and market research to identify opportunities, define product requirements, and set success metrics.\n    Collaborate with cross-functional teams (Engineering, Data Science, Design) to prioritize features and plan releases.\n    Develop and communicate product roadmaps, ensuring stakeholders are aligned on goals and timelines.\n    Monitor product performance through data analysis and user feedback, iterating on improvements and new feature ideas.\n    Facilitate agile development practices, writing clear user stories and acceptance criteria.\n  &lt;/KeyResponsibilities&gt;\n  &lt;SkillsAndTools&gt;\n    Strong understanding of product lifecycle management and agile methodologies (Scrum/Kanban).\n    Excellent communication, negotiation, and stakeholder management skills.\n    Experience with product management and collaboration tools (e.g., Jira, Confluence, Trello).\n    Analytical mindset for leveraging metrics, A/B testing, and user feedback in decision-making.\n    Familiarity with AI/ML concepts and the ability to translate technical possibilities into viable product features.\n  &lt;/SkillsAndTools&gt;\n&lt;/Option&gt;\n&lt;Option title=\"Software Engineer\" number=\"8\"&gt;\n  &lt;PrimaryFocus&gt;\n  Design, develop, and maintain high-quality software applications and services that address user needs and align with overall business objectives.\n  &lt;/PrimaryFocus&gt;\n  &lt;KeyResponsibilities&gt;\n    Collaborate with cross-functional teams (Product, Design, QA) to interpret requirements and deliver robust solutions.\n    Write clean, efficient, and testable code following best practices and coding standards.\n    Participate in system architecture and design discussions, contributing to the evolution of technical roadmaps.\n    Perform code reviews and provide constructive feedback to peers, maintaining a high bar for code quality.\n    Implement and maintain CI/CD pipelines to streamline deployment and reduce manual interventions.\n    Continuously improve system performance and scalability through profiling and optimization.\n  &lt;/KeyResponsibilities&gt;\n  &lt;SkillsAndTools&gt;\n    Proficiency in one or more programming languages (e.g., Java, Python, JavaScript, C++).\n    Experience with modern frameworks/libraries (e.g., Spring Boot, Node.js, React, Django).\n    Solid understanding of software design principles (e.g., SOLID, DRY) and architectural patterns (e.g., microservices).\n    Familiarity with version control systems (Git), testing frameworks, and agile methodologies.\n    Working knowledge of containerization (Docker), orchestration (Kubernetes), and cloud platforms (AWS, Azure, GCP).\n  &lt;/SkillsAndTools&gt;\n&lt;/Option&gt;\n\"\"\"\n\nPROMPTS = {\n\"prompt\": \"\"\"\nYou will be given a list of Responsibilities and\nSkills listed for a job. Your task is to determine\nif the job is a good fit with any of the Options,\nand if so, which one.\n\n&lt;Job&gt;\n&lt;Responsibilities&gt;\n{responsibilities}\n&lt;/Responsibilities&gt;\n&lt;Skills&gt;\n{skills}\n&lt;/Skills&gt;\n&lt;/Job&gt;\n\n&lt;Options&gt;\n{Options}\n&lt;/Options&gt;\n\nStart by thinking step-by-step about the Job and its \nResponsibilities and Skills, in relation to each of the \nOptions.\n\nDecide if the Job is a good fit with ANY of the Options.\nIf NONE of the Options are relevant to the Job, say so and \nreturn a 0 as your FinalAnswer.\n\nOtherwise, decide which of the Options is the most similar\nto the Job and return its number as your FinalAnswer.\n\nReturn your response in the following format:\n&lt;Analysis&gt;\n[Your analysis of the job and its Responsibilities and Skills, in relation each of the Options]\n&lt;/Analysis&gt;\n&lt;FinalAnswer&gt;\n0|1|2|3|4|5|6|7|8\n&lt;/FinalAnswer&gt;\n\"\"\"\n}\n\n# Enable nested event loops\nnest_asyncio.apply()\n\n@dataclass\nclass JobData:\n    \"\"\"Represents a job posting with extracted information.\"\"\"\n    filename: str\n    responsibilities: List[str]\n    skills: List[str]\n\n@dataclass\nclass ClassificationResult:\n    \"\"\"Represents the result of a job classification.\"\"\"\n    filename: str\n    responsibilities: List[str]\n    skills: List[str]\n    analysis: str\n    role_classification: Optional[int]\n    role_title: Optional[str]\n\nclass JobClassifier:\n    \"\"\"Handles classification of jobs into predefined roles.\"\"\"\n    \n    def __init__(self, output_dir: str = 'role_classifications', batch_size: int = 3):\n        self.output_dir = output_dir\n        self.batch_size = batch_size\n        self.semaphore = asyncio.Semaphore(batch_size)\n        os.makedirs(output_dir, exist_ok=True)\n        \n    async def classify_job(self, job: JobData) -&gt; ClassificationResult:\n        \"\"\"Classify a single job listing.\"\"\"\n        logging.info(f\"Classifying job '{job.filename}'\")\n        \n        prompt = PROMPTS[\"prompt\"].format(\n            responsibilities=job.responsibilities,  # Access as attribute instead of dict\n            skills=job.skills,  # Access as attribute instead of dict\n            Options=JOB_DESCRIPTIONS\n        )\n        \n        try:\n            response = await get_completion(prompt)\n            await asyncio.sleep(5)  # Rate limiting\n            return self._parse_response(job, response)\n        except Exception as e:\n            logging.error(f\"Failed to classify job '{job.filename}': {str(e)}\")\n            return ClassificationResult(\n                filename=job.filename,\n                responsibilities=job.responsibilities,\n                skills=job.skills,\n                analysis=f'Failed to process: {str(e)}',\n                role_classification=None,\n                role_title=None\n            )\n    \n    def _parse_response(self, job: JobData, response: str) -&gt; ClassificationResult:\n        \"\"\"Parse LLM response into structured format.\"\"\"\n        soup = BeautifulSoup(f\"&lt;root&gt;{response}&lt;/root&gt;\", 'lxml-xml')\n        \n        analysis = soup.find('Analysis')\n        role_choice = soup.find('FinalAnswer')\n        role_number = int(role_choice.text.strip()) if role_choice else None\n        \n        role_title = self._get_role_title(role_number)\n        \n        return ClassificationResult(\n            filename=job.filename,\n            responsibilities=job.responsibilities,\n            skills=job.skills,\n            analysis=analysis.text.strip() if analysis else '',\n            role_classification=role_number,\n            role_title=role_title\n        )\n    \n    def _get_role_title(self, role_number: Optional[int]) -&gt; Optional[str]:\n        \"\"\"Get the title for a role number.\"\"\"\n        if role_number is None:\n            return None\n        if role_number == 0:\n            return \"Other\"\n            \n        wrapped_xml = f\"&lt;root&gt;{JOB_DESCRIPTIONS}&lt;/root&gt;\"\n        job_descriptions_soup = BeautifulSoup(wrapped_xml, 'lxml-xml')\n        matching_job = job_descriptions_soup.find('Option', {'number': str(role_number)})\n        \n        if matching_job:\n            return matching_job['title']\n        logging.error(f\"No matching job found for role number {role_number}\")\n        return None\n\nclass JobProcessor:\n    \"\"\"Handles the processing of job data files.\"\"\"\n    \n    def __init__(self, input_dir: str = 'json_extracted_data'):\n        self.input_dir = input_dir\n        self.classifier = JobClassifier()\n        \n    def load_jobs(self) -&gt; List[JobData]:\n        \"\"\"Load jobs from JSON files.\"\"\"\n        jobs = []\n        # Get list of all JSON files\n        total_files = len([f for f in os.listdir(self.input_dir) if f.endswith('.json')])\n        # Get files that were classified as GenAI-relevant\n        classified_files = self._get_classified_files()\n        # Get files that have already been processed\n        processed_files = {\n            f[:-5] for f in os.listdir(self.classifier.output_dir) \n            if f.endswith('.json')\n        }\n        # Get relevant files that haven't been processed yet\n        files_to_process = classified_files - processed_files\n        \n        logging.info(f\"Found {total_files} total files\")\n        logging.info(f\"Found {len(classified_files)} relevant GenAI files\")\n        logging.info(f\"Already processed: {len(processed_files)} files\")\n        logging.info(f\"Remaining to process: {len(files_to_process)} files\")\n        \n        # Only process files that are both relevant and unprocessed\n        for filename in os.listdir(self.input_dir):\n            if not filename.endswith('.json'):\n                continue\n                \n            name = filename[:-5]\n            if name not in files_to_process:\n                continue\n                \n            try:\n                job = self._load_job_file(filename)\n                if job:\n                    jobs.append(job)\n            except Exception as e:\n                logging.error(f\"Error processing {filename}: {str(e)}\")\n        \n        logging.info(f\"Processing {len(jobs)} remaining jobs\")\n        return jobs\n    \n    def _load_job_file(self, filename: str) -&gt; Optional[JobData]:\n        \"\"\"Load and parse a single job file.\"\"\"\n        file_path = os.path.join(self.input_dir, filename)\n        try:\n            with open(file_path, 'r') as f:\n                data = json.load(f)\n                if 'responsibilities' in data and 'skills' in data:\n                    return JobData(\n                        filename=filename[:-5],\n                        responsibilities=data['responsibilities'],\n                        skills=data['skills']\n                    )\n        except json.JSONDecodeError:\n            logging.error(f\"Invalid JSON in {filename}\")\n        return None\n    \n    def _get_classified_files(self) -&gt; Set[str]:\n        \"\"\"Get set of files that have been previously classified as GenAI-related.\"\"\"\n        genai_dir = 'role_genai_classifications'\n        if not os.path.exists(genai_dir):\n            return set()\n        \n        genai_files = set()\n        for f in os.listdir(genai_dir):\n            if f.endswith('.json'):\n                try:\n                    with open(os.path.join(genai_dir, f), 'r') as file:\n                        data = json.load(file)\n                        if data.get('is_genai_role') is True:  # Explicitly check for True\n                            genai_files.add(f[:-5])\n                except Exception as e:\n                    logging.error(f\"Error reading {f}: {e}\")\n        return genai_files\n    \n    async def process_jobs(self) -&gt; None:\n        \"\"\"Process all jobs.\"\"\"\n        jobs = self.load_jobs()\n        if not jobs:\n            return\n            \n        logging.info(f\"Processing {len(jobs)} relevant jobs\")\n        await self._process_jobs_batch(jobs)\n        logging.info(\"Job classification complete\")\n    \n    async def _process_jobs_batch(self, jobs: List[JobData]) -&gt; None:\n        \"\"\"Process a batch of jobs concurrently.\"\"\"\n        async def process_with_semaphore(job: JobData) -&gt; None:\n            async with self.classifier.semaphore:\n                result = await self.classifier.classify_job(job)\n                self._save_result(result)\n        \n        await asyncio.gather(*[process_with_semaphore(job) for job in jobs])\n    \n    def _save_result(self, result: ClassificationResult) -&gt; None:\n        \"\"\"Save classification result to file.\"\"\"\n        filename = os.path.join(self.classifier.output_dir, f\"{result.filename}.json\")\n        with open(filename, 'w') as f:\n            json.dump(vars(result), f, indent=2)\n        logging.info(f\"Saved classification for job {result.filename}\")\n\ndef classify_job_roles(df: pd.DataFrame) -&gt; None:\n    \"\"\"Main entry point for job classification.\"\"\"\n    if df.empty:\n        logging.warning(\"Empty DataFrame provided\")\n        return\n        \n    processor = JobProcessor()\n    loop = asyncio.get_event_loop()\n    loop.run_until_complete(processor.process_jobs())\n\n\n\nimport logging\nlogging.basicConfig(level=logging.INFO)\nloader = JobDataLoader()\njobs = loader.read_json_files()\ndf = pd.DataFrame(jobs)\nclassify_job_roles(df)\n\n2025-01-24 13:50:53,982 - INFO - Found 739 total files\n2025-01-24 13:50:53,982 - INFO - Found 247 relevant GenAI files\n2025-01-24 13:50:53,983 - INFO - Already processed: 247 files\n2025-01-24 13:50:53,983 - INFO - Remaining to process: 0 files\n2025-01-24 13:50:53,984 - INFO - Processing 0 remaining jobs"
  },
  {
    "objectID": "blog/2025/01/24/index.html#o1-generated-senior-ai-research-scientist",
    "href": "blog/2025/01/24/index.html#o1-generated-senior-ai-research-scientist",
    "title": "Analysis of the GenAI/LLM job market in January 2025",
    "section": "o1-generated Senior AI Research Scientist",
    "text": "o1-generated Senior AI Research Scientist\nHere’s what o1 said about the Responsibilities and Skills observed in Senior AI Research Scientist roles:\n\nResponsibilities\n\nConduct advanced AI research\nMany roles require pushing the state-of-the-art in Generative AI, LLMs, and related areas (e.g., video/multimodal models, diffusion models) through novel algorithms, architectures, and experimental studies.\nTrain and fine-tune large-scale models\nCommonly involves working with massive datasets and distributed training setups (thousands of GPUs, HPC environments) to develop foundation models and advanced AI systems.\nDevelop and implement new algorithms or architectures\nSpans designing novel model architectures (e.g., diffusion, transformer-based, multimodal fusion) and creating robust data processing or simulation pipelines to support AI solutions.\nCollaborate with cross-functional teams\nEmphasizes close work with engineering, product management, research, and external stakeholders to integrate AI breakthroughs into real-world applications and products.\nEvaluate and measure AI performance\nEntails building rigorous evaluation frameworks, designing new metrics, and systematically analyzing model behavior to ensure quality and reliability.\nPublish and communicate research findings\nMany positions highlight writing influential papers, presenting at conferences, and sharing innovative results both internally and with the broader AI community.\nBuild and maintain data pipelines\nInvolves constructing high-quality, scalable data pipelines or tooling to support training, fine-tuning, and inference of large models.\nEnsure production-grade implementation\nRequires writing clean, efficient, and maintainable code as well as optimizing models and pipelines to meet performance, reliability, and quality standards.\n\n\n\nSkills\n\nProficiency in Python and deep learning frameworks\nStrong coding skills in Python and hands-on experience with libraries such as PyTorch, TensorFlow, or JAX appear in nearly every role.\nExpertise with LLMs and Generative AI\nDeep understanding of transformer architectures, diffusion models, multimodal systems, prompt engineering, and other advanced AI techniques is frequently mentioned.\nExperience with large-scale/distributed training\nMany roles emphasize knowledge of HPC, GPU optimization, model parallelism (e.g., FSDP, DeepSpeed, Megatron-LM), and handling massive datasets.\nStrong software engineering practices\nTesting, code review, debugging, version control, and producing clean, modular research or production code are consistently important.\nCollaboration and communication skills\nClear written and verbal communication, along with cross-functional teamwork, is vital for integrating AI solutions into products and relaying complex ideas.\nResearch acumen and adaptability\nAbility to read, interpret, and prototype cutting-edge AI literature, publish findings, and rapidly iterate on experiments.\nMachine Learning fundamentals\nSolid grounding in ML theory (e.g., optimization, statistics, data structures) and experience with model evaluation, data manipulation, and pipeline design.\nFamiliarity with prompt engineering and advanced NLP concepts\nMany roles highlight crafting effective prompts, aligning model outputs with user needs, and leveraging text-generation or conversational AI techniques."
  },
  {
    "objectID": "blog/2025/01/24/index.html#o1-generated-senior-ai-ml-engineer",
    "href": "blog/2025/01/24/index.html#o1-generated-senior-ai-ml-engineer",
    "title": "Analysis of the GenAI/LLM job market in January 2025",
    "section": "o1-generated Senior AI ML Engineer",
    "text": "o1-generated Senior AI ML Engineer\nAnd here’s what o1 said about the Responsibilities and Skills observed in Senior AI ML Engineer roles:\n\nResponsibilities\n\nDesign, develop, and deploy AI/ML solutions\nEnd-to-end creation of machine learning systems, from initial prototypes to production-ready deployments.\nCollaborate with cross-functional teams\nWork closely with product managers, data scientists, engineers, and other stakeholders to align technical solutions with business goals.\nMonitor and optimize model performance\nTrack key metrics, fine-tune models, and iterate to ensure continuous improvement and reliability in production.\nStay current with AI research and emerging technologies\nKeep up-to-date with the latest breakthroughs in areas like LLMs, generative AI, and deep learning.\nMentor and coach team members\nProvide guidance on best practices, design patterns, code quality, and career development for junior or peer engineers.\nDevelop scalable data/ML pipelines\nBuild robust infrastructure for data collection, preprocessing, model training, and deployment at scale.\nImplement and maintain CI/CD and coding best practices\nEnsure code quality, streamline release processes, and enforce testing discipline for AI/ML components.\nIntegrate and leverage LLMs/generative AI\nIncorporate large language models or generative methods into products and workflows.\nPrototype and experiment\nConduct R&D, proof-of-concepts, and pilot programs to explore emerging AI techniques and validate new product ideas.\nDocument and communicate findings\nProduce clear technical documentation, share results with stakeholders, and provide actionable insights for decision-making.\n\n\n\nSkills\n\nProficiency in Python\nCommonly required for AI/ML development, data manipulation, and scripting.\nExperience with ML/DL frameworks\nHands-on expertise in tools like PyTorch, TensorFlow, or JAX for building and training models.\nFamiliarity with cloud platforms\nWorking knowledge of AWS, GCP, or Azure for deploying and scaling AI solutions.\nExpertise in LLMs/generative AI\nUnderstanding of transformer architectures, prompt engineering, retrieval-augmented generation (RAG), and related libraries.\nStrong software engineering fundamentals\nSolid grasp of algorithms, data structures, design patterns, and best practices for production code.\nKnowledge of MLOps and CI/CD\nExperience with containerization (Docker, Kubernetes), version control (Git), and automated testing/monitoring.\nData processing and SQL\nSkills in handling large datasets, working with Spark or similar frameworks, and writing performant SQL queries.\nEffective communication and collaboration\nAbility to translate complex technical concepts for non-technical stakeholders and work well in diverse teams.\nProblem-solving and debugging\nTrack record of diagnosing issues in production environments and implementing reliable fixes.\nContinuous learning mindset\nEagerness to stay on top of new AI research, frameworks, and technologies to innovate and improve solutions."
  },
  {
    "objectID": "blog/2023/12/09/index.html",
    "href": "blog/2023/12/09/index.html",
    "title": "AI Math Tutoring: Using GPT to generate “step-by-step guidance”",
    "section": "",
    "text": "Imagine you’re developing an AI Math Tutor application: You have a set of math questions that student users can answer, along with the correct answers to those questions. Students will sometimes get stuck answering multi-step problems, and in those situations you want them to be able to ask an AI tutor for help. An AI Tutoring interaction that can be helpful is one where a student asks the tutor for step-by-step guidance.\n\n\nSimple AI Math Tutor mock-up (mouse cursor is from kindpng.com)\n\nIn this blog post, I show how a “step-by-step guidance” feature could be developed using GPT and prompt engineering, and how this guidance can be validated. As a demonstration, I use a multi-step math problem that I’ve found GPT-3.5 often struggles to answer. I show how this step-by-step guidance can be validated by asking GPT to solve the problem using its own instructions and then comparing its “stepwise” performance against the performance of a baseline model.\nImports and setup\n\n\n\nR\n\nlibrary(reticulate)\nlibrary(tidyverse)\n# Add OpenAI key to environment\npy_run_string(\"import os\")\npy_run_string(paste0(\"os.environ['OPENAI_API_KEY'] = '\", Sys.getenv('OPENAI_API_KEY'), \"'\"))\n\n\n\n\n\npython\n\nimport pandas as pd\nimport numpy as np\nimport ujson as json\nimport inspect\nimport textwrap\nfrom multiprocessing.pool import ThreadPool\npool = ThreadPool()\n\n\nImport python prompting functions\nIn order to use parallelization within an interactive notebook using the multiprocessing package, it’s necessary to write the python functions to-be-parallelized to disk and import them. I’ll import the functions here, and introduce these functions later in the post as I use them.\n\n\n\npython\n\nfrom prompt_functions import get_response, baseline_solver, step_generator, stepwise_solver\n\n\nTest case\nAs a test case, I’ll use a math problem that I’ve found GPT has some difficulty solving. This problem comes from the GSM8K dataset. Although it’s a grade school math problem which should be very easy, it requires multiple reasoning steps. If any one step is wrong, the final answer is likely to be incorrect.\n\n\n\npython\n\nquestion = 'Gail has two fish tanks. The first tank is twice the size of the second tank. There are 48 gallons of water in the first tank. She follows the rule of one gallon of water per inch of fish. If she keeps two-inch fish in the second tank and three-inch fish in the first tank, how many more fish would Gail have in the first tank than the second tank if one of the first tank fish eats another?'\nprint(textwrap.fill(question, width=80))\n\n\nGail has two fish tanks. The first tank is twice the size of the second tank.\nThere are 48 gallons of water in the first tank. She follows the rule of one\ngallon of water per inch of fish. If she keeps two-inch fish in the second tank\nand three-inch fish in the first tank, how many more fish would Gail have in the\nfirst tank than the second tank if one of the first tank fish eats another?\n\n\nBaseline solver\nIn order to generate steps that an AI Tutor could suggest to a student, I’ll first get GPT to “discover” how to correctly solve the problem on its own. I’ll use the baseline_solver() function, which implements a simple chain-of-thought prompt.\n\n\n\npython\n\nprint(inspect.getsource(baseline_solver))\n\n\ndef baseline_solver(question):\n    instructions = \"Solve the math problem delimited by triple backticks.\"\n    user_content = f\"```{question}```\\nLet's work this out in a step by step way to be sure we have the right answer\"\n    msg = [\n        {\"role\": \"system\", \"content\": instructions},\n        {\"role\": \"user\", \"content\": user_content}\n    ]\n    solution = get_response(msg=msg, temp=0.5)\n    answer = identify_final_answer(solution)\n    return {\n      'is_correct': answer == '3',\n      'solution': solution,\n      'question': question,\n      'answer': answer\n    }\n\n\nI’ll give it 100 attempts to solve the problem.\n\n\n\npython\n\ntry: # Read from disk if I've done this already\n  df_baseline = pd.read_json('baseline_solver_results.ndjson')\nexcept:\n  baseline_results = pool.map(baseline_solver, 100*[question])\n  df_baseline = pd.DataFrame(baseline_results, columns=['is_correct', 'solution', 'question', 'answer'])\n  df_baseline.to_json('baseline_solver_results.ndjson', orient='records')\n\n\nIdentify solution steps\nUsing correct answers from the 100 attempts above, I’ll pick a few examples and ask GPT to synthesize and generalize the steps.\nFor this task I’ll use the step_generator() function, which asks GPT to synthesize the steps from three different solutions provided as input. It also asks GPT to remove any calculations from those steps, which is important for an AI Tutor – after all, we don’t want to give away the answer!\n\n\n\npython\n\nprint(inspect.getsource(step_generator))\n\n\ndef step_generator(solutions):\n    instructions = '''\n      You're given three different solutions to a single math problem, delimited by\n      triple hashtags. Synthesize the solutions into a final set of steps to solve\n      the problem. Remove any calculations from the instructions, leaving only the\n      steps.\n    '''\n    user_content = f'''\n      ###\n      Solution 1: \n      {solutions[0]}\n      ---\n      \n      Solution 2: \n      {solutions[1]}\n      ---\n      \n      Solution 3: \n      {solutions[2]}\n      ###\n      \n      Synthesize the three solutions above. Remove any calculations from the \n      instructions, leaving only the steps.\n    '''\n    msg = [\n        {\"role\": \"system\", \"content\": instructions},\n        {\"role\": \"user\", \"content\": user_content}\n    ]\n    return get_response(msg=msg, temp=0.3)\n\n\nHere’s what the final set of steps looks like:\n\n\n\npython\n\ntry: # Read from disk if I've done this already\n  f = open(\"steps.txt\", \"r\")\n  steps = f.read()\n  print(steps)\nexcept:\n  solutions = df_baseline[df_baseline['is_correct'] == True]['solution'].values[0:3]\n  steps = step_generator(solutions)\n  \n  f = open(\"steps.txt\", \"w\")\n  f.write(steps)\n  f.close()\n  \n  print(steps)\n\n\nTo solve the problem, follow these steps:\n\n1. Find the size of the second tank by dividing the size of the first tank by 2.\n2. Determine the number of fish that can be kept in each tank based on the rule of one gallon of water per inch of fish.\n3. Calculate the number of fish that can be kept in the second tank by dividing the size of the second tank by 2.\n4. Calculate the number of fish that can be kept in the first tank by dividing the size of the first tank by 3.\n5. Subtract 1 from the number of fish in the first tank to account for one fish eating another.\n6. Subtract the number of fish in the second tank from the number of fish in the first tank to find the difference.\n7. Determine the final answer, which is the difference in the number of fish between the two tanks.\n\n\nStepwise solver\nNext, I’ll validate the steps generated above using stepwise_solver(), a function that asks GPT to solve the problem using the steps provided. I expect that providing GPT with the steps above will improve its performance by a significant margin.\n\n\n\npython\n\nprint(inspect.getsource(stepwise_solver))\n\n\ndef stepwise_solver(question, steps):\n    instructions = \"Solve the math problem in triple backticks, using the steps provided in triple hashtags.\"\n    user_content = f\"```{question}```\\n\\n###{steps}###\"\n    msg = [\n        {\"role\": \"system\", \"content\": instructions},\n        {\"role\": \"user\", \"content\": user_content}\n    ]\n    solution = get_response(msg=msg, temp=0.5)\n    answer = identify_final_answer(solution)\n    return {\n      'is_correct': answer == '3',\n      'solution': solution,\n      'question': question,\n      'steps': steps,\n      'answer': answer\n    }\n\n\n\n\n\npython\n\ntry: # Read from disk if I've done this already\n  df_stepwise = pd.read_json('stepwise_solver_results.ndjson')\nexcept:\n  stepwise_results = pool.starmap(stepwise_solver, zip(100*[question], 100*[steps]))\n  df_stepwise = pd.DataFrame(stepwise_results, columns=['is_correct', 'solution', 'question', 'steps', 'answer'])\n  df_stepwise.to_json('stepwise_solver_results.ndjson', orient='records')\n\n\nHere we can see that by providing the GPT solver with steps derived from correct solutions, performance was almost doubled (from 39% to 77% correct responses). This provides important validation for an AI Tutor with “step-by-step guidance” functionality, because now we know that by following these steps the student would be likely to arrive at the correct answer.\n\n\n\npython\n\nprint(f'''\nBaseline solver: {round(np.mean(df_baseline['is_correct'])*100)}% correct\nStepwise solver: {round(np.mean(df_stepwise['is_correct'])*100)}% correct\n''')\n\n\n\nBaseline solver: 39% correct\nStepwise solver: 77% correct\n\n\n\n\n\nR\n\ntibble(`Baseline Solver` = 39, `Stepwise Solver` = 77) %&gt;% \n  pivot_longer(everything()) %&gt;%\n  ggplot(aes(x = name, y = value, fill = name)) + \n    geom_col(width = 0.5) + \n    geom_text(aes(x = name, y = value, label = paste0(round(value), '%')), vjust=-0.5) +\n    labs(\n      x = '',\n      y = '% correct (out of 100)',\n      title = 'Validating the step-by-step guidance, performance of the\\nStepwise Solver was roughly double the Baseline Solver.'\n    ) +\n    ylim(0, 100) +\n    theme(legend.position = \"none\",\n          text = element_text(size=14),\n          axis.text.x = element_text(size=12),\n          axis.text.y = element_text(size=12),  \n          axis.title.x = element_text(size=12),\n          axis.title.y = element_text(size=12))\n\n\n\n\n\n\n\n\nAI Tutor interaction\nHaving generated and validated the step-by-step guidance, we can now begin to imagine what the user interaction would look like. It could take the form of a single interaction, where a student asks for help and the AI Tutor provides all of the steps at once.\n\n\n\npython\n\nprint(steps)\n\n\nTo solve the problem, follow these steps:\n\n1. Find the size of the second tank by dividing the size of the first tank by 2.\n2. Determine the number of fish that can be kept in each tank based on the rule of one gallon of water per inch of fish.\n3. Calculate the number of fish that can be kept in the second tank by dividing the size of the second tank by 2.\n4. Calculate the number of fish that can be kept in the first tank by dividing the size of the first tank by 3.\n5. Subtract 1 from the number of fish in the first tank to account for one fish eating another.\n6. Subtract the number of fish in the second tank from the number of fish in the first tank to find the difference.\n7. Determine the final answer, which is the difference in the number of fish between the two tanks.\n\n\nOr the AI Tutor could provide the steps one at a time – i.e., one step is given each time the student asks for help.\n\n\n\npython\n\n# Print step 1\nprint(steps.split('\\n')[2])\n\n\n1. Find the size of the second tank by dividing the size of the first tank by 2.\n\n\n\n\n\npython\n\n# Print step 2\nprint(steps.split('\\n')[3])\n\n\n2. Determine the number of fish that can be kept in each tank based on the rule of one gallon of water per inch of fish.\n\n\nProviding steps one-at-a-time could be implemented as part of a “progressive” hint system. In an educational math game, for example, the student could receive full points for giving a correct answer with zero assistance, and the number of points earned could be reduced every time they ask for a step hint.\nIn this implementation I’ve deliberately removed the results from each step. But we could imagine an interaction where the AI first gives a step, and then optionally provides the result obtained at that step. This could help the student figure out at which step they’re making a mistake."
  },
  {
    "objectID": "blog/2023/10/08/index.html",
    "href": "blog/2023/10/08/index.html",
    "title": "Using GPT-4 for classification",
    "section": "",
    "text": "GPT is a powerful new tool in the Data Science toolkit. Used correctly, it can increase productivity while decreasing the “drudgery” of boring tasks like data cleaning. I’ve been trying to find ways to integrate GPT into my data science workflow, and I thought it might be fun to use it with the latest Tidy Tuesday. (US Government Grant Opportunities). So in this blog post, I use GPT to classify US grant-funding agencies into categories using government agency names."
  },
  {
    "objectID": "blog/2023/10/08/index.html#ask-it-to-classify-agencies-using-agency-names-and-categories",
    "href": "blog/2023/10/08/index.html#ask-it-to-classify-agencies-using-agency-names-and-categories",
    "title": "Using GPT-4 for classification",
    "section": "2. Ask it to classify agencies using agency names and categories",
    "text": "2. Ask it to classify agencies using agency names and categories\nNext, using the agency names and categories generated above I’ll ask GPT to do classification. First, I’ll define a function that takes a category as input and runs a query against GPT asking it to put the agencies into the provided category, returning a list of agencies that it put in that category. Although I could ask GPT to classify agencies using all categories in a single query, I expect this would be less reliable than tackling each category separately. One of the trade-offs here is that I won’t get mutual exclusivity of the categories, since GPT won’t know how it’s already classified agencies. For this analysis, let’s assume I don’t want mutual exclusivity.\n\nget_agencies_in_category &lt;- function(category) {\n  query &lt;-paste0(\n    \"I'm going to present a comma-separated list of US agencies,\n    delimited by triple backticks (```), and a single category to \n    which some of the agencies belong, delimited by triple hashtags (###). \n    Your task is to provide a comma-separated list of agency names that \n    belong in the category provided.\n    ```\", agencies_str,  \"```\n    ###\", category, \"###\"\n  )\n  results &lt;- chatGPT(query)\n  \n  # Return as a vector\n  trimws(strsplit(results, \",\")[[1]])\n}\n\nUsing the function above, I’ll query GPT for each of the categories, saving the results into a list called agencies_categorized.\n\nif(!exists('agencies_categorized')){\n  agencies_categorized &lt;- list()\n  for (category in categories){\n    if(category != 'Other'){\n      agencies_categorized[[category]] &lt;- get_agencies_in_category(category) \n    }\n  }\n  \n  # Save to disk\n  save(agencies_categorized, file = 'agencies_categorized.Rdata')\n}\n  \nprint(agencies_categorized)\n\n$`Defense and Military`\n [1] \"69A345 Office of the Under Secretary for Policy\"   \n [2] \"69A350 OSDBU\"                                      \n [3] \"69A355 Research and Technology\"                    \n [4] \"ACC APG - Natick\"                                  \n [5] \"ACC-APG-Aberdeen Division A\"                       \n [6] \"ACC-APG-Belvoir\"                                   \n [7] \"ACC-APG-Detrick\"                                   \n [8] \"ACC-APG-Edgewood\"                                  \n [9] \"ACC-APG-Fort Huachuca\"                             \n[10] \"Air Force -- Materiel Command\"                     \n[11] \"Air Force -- Research Lab\"                         \n[12] \"Air Force Academy\"                                 \n[13] \"Air Force Office of Scientific Research\"           \n[14] \"Alaska District\"                                   \n[15] \"Army Contracting Command - Benet Laboratories\"     \n[16] \"Army Contracting Command - New Jersey\"             \n[17] \"Army Contracting Command Rock Island\"              \n[18] \"Bureau of Diplomatic Security\"                     \n[19] \"Bureau of International Security-Nonproliferation\" \n[20] \"Bureau of Political-Military Affairs - GPI\"        \n[21] \"Bureau of Political-Military Affairs - WRA\"        \n[22] \"DARPA - Biological Technologies Office\"            \n[23] \"DARPA - Defense Sciences Office\"                   \n[24] \"DARPA - Information Innovation Office\"             \n[25] \"DARPA - Information Processing Technology Office\"  \n[26] \"DARPA - Microsystems Technology Office\"            \n[27] \"DARPA - Strategic Technology Office\"               \n[28] \"DARPA - Tactical Technology Office\"                \n[29] \"DARPA - Transformational Convergence Technology\"   \n[30] \"DARPA-MTO-BAA-09-25\"                               \n[31] \"Defense Advanced Research Projects Agency\"         \n[32] \"Defense Health Agency\"                             \n[33] \"Defense Intelligence Agency\"                       \n[34] \"Defense Logistics Agency\"                          \n[35] \"Defense Threat Reduction Agency\"                   \n[36] \"Department of Defense\"                             \n[37] \"Dept of the Army -- Materiel Command\"              \n[38] \"Dept. of the Army  --  Corps of Engineers\"         \n[39] \"Dept. of the Army -- Space & Missle Defense Comman\"\n[40] \"Dept. of the Army -- USAMRAA\"                      \n[41] \"DoD Education Activity\"                            \n[42] \"DOT - FAA Aviation Research Grants\"                \n[43] \"DOT - FAA Centers of Excellence\"                   \n[44] \"DOT Federal Aviation Administration\"               \n[45] \"Engineer Research and Development Center\"          \n[46] \"Fort Worth District\"                               \n[47] \"Kansas City District\"                              \n[48] \"Missile Defense Agency\"                            \n[49] \"Mission and Install. Cmd. JBSA Ft. Sam Houston\"    \n[50] \"NAVAIR\"                                            \n[51] \"Naval Air Warfare Center Aircraft Div. Lakehurst\"  \n[52] \"NAVAL FACILITIES ENGINEERING COMMAND\"              \n[53] \"Naval Facilities Engineering Command Southwest\"    \n[54] \"Naval Information Warfare Center Pacific\"          \n[55] \"NAVAL MEDICAL LOGISTICS COMMAND\"                   \n[56] \"Naval Research Laboratory\"                         \n[57] \"Naval Supply Systems Command\"                      \n[58] \"Naval Surface Warfare Center - Carderock\"          \n[59] \"NAVFAC Atlantic\"                                   \n[60] \"NAVFAC Washington DC\"                              \n[61] \"NCA Contracting\"                                   \n[62] \"NEA Cooperative Agreements Office\"                 \n[63] \"NSWC - CRANE\"                                      \n[64] \"NSWC Indian Head\"                                  \n[65] \"NUWC Division Keyport\"                             \n[66] \"Office of Local Defense Community Cooperation\"     \n[67] \"Office of Naval Research\"                          \n[68] \"Office of the Director of National Intelligence\"   \n[69] \"Omaha District\"                                    \n[70] \"Savannah District\"                                 \n[71] \"Seattle District\"                                  \n[72] \"SPAWAR SYSTEMS CENTER\"                             \n[73] \"U.S. Dept. of Treasury RESTORE Act Program\"        \n[74] \"U.S. Mission to NATO\"                              \n[75] \"United States Coast Guard\"                         \n[76] \"United States Marine Corps\"                        \n[77] \"USAF 347 Contracting Squadron\"                     \n[78] \"Washington Headquarters Services\"                  \n\n$`Science and Technology`\n [1] \"69A345 Office of the Under Secretary for Policy\"   \n [2] \"69A355 Research and Technology\"                    \n [3] \"Advanced Research Projects Agency Energy\"          \n [4] \"Advanced Research Projects Agency for Health\"      \n [5] \"Agency for Health Care Research and Quality\"       \n [6] \"Agricultural Research Service\"                     \n [7] \"Air Force -- Research Lab\"                         \n [8] \"Air Force Office of Scientific Research\"           \n [9] \"Army Contracting Command - Benet Laboratories\"     \n[10] \"Bureau of Oceans - Int. Environmental - Scientific\"\n[11] \"Centers for Disease Control - ATSDR\"               \n[12] \"Centers for Disease Control - CFA\"                 \n[13] \"Centers for Disease Control - CGH\"                 \n[14] \"Centers for Disease Control - CSELS\"               \n[15] \"Centers for Disease Control - NCBDDD\"              \n[16] \"Centers for Disease Control - NCCDPHP\"             \n[17] \"Centers for Disease Control - NCEH\"                \n[18] \"Centers for Disease Control - NCEZID\"              \n[19] \"Centers for Disease Control - NCHHSTP\"             \n[20] \"Centers for Disease Control - NCHS\"                \n[21] \"Centers for Disease Control - NCIPC\"               \n[22] \"Centers for Disease Control - NCIRD\"               \n[23] \"Centers for Disease Control - NIOSH\"               \n[24] \"Centers for Disease Control - OD\"                  \n[25] \"Centers for Disease Control - OPHPR\"               \n[26] \"Centers for Disease Control - OSTLTS\"              \n[27] \"Centers for Disease Control and Prevention\"        \n[28] \"Centers for Disease Control and Prevention - ERA\"  \n[29] \"DARPA - Biological Technologies Office\"            \n[30] \"DARPA - Defense Sciences Office\"                   \n[31] \"DARPA - Information Innovation Office\"             \n[32] \"DARPA - Information Processing Technology Office\"  \n[33] \"DARPA - Microsystems Technology Office\"            \n[34] \"DARPA - Strategic Technology Office\"               \n[35] \"DARPA - Tactical Technology Office\"                \n[36] \"DARPA - Transformational Convergence Technology\"   \n[37] \"Defense Advanced Research Projects Agency\"         \n[38] \"Defense Health Agency\"                             \n[39] \"Defense Intelligence Agency\"                       \n[40] \"Defense Threat Reduction Agency\"                   \n[41] \"Department of Energy\"                              \n[42] \"DoD Education Activity\"                            \n[43] \"DOT - FAA Aviation Research Grants\"                \n[44] \"DOT - FAA Centers of Excellence\"                   \n[45] \"DOT Federal Aviation Administration\"               \n[46] \"Economic Research Service\"                         \n[47] \"Engineer Research and Development Center\"          \n[48] \"Environmental Protection Agency\"                   \n[49] \"FAA - Aviation Next Gen\"                           \n[50] \"FAA-COE-AJFE\"                                      \n[51] \"FAA-COE-GA\"                                        \n[52] \"FAA-COE-TTHP\"                                      \n[53] \"Food and Drug Administration\"                      \n[54] \"Geological Survey\"                                 \n[55] \"Health Resources and Services Administration\"      \n[56] \"Indian Health Service\"                             \n[57] \"Institute of Museum and Library Services\"          \n[58] \"National Aeronautics and Space Administration\"     \n[59] \"National Energy Technology Laboratory\"             \n[60] \"National Geospatial-Intelligence Agency\"           \n[61] \"National Highway Traffic Safety Administration\"    \n[62] \"National Institute of Food and Agriculture\"        \n[63] \"National Institute of Justice\"                     \n[64] \"National Institute of Standards and Technology\"    \n[65] \"National Institutes of Health\"                     \n[66] \"National Oceanic and Atmospheric Administration\"   \n[67] \"National Park Service\"                             \n[68] \"National Science Foundation\"                       \n[69] \"National Telecommunications and Information Admini\"\n[70] \"Naval Research Laboratory\"                         \n[71] \"Naval Supply Systems Command\"                      \n[72] \"Naval Surface Warfare Center - Carderock\"          \n[73] \"NNSA\"                                              \n[74] \"Nuclear Regulatory Commission\"                     \n[75] \"NUWC Division Keyport\"                             \n[76] \"Oak Ridge Office\"                                  \n[77] \"Office of Science\"                                 \n[78] \"Office of the Assistant Secretary for Health\"      \n[79] \"Office of the Director of National Intelligence\"   \n[80] \"Office of the National Coordinator\"                \n[81] \"Pipeline and Hazardous Materials Safety Admin\"     \n[82] \"Risk Management Agency\"                            \n[83] \"Science and Technology Directorate\"                \n[84] \"Substance Abuse and Mental Health Services Admin\"  \n[85] \"Substance Abuse and Mental Health Services Adminis\"\n[86] \"Uniformed Services Univ. of the Health Sciences\"   \n[87] \"USUHS Medical - Non- Research Projects\"            \n[88] \"USUHS Medical Research Projects\"                   \n[89] \"USAID\"                                             \n[90] \"Woodrow Wilson Center\"                             \n\n$`Health and Medicine`\n [1] \"Administration for Children & Families - ACYF/FYSB\"\n [2] \"Administration for Children and Families\"          \n [3] \"Administration for Children and Families - ACYF/CB\"\n [4] \"Administration for Children and Families - ANA\"    \n [5] \"Administration for Children and Families - OCC\"    \n [6] \"Administration for Children and Families - OCS\"    \n [7] \"Administration for Children and Families - OCSE\"   \n [8] \"Administration for Children and Families - OFA\"    \n [9] \"Administration for Children and Families - OHS\"    \n[10] \"Administration for Children and Families - OHSEPR\" \n[11] \"Administration for Children and Families - OPRE\"   \n[12] \"Administration for Children and Families - ORR\"    \n[13] \"Administration for Children and Families-IOAS-OTIP\"\n[14] \"Administration for Community Living\"               \n[15] \"Administration on Aging\"                           \n[16] \"Advanced Research Projects Agency for Health\"      \n[17] \"Agency for Health Care Research and Quality\"       \n[18] \"Centers for Disease Control - ATSDR\"               \n[19] \"Centers for Disease Control - CFA\"                 \n[20] \"Centers for Disease Control - CGH\"                 \n[21] \"Centers for Disease Control - CSELS\"               \n[22] \"Centers for Disease Control - NCBDDD\"              \n[23] \"Centers for Disease Control - NCCDPHP\"             \n[24] \"Centers for Disease Control - NCEH\"                \n[25] \"Centers for Disease Control - NCEZID\"              \n[26] \"Centers for Disease Control - NCHHSTP\"             \n[27] \"Centers for Disease Control - NCHS\"                \n[28] \"Centers for Disease Control - NCIPC\"               \n[29] \"Centers for Disease Control - NCIRD\"               \n[30] \"Centers for Disease Control - NIOSH\"               \n[31] \"Centers for Disease Control - OD\"                  \n[32] \"Centers for Disease Control - OPHPR\"               \n[33] \"Centers for Disease Control - OSTLTS\"              \n[34] \"Centers for Disease Control and Prevention\"        \n[35] \"Centers for Disease Control and Prevention - ERA\"  \n[36] \"Centers for Medicare & Medicaid Services\"          \n[37] \"CMS Consumer Operated and Oriented Plan Program\"   \n[38] \"CMS-Consumer Information & Insurance Oversight\"    \n[39] \"Defense Health Agency\"                             \n[40] \"Department of Health and Human Services\"           \n[41] \"Food and Drug Administration\"                      \n[42] \"Health Resources and Services Administration\"      \n[43] \"Indian Health Service\"                             \n[44] \"National Institute of Food and Agriculture\"        \n[45] \"National Institutes of Health\"                     \n[46] \"Office of the Assistant Secretary for Health\"      \n[47] \"Office of the National Coordinator\"                \n[48] \"Substance Abuse and Mental Health Services Admin\"  \n[49] \"Substance Abuse and Mental Health Services Adminis\"\n[50] \"Uniformed Services Univ. of the Health Sciences\"   \n[51] \"USUHS Medical - Non- Research Projects\"            \n[52] \"USUHS Medical Research Projects\"                   \n[53] \"VA Office of Mental Health\"                        \n[54] \"VHA Member Services-Veterans Transportation\"       \n\n$`International Aid`\n [1] \"Afghanistan USAID-Kabul\"                        \n [2] \"Africa Regional Services\"                       \n [3] \"Agency for International Development\"           \n [4] \"Albania USAID-Tirana\"                           \n [5] \"Armenia USAID-Yerevan\"                          \n [6] \"Azerbaijan USAID-Baku\"                          \n [7] \"Bangladesh USAID-Dhaka\"                         \n [8] \"Benin USAID-Cotonou\"                            \n [9] \"Bolivia USAID-La Paz\"                           \n[10] \"Bosnia USAID-Herzegovina\"                       \n[11] \"Brazil USAID-Brasilia\"                          \n[12] \"Burma USAID - Rangoon\"                          \n[13] \"Burundi USAID-Bujumbura\"                        \n[14] \"Cambodia USAID-Phnom Penh\"                      \n[15] \"Colombia USAID-Bogota\"                          \n[16] \"Democratic Republic of the Congo USAID-Kinshasa\"\n[17] \"Dominican Republic USAID-Santo Domingo\"         \n[18] \"East Africa USAID-Kenya\"                        \n[19] \"Ecuador USAID-Quito\"                            \n[20] \"Egypt USAID-Cairo\"                              \n[21] \"El Salvador USAID-San Salvador\"                 \n[22] \"Ethiopia USAID-Addis Ababa\"                     \n[23] \"Georgia USAID-Tbilisi\"                          \n[24] \"Ghana USAID-Accra\"                              \n[25] \"Guatemala USAID-Guatemala City\"                 \n[26] \"Guinea USAID-Conakry\"                           \n[27] \"Haiti USAID-Port Au Prince\"                     \n[28] \"Honduras USAID-Tegucigalpa\"                     \n[29] \"Hungary USAID-Budapest\"                         \n[30] \"India USAID-New Delhi\"                          \n[31] \"Indonesia USAID-Jakarta\"                        \n[32] \"Iraq Assistance Office\"                         \n[33] \"Iraq USAID-Baghdad\"                             \n[34] \"Jamaica USAID-Kingston\"                         \n[35] \"Jordan USAID-Amman\"                             \n[36] \"Kazakhstan USAID-Almaty\"                        \n[37] \"Kenya USAID-Nairobi\"                            \n[38] \"Kosovo USAID-Pristina\"                          \n[39] \"Lebanon USAID-Beirut\"                           \n[40] \"Liberia USAID-Monrovia\"                         \n[41] \"Macedonia USAID-Skopje\"                         \n[42] \"Madagascar USAID-Antananarivo\"                  \n[43] \"Malawi USAID-Lilongwe\"                          \n[44] \"Mali USAID -Bamako\"                             \n[45] \"Mexico USAID-Mexico City\"                       \n[46] \"Middle East Regional Platform USAID-MERP\"       \n[47] \"Moldova USAID-Chisinau\"                         \n[48] \"Mongolia USAID-Ulaanbaatar\"                     \n[49] \"Morocco USAID-Rabat\"                            \n[50] \"Mozambique USAID-Maputo\"                        \n[51] \"Nepal USAID-Kathmandu\"                          \n[52] \"Nicaragua USAID-Managua\"                        \n[53] \"Nigeria USAID-Abuja\"                            \n[54] \"Pakistan USAID-Islamabad\"                       \n[55] \"Panama USAID-Panama City\"                       \n[56] \"Paraguay USAID-Asuncion\"                        \n[57] \"Peru USAID-Lima\"                                \n[58] \"Philippines USAID-Manila\"                       \n[59] \"Rwanda USAID-Kigali\"                            \n[60] \"Senegal USAID-Dakar\"                            \n[61] \"Serbia USAID-Belgrade\"                          \n[62] \"South Africa USAID-Pretoria\"                    \n[63] \"South Sudan (USAID)-Juba\"                       \n[64] \"Sri Lanka USAID-Colombo\"                        \n[65] \"Sudan USAID-Khartoum\"                           \n[66] \"Tajikistan USAID-Dushanbe\"                      \n[67] \"Tanzania USAID-Dar es Salaam\"                   \n[68] \"Thailand USAID-Bangkok\"                         \n[69] \"Uganda USAID-Kampala\"                           \n[70] \"Ukraine USAID-Kiev\"                             \n[71] \"Uzbekistan USAID-Tashkent\"                      \n[72] \"West Africa USAID-Ghana\"                        \n[73] \"West Bank\"                                      \n[74] \"Gaza USAID-West Bank\"                           \n[75] \"Yemen USAID-Sanaa\"                              \n[76] \"Zambia USAID-Lusaka\"                            \n[77] \"Zimbabwe USAID-Harare\"                          \n[78] \"USAID\"                                          \n[79] \"USAID - Barbados and Eastern Caribbean\"         \n[80] \"USAID-VIETNAM\"                                  \n\n$`Education and Research`\n  [1] \"Advanced Research Projects Agency Energy\"          \n  [2] \"Advanced Research Projects Agency for Health\"      \n  [3] \"Agency for Health Care Research and Quality\"       \n  [4] \"Air Force Academy\"                                 \n  [5] \"Air Force Office of Scientific Research\"           \n  [6] \"Army Contracting Command - Benet Laboratories\"     \n  [7] \"Bureau Of Educational and Cultural Affairs\"        \n  [8] \"Centers for Disease Control - ATSDR\"               \n  [9] \"Centers for Disease Control - CFA\"                 \n [10] \"Centers for Disease Control - CGH\"                 \n [11] \"Centers for Disease Control - CSELS\"               \n [12] \"Centers for Disease Control - NCBDDD\"              \n [13] \"Centers for Disease Control - NCCDPHP\"             \n [14] \"Centers for Disease Control - NCEH\"                \n [15] \"Centers for Disease Control - NCEZID\"              \n [16] \"Centers for Disease Control - NCHHSTP\"             \n [17] \"Centers for Disease Control - NCHS\"                \n [18] \"Centers for Disease Control - NCIPC\"               \n [19] \"Centers for Disease Control - NCIRD\"               \n [20] \"Centers for Disease Control - NIOSH\"               \n [21] \"Centers for Disease Control - OD\"                  \n [22] \"Centers for Disease Control - OPHPR\"               \n [23] \"Centers for Disease Control - OSTLTS\"              \n [24] \"Centers for Disease Control and Prevention\"        \n [25] \"Centers for Disease Control and Prevention - ERA\"  \n [26] \"Centers for Medicare & Medicaid Services\"          \n [27] \"Chief Evaluation Office\"                           \n [28] \"CMS Consumer Operated and Oriented Plan Program\"   \n [29] \"CMS-Consumer Information & Insurance Oversight\"    \n [30] \"DARPA - Biological Technologies Office\"            \n [31] \"DARPA - Defense Sciences Office\"                   \n [32] \"DARPA - Information Innovation Office\"             \n [33] \"DARPA - Information Processing Technology Office\"  \n [34] \"DARPA - Microsystems Technology Office\"            \n [35] \"DARPA - Strategic Technology Office\"               \n [36] \"DARPA - Tactical Technology Office\"                \n [37] \"DARPA - Transformational Convergence Technology\"   \n [38] \"DARPA-MTO-BAA-09-25\"                               \n [39] \"Defense Advanced Research Projects Agency\"         \n [40] \"Defense Health Agency\"                             \n [41] \"Defense Intelligence Agency\"                       \n [42] \"Department of Education\"                           \n [43] \"DoD Education Activity\"                            \n [44] \"DOT - FAA Aviation Research Grants\"                \n [45] \"DOT - FAA Centers of Excellence\"                   \n [46] \"DOT Federal Aviation Administration\"               \n [47] \"Economic Research Service\"                         \n [48] \"Engineer Research and Development Center\"          \n [49] \"FAA - Aviation Next Gen\"                           \n [50] \"FAA-COE-AJFE\"                                      \n [51] \"FAA-COE-GA\"                                        \n [52] \"FAA-COE-TTHP\"                                      \n [53] \"Faculty Exchange Program 10.613\"                   \n [54] \"Fish and Wildlife Service\"                         \n [55] \"Fisheries & Habitat Conservation\"                  \n [56] \"Food and Drug Administration\"                      \n [57] \"Food and Nutrition Service\"                        \n [58] \"Food Safety Inspection Service\"                    \n [59] \"Foreign Agricultural Service\"                      \n [60] \"Forest Service\"                                    \n [61] \"Geological Survey\"                                 \n [62] \"Health Resources and Services Administration\"      \n [63] \"Indian Health Service\"                             \n [64] \"Institute of Museum and Library Services\"          \n [65] \"Internal Revenue Service\"                          \n [66] \"International Agricultural Educ Fellowship 10.619\" \n [67] \"Library of Congress\"                               \n [68] \"NASA Ames Research Center\"                         \n [69] \"NASA Armstrong Flight Research Center\"             \n [70] \"NASA Glenn Research Center\"                        \n [71] \"NASA Goddard Space Flight Center\"                  \n [72] \"NASA Headquarters\"                                 \n [73] \"NASA Johnson Space Center\"                         \n [74] \"NASA Kennedy Space Center\"                         \n [75] \"NASA Langley Research Center\"                      \n [76] \"NASA Marshall Space Flight Center\"                 \n [77] \"NASA Stennis Space Center\"                         \n [78] \"National Aeronautics and Space Administration\"     \n [79] \"National Archives and Records Administration\"      \n [80] \"National Endowment for the Arts\"                   \n [81] \"National Endowment for the Humanities\"             \n [82] \"National Energy Technology Laboratory\"             \n [83] \"National Geospatial-Intelligence Agency\"           \n [84] \"National Highway Traffic Safety Administration\"    \n [85] \"National Institute of Corrections\"                 \n [86] \"National Institute of Food and Agriculture\"        \n [87] \"National Institute of Justice\"                     \n [88] \"National Institute of Standards and Technology\"    \n [89] \"National Institutes of Health\"                     \n [90] \"National Oceanic and Atmospheric Administration\"   \n [91] \"National Park Service\"                             \n [92] \"National Science Foundation\"                       \n [93] \"National Telecommunications and Information Admini\"\n [94] \"National Veterans Sports Programs\"                 \n [95] \"Natural Resources Conservation Service\"            \n [96] \"Naval Research Laboratory\"                         \n [97] \"Nuclear Regulatory Commission\"                     \n [98] \"Office of Science\"                                 \n [99] \"Office of the Assistant Secretary for Health\"      \n[100] \"Office of the Director of National Intelligence\"   \n[101] \"Office of the National Coordinator\"                \n[102] \"Office of the Secretary\"                           \n[103] \"Occupational Safety and Health Administration\"     \n[104] \"Pipeline and Hazardous Materials Safety Admin\"     \n[105] \"Risk Management Agency\"                            \n[106] \"Risk Management Education\"                         \n[107] \"Rural Business-Cooperative Service\"                \n[108] \"Rural Housing Service\"                             \n[109] \"Rural Utilities Service\"                           \n[110] \"Scientific Cooperation and Research 10.961\"        \n[111] \"Social Security Administration\"                    \n[112] \"Substance Abuse and Mental Health Services Admin\"  \n[113] \"Substance Abuse and Mental Health Services Adminis\"\n[114] \"Technical Agricultural Assistance 10.960\"          \n[115] \"Uniformed Services Univ. of the Health Sciences\"   \n[116] \"USUHS Medical - Non- Research Projects\"            \n[117] \"USUHS Medical Research Projects\"                   \n[118] \"Veterans Employment and Training Service\"          \n[119] \"Volunteer Income Tax Assistance\"                   \n[120] \"Woodrow Wilson Center\"                             \n\n$`Agriculture and Environment`\n [1] \"Agricultural Marketing Service\"                    \n [2] \"Agricultural Trade Promotion Program 10.618\"       \n [3] \"Animal and Plant Health Inspection Service\"        \n [4] \"Bureau of Land Management\"                         \n [5] \"Bureau of Ocean Energy Management\"                 \n [6] \"Bureau of Reclamation\"                             \n [7] \"Bureau of Reclamation - Denver Office\"             \n [8] \"Bureau of Reclamation - Great Plains Region\"       \n [9] \"Bureau of Reclamation - Lower Colorado Region\"     \n[10] \"Bureau of Reclamation - Mid-Pacific Region\"        \n[11] \"Bureau of Reclamation - Pacific Northwest Region\"  \n[12] \"Bureau of Reclamation - Upper Colorado Region\"     \n[13] \"Bureau of Reclamation-Upper Columbia Area Office\"  \n[14] \"Bureau of Reclamation\"                             \n[15] \"Denver Office\"                                     \n[16] \"Bureau of Reclamation\"                             \n[17] \"Mid-Pacific Regional Office\"                       \n[18] \"Bureau of Safety and Environmental Enforcement\"    \n[19] \"Department of Agriculture\"                         \n[20] \"Endangered Species\"                                \n[21] \"Environmental Management Consolidated Business Cen\"\n[22] \"Environmental Protection Agency\"                   \n[23] \"Farm Production and Conservation Business Center\"  \n[24] \"Farm Service Agency\"                               \n[25] \"Fish and Wildlife Service\"                         \n[26] \"Fisheries & Habitat Conservation\"                  \n[27] \"Forest Service\"                                    \n[28] \"Migratory Birds\"                                   \n[29] \"National Energy Technology Laboratory\"             \n[30] \"National Oceanic and Atmospheric Administration\"   \n[31] \"Natural Resources Conservation Service\"            \n[32] \"Office of Science\"                                 \n[33] \"Risk Management Agency\"                            \n[34] \"Rural Business-Cooperative Service\"                \n[35] \"Rural Housing Service\"                             \n[36] \"Rural Utilities Service\"                           \n\n$`Infrastructure and Transportation`\n  [1] \"```69A345 Office of the Under Secretary for Policy\"\n  [2] \"69A350 OSDBU\"                                      \n  [3] \"69A355 Research and Technology\"                    \n  [4] \"ACC APG - Natick\"                                  \n  [5] \"ACC-APG-Aberdeen Division A\"                       \n  [6] \"ACC-APG-Belvoir\"                                   \n  [7] \"ACC-APG-Detrick\"                                   \n  [8] \"ACC-APG-Edgewood\"                                  \n  [9] \"ACC-APG-Fort Huachuca\"                             \n [10] \"Air Force -- Materiel Command\"                     \n [11] \"Air Force -- Research Lab\"                         \n [12] \"Air Force Academy\"                                 \n [13] \"Air Force Office of Scientific Research\"           \n [14] \"Airport Improvement Program Discretionary Grants\"  \n [15] \"Alaska District\"                                   \n [16] \"Army Contracting Command - Benet Laboratories\"     \n [17] \"Army Contracting Command - New Jersey\"             \n [18] \"Army Contracting Command Rock Island\"              \n [19] \"Bureau of Land Management\"                         \n [20] \"Bureau of Ocean Energy Management\"                 \n [21] \"Bureau of Reclamation\"                             \n [22] \"Bureau of Reclamation - Denver Office\"             \n [23] \"Bureau of Reclamation - Great Plains Region\"       \n [24] \"Bureau of Reclamation - Lower Colorado Region\"     \n [25] \"Bureau of Reclamation - Mid-Pacific Region\"        \n [26] \"Bureau of Reclamation - Pacific Northwest Region\"  \n [27] \"Bureau of Reclamation - Upper Colorado Region\"     \n [28] \"Bureau of Reclamation-Upper Columbia Area Office\"  \n [29] \"Bureau of Reclamation\"                             \n [30] \"Denver Office\"                                     \n [31] \"Bureau of Reclamation\"                             \n [32] \"Mid-Pacific Regional Office\"                       \n [33] \"Bureau of Safety and Environmental Enforcement\"    \n [34] \"Chicago Service Center\"                            \n [35] \"DARPA - Biological Technologies Office\"            \n [36] \"DARPA - Defense Sciences Office\"                   \n [37] \"DARPA - Information Innovation Office\"             \n [38] \"DARPA - Information Processing Technology Office\"  \n [39] \"DARPA - Microsystems Technology Office\"            \n [40] \"DARPA - Strategic Technology Office\"               \n [41] \"DARPA - Tactical Technology Office\"                \n [42] \"DARPA - Transformational Convergence Technology\"   \n [43] \"Defense Advanced Research Projects Agency\"         \n [44] \"Defense Health Agency\"                             \n [45] \"Defense Intelligence Agency\"                       \n [46] \"Defense Logistics Agency\"                          \n [47] \"Defense Threat Reduction Agency\"                   \n [48] \"Department of Transportation\"                      \n [49] \"Dept of the Army -- Materiel Command\"              \n [50] \"Dept. of the Army  --  Corps of Engineers\"         \n [51] \"Dept. of the Army -- Space & Missle Defense Comman\"\n [52] \"Dept. of the Army -- USAMRAA\"                      \n [53] \"DOT - FAA Aviation Research Grants\"                \n [54] \"DOT - FAA Centers of Excellence\"                   \n [55] \"DOT - Federal Railroad Administration\"             \n [56] \"DOT Federal Aviation Administration\"               \n [57] \"DOT Federal Highway Administration\"                \n [58] \"DOT OSDBU\"                                         \n [59] \"DOT-Federal Motor Carrier Safety Administration\"   \n [60] \"DOT-Federal Transit Administration - Inactive Site\"\n [61] \"DOT/Federal Transit Administration\"                \n [62] \"Economic Development Administration\"               \n [63] \"Engineer Research and Development Center\"          \n [64] \"FAA - Aviation Next Gen\"                           \n [65] \"FAA-COE-AJFE\"                                      \n [66] \"FAA-COE-GA\"                                        \n [67] \"FAA-COE-TTHP\"                                      \n [68] \"Federal Communications Commission\"                 \n [69] \"Federal Mediation and Conciliation Service\"        \n [70] \"Federal Motor Carrier Safety Administration\"       \n [71] \"Federal Transit Administration\"                    \n [72] \"Fort Worth District\"                               \n [73] \"Kansas City District\"                              \n [74] \"Maritime Administration\"                           \n [75] \"NASA Ames Research Center\"                         \n [76] \"NASA Armstrong Flight Research Center\"             \n [77] \"NASA Glenn Research Center\"                        \n [78] \"NASA Goddard Space Flight Center\"                  \n [79] \"NASA Headquarters\"                                 \n [80] \"NASA Johnson Space Center\"                         \n [81] \"NASA Kennedy Space Center\"                         \n [82] \"NASA Langley Research Center\"                      \n [83] \"NASA Marshall Space Flight Center\"                 \n [84] \"NASA Stennis Space Center\"                         \n [85] \"National Aeronautics and Space Administration\"     \n [86] \"National Highway Traffic Safety Administration\"    \n [87] \"National Oceanic and Atmospheric Administration\"   \n [88] \"National Telecommunications and Information Admini\"\n [89] \"Naval Air Warfare Center Aircraft Div. Lakehurst\"  \n [90] \"NAVAL FACILITIES ENGINEERING COMMAND\"              \n [91] \"Naval Facilities Engineering Command Southwest\"    \n [92] \"Naval Information Warfare Center Pacific\"          \n [93] \"NAVAL MEDICAL LOGISTICS COMMAND\"                   \n [94] \"Naval Research Laboratory\"                         \n [95] \"Naval Supply Systems Command\"                      \n [96] \"Naval Surface Warfare Center - Carderock\"          \n [97] \"NAVFAC Atlantic\"                                   \n [98] \"NAVFAC Washington DC\"                              \n [99] \"NCA Contracting\"                                   \n[100] \"Nebraska State Office\"                             \n[101] \"Nuclear Regulatory Commission\"                     \n[102] \"NUWC Division Keyport\"                             \n[103] \"Office of Local Defense Community Cooperation\"     \n[104] \"Office of the Secretary\"                           \n[105] \"Omaha District\"                                    \n[106] \"Pipeline and Hazardous Materials Safety Admin\"     \n[107] \"Region 1\"                                          \n[108] \"Region 10\"                                         \n[109] \"Region 2\"                                          \n[110] \"Region 3\"                                          \n[111] \"Region 4\"                                          \n[112] \"Region 5\"                                          \n[113] \"Region 6\"                                          \n[114] \"Region 7\"                                          \n[115] \"Region 8\"                                          \n[116] \"Region 9\"                                          \n[117] \"Risk Management Agency\"                            \n[118] \"Rural Utilities Service\"                           \n[119] \"Savannah District\"                                 \n[120] \"Seattle District\"                                  \n[121] \"SPAWAR SYSTEMS CENTER\"                             \n[122] \"Transportation Security Administration\"            \n[123] \"U.S. Dept. of Treasury RESTORE Act Program\"        \n[124] \"United States Coast Guard\"                         \n[125] \"United States Marine Corps\"                        \n[126] \"USACE Portland District\"                           \n[127] \"USAF 347 Contracting Squadron\"                     \n[128] \"Walla Walla District\"                              \n[129] \"Washington Headquarters Services```\"               \n\n$`Business and Economic Development`\n [1] \"Economic Development Administration\"               \n [2] \"Small Business Administration\"                     \n [3] \"Community Development Financial Institutions\"      \n [4] \"Rural Business-Cooperative Service\"                \n [5] \"Employment and Training Administration\"            \n [6] \"Office of Local Defense Community Cooperation\"     \n [7] \"Economic Research Service\"                         \n [8] \"Agricultural Marketing Service\"                    \n [9] \"Agricultural Trade Promotion Program 10.618\"       \n[10] \"Bureau of Economic and Business Affairs\"           \n[11] \"Trade Policy and Geographic Affairs\"               \n[12] \"Market Access Program 10.601\"                      \n[13] \"Foreign Agricultural Service\"                      \n[14] \"Foreign Market Development Cooperator Prog 10600\"  \n[15] \"Technical Assistance for Specialty Crops 10.604\"   \n[16] \"Jobs and Innovation Accelerator Challenge\"         \n[17] \"Energy Cluster Program\"                            \n[18] \"DOT - FAA Centers of Excellence\"                   \n[19] \"DOT Federal Highway Administration\"                \n[20] \"DOT OSDBU\"                                         \n[21] \"DOT-Federal Motor Carrier Safety Administration\"   \n[22] \"DOT-Federal Transit Administration - Inactive Site\"\n[23] \"DOT/Federal Transit Administration\"                \n[24] \"Federal Communications Commission\"                 \n[25] \"National Business Center\"                          \n[26] \"National Telecommunications and Information Admini\"\n[27] \"U.S. Dept. of Treasury RESTORE Act Program\"        \n[28] \"Volunteer Income Tax Assistance\"                   \n[29] \"Low Income Taxpayer Clinic\"                        \n[30] \"Tax Counseling for the Elderly\"                    \n[31] \"CMS Consumer Operated and Oriented Plan Program\"   \n[32] \"CMS-Consumer Information & Insurance Oversight\"    \n[33] \"Office of Acquisitions Management\"                 \n[34] \"Office of Procurement Operations - Grants Division\"\n[35] \"Office of the Secretary\"                           \n[36] \"Office on Violence Against Women\"                  \n[37] \"Veterans Employment and Training Service\"          \n[38] \"Veterans Employment Pay for Success\"               \n[39] \"Office of Disability Employment Policy\"            \n[40] \"Office of Partnerships and Public Engagements\"     \n[41] \"Risk Management Agency\"                            \n[42] \"Risk Management Education\"                         \n[43] \"Office of the Assistant Secretary for Health\"      \n[44] \"Office of the National Coordinator\"                \n[45] \"Office of the Director of National Intelligence\"   \n[46] \"Office of the Middle East Partnership Initiative\"  \n[47] \"Office to Monitor-Combat Trafficking in Persons\"   \n[48] \"Office of Global Womens Issues\"                    \n[49] \"Office of Global Criminal Justice\"                 \n[50] \"Office of Justice Programs\"                        \n[51] \"Office of Juvenile Justice Delinquency Prevention\" \n[52] \"Office for Victims of Crime\"                       \n[53] \"Office of Science\"                                 \n[54] \"Office of Surface Mining\"                          \n[55] \"Office of Mental Health and Suicide Prevention\"    \n[56] \"Office of National Drug Control Policy\"            \n[57] \"Office of the Secretary\"                           \n[58] \"Office of Policy ORES\"                             \n[59] \"Office of Acquisitions Management\"                 \n[60] \"Office of Procurement Operations - Grants Division\"\n[61] \"Office of the Secretary\"                           \n[62] \"Office on Violence Against Women\"                  \n[63] \"Veterans Employment and Training Service\"          \n[64] \"Veterans Employment Pay for Success\"               \n[65] \"Office of Disability Employment Policy\"            \n[66] \"Office of Partnerships and Public Engagements\"     \n[67] \"Risk Management Agency\"                            \n[68] \"Risk Management Education\"                         \n[69] \"Office of the Assistant Secretary for Health\"      \n[70] \"Office of the National Coordinator\"                \n[71] \"Office of the Director of National Intelligence\"   \n[72] \"Office of the Middle East Partnership Initiative\"  \n[73] \"Office to Monitor-Combat Trafficking in Persons\"   \n[74] \"Office of Global Womens Issues\"                    \n[75] \"Office of Global Criminal Justice\"                 \n[76] \"Office of Justice Programs\"                        \n[77] \"Office of Juvenile Justice Delinquency Prevention\" \n[78] \"Office for Victims of Crime\"                       \n[79] \"Office of Science\"                                 \n[80] \"Office of Surface Mining\"                          \n[81] \"Office of Mental Health and Suicide Prevention\"    \n[82] \"Office of National Drug Control Policy\"            \n\n$`Arts and Culture`\n[1] \"National Endowment for the Arts\"             \n[2] \"National Endowment for the Humanities\"       \n[3] \"Institute of Museum and Library Services\"    \n[4] \"Library of Congress\"                         \n[5] \"National Archives and Records Administration\"\n[6] \"Smithsonian Institution\"                     \n\n$`Social Services and Community Development`\n [1] \"Administration for Children & Families - ACYF/FYSB\"\n [2] \"Administration for Children and Families\"          \n [3] \"Administration for Children and Families - ACYF/CB\"\n [4] \"Administration for Children and Families - ANA\"    \n [5] \"Administration for Children and Families - OCC\"    \n [6] \"Administration for Children and Families - OCS\"    \n [7] \"Administration for Children and Families - OCSE\"   \n [8] \"Administration for Children and Families - OFA\"    \n [9] \"Administration for Children and Families - OHS\"    \n[10] \"Administration for Children and Families - OHSEPR\" \n[11] \"Administration for Children and Families - OPRE\"   \n[12] \"Administration for Children and Families - ORR\"    \n[13] \"Administration for Children and Families-IOAS-OTIP\"\n[14] \"Administration for Community Living\"               \n[15] \"Administration on Aging\"                           \n[16] \"AmeriCorps\"                                        \n[17] \"Community Capacity Development Office\"             \n[18] \"Community Development Financial Institutions\"      \n[19] \"Community Oriented Policing Services\"              \n[20] \"Corporation for National and Community Service\"    \n[21] \"Department of Housing and Urban Development\"       \n[22] \"Employment and Training Administration\"            \n[23] \"Health Resources and Services Administration\"      \n[24] \"Homeless Providers Grant and Per Diem Program\"     \n[25] \"Housing and Urban Development\"                     \n[26] \"Office of Juvenile Justice Delinquency Prevention\" \n[27] \"Office of Local Defense Community Cooperation\"     \n[28] \"Office of the Assistant Secretary for Health\"      \n[29] \"Office on Violence Against Women\"                  \n[30] \"Rural Business-Cooperative Service\"                \n[31] \"Rural Housing Service\"                             \n[32] \"Rural Utilities Service\"                           \n[33] \"Social Security Administration\"                    \n[34] \"Substance Abuse and Mental Health Services Admin\"  \n[35] \"Substance Abuse and Mental Health Services Adminis\"\n[36] \"Supportive Services for Veteran Families\"          \n[37] \"Veterans Employment and Training Service\"          \n[38] \"Veterans Employment Pay for Success\"               \n[39] \"Veterans Legacy Grants Program\"                    \n[40] \"Volunteer Income Tax Assistance\"                   \n[41] \"Womens Bureau\""
  },
  {
    "objectID": "blog/2023/10/08/index.html#add-categories-to-dataframe",
    "href": "blog/2023/10/08/index.html#add-categories-to-dataframe",
    "title": "Using GPT-4 for classification",
    "section": "Add categories to dataframe",
    "text": "Add categories to dataframe\nFinally, I’ll add the category labels to the grant_opportunity_details dataframe. Since the categories are not mutually exclusive, I’ll encode them as boolean.\n\ncategories_snakecase &lt;- snakecase::to_snake_case(categories)\n\nfor(i in seq(1, length(categories_snakecase))){\n  grant_opportunity_details &lt;- grant_opportunity_details %&gt;%\n    mutate(!!categories_snakecase[i] := agency_name %in% agencies_categorized[i][[1]])\n}"
  },
  {
    "objectID": "blog/2023/09/08/index.html",
    "href": "blog/2023/09/08/index.html",
    "title": "Using random forest based outlier detection to clean a training dataset",
    "section": "",
    "text": "For this blog post, I will be tackling the Kaggle compettition Improve a Fixed Model the Data-Centric Way!\nThis is the challenge of the competition: Improve a dataset that is being used to train a random forest model. The model is fixed, so model performance can only be improved by modifying the dataset. In terms of dataset modifications, there are some additional limitations:\n\nRows can be removed, but not added\nColumns cannot be removed or added\nValues in the dataset that are used to train the model can be transformed, but those transformations will not be applied to the validation dataset (which is held out until the challenge comes to an end)\n\nThis means that many of the tools available to a data scientist for improving an ML model, such as hyperparameter tuning, or data pre-processing applied to both training and test/validation datasets, are not available. The best options, therefore, will be to find ways to clean the training dataset that will yield better performance in the untouched validation dataset.\nIn this post, I will explore whether the training data can be improved using multivariate outlier imputation and by reducing feature multicollinearity."
  },
  {
    "objectID": "blog/2023/09/08/index.html#model-pipeline",
    "href": "blog/2023/09/08/index.html#model-pipeline",
    "title": "Using random forest based outlier detection to clean a training dataset",
    "section": "Model pipeline",
    "text": "Model pipeline\nBefore doing anything else, I want to create a model pipeline function and establish a baseline of model performance. This pipeline and baseline model will allow me to quickly iterate, test, and benchmark changes to the training dataset.\n\nfit_ranger_cv &lt;- function(train, test, model_name){\n  set.seed(42)\n  model_ranger &lt;-\n    # The parameters here mirror those that\n    # will be used in the competition model\n    rand_forest(trees = 1000, \n                min_n = 7) %&gt;% \n    set_engine(\"ranger\") %&gt;% \n    set_mode(\"regression\")\n  \n  workflow_ranger &lt;- \n    workflow() %&gt;% \n    add_formula(target ~ .) %&gt;% \n    add_model(model_ranger)\n  \n  folds &lt;- vfold_cv(train, v = 5)\n  \n  fit_ranger &lt;- \n    workflow_ranger %&gt;% \n    fit_resamples(folds)\n  \n  # Get in-sample performance over resamples\n  round((fit_ranger %&gt;%\n    collect_metrics() %&gt;%\n    filter(.metric == 'rmse'))$mean, 3) -&gt; train_perf\n  \n  # Evaluate performance on out-of-sample (test) data\n  ranger_fit &lt;- \n    workflow_ranger %&gt;%\n    fit(train)\n  \n  round(rmse(test$target, predict(ranger_fit, test)$.pred), 3) -&gt; test_perf\n  \n  # Combine in-sample and out-of-sample into a dataframe\n  df_perf &lt;- data.frame(model = model_name,\n                        train_perf = train_perf,\n                        test_perf = test_perf)\n  return(df_perf)\n}"
  },
  {
    "objectID": "blog/2023/09/08/index.html#baseline-performance",
    "href": "blog/2023/09/08/index.html#baseline-performance",
    "title": "Using random forest based outlier detection to clean a training dataset",
    "section": "Baseline performance",
    "text": "Baseline performance\n\nbaseline_fit &lt;- fit_ranger_cv(train %&gt;% select(-id), test %&gt;% select(-id), 'baseline')\nbaseline_fit\n\n     model train_perf test_perf\n1 baseline      1.231     2.134\n\n\nI’m going to run that again so I can be sure the RNG seed is set properly and the results are reproducible – otherwise I’ll be chasing a moving target!\n\nbaseline_fit &lt;- fit_ranger_cv(train %&gt;% select(-id), test %&gt;% select(-id), 'baseline')\nbaseline_fit\n\n     model train_perf test_perf\n1 baseline      1.231     2.134"
  },
  {
    "objectID": "blog/2023/09/08/index.html#outlier-detection",
    "href": "blog/2023/09/08/index.html#outlier-detection",
    "title": "Using random forest based outlier detection to clean a training dataset",
    "section": "1. Outlier detection",
    "text": "1. Outlier detection\nUnivariate outlier detection\nOne simple univariate outlier detection method involves a “Z-score threshold”. In a normally distributed dataset, 99% of values will tend to fall between a Z-score of -3 to +3. This is why a Z-score threshold of +/- 3 is often used to identify outliers in practice.\nFor example, here’s a plot of the percentage of outliers found for each variable. I can see that some variables contained more outliers than others. In particular, there were 6 features with more than 3% extreme values.\n\ntrain %&gt;%\n  select(-id) %&gt;%\n  outliers::scores(type=\"z\") %&gt;%\n  pivot_longer(everything()) %&gt;%\n  group_by(name) %&gt;%\n  summarize(n_outlier = sum(abs(value) &gt; 3),\n            pct_outlier = round(sum(abs(value) &gt; 3)/n()*100,2)) %&gt;%\n  arrange(pct_outlier) -&gt; train_pct_outlier\n\ntrain_pct_outlier %&gt;%\n  ggplot(aes(x = fct_inorder(name), y = pct_outlier)) +\n    geom_bar(stat='identity') +\n    coord_flip() +\n    xlab(\"Feature\") +\n    ylab(\"% values exceeding 3 z-score threshold\") +\n    geom_hline(yintercept = 3)\n\n\n\n\n\n\ntrain_pct_outlier %&gt;%\n  filter(pct_outlier &gt; 3) %&gt;%\n  arrange(desc(pct_outlier))\n\n# A tibble: 6 × 3\n  name   n_outlier pct_outlier\n  &lt;chr&gt;      &lt;int&gt;       &lt;dbl&gt;\n1 NH4_7        137        5.22\n2 NH4_1        122        4.65\n3 BOD5_3       113        4.3 \n4 O2_2         111        4.23\n5 NO2_1        104        3.96\n6 NH4_2         99        3.77\n\n\nOther options for univariate outlier detection include using the inter-quartile range (IQR) or percentile-based thresholds.\nMultivariate outlier detection\nAnother option is multivariate outlier detection. For multivariate outlier detection, random forest based methods have been growing in popularity within the data science community. There are two methods that I’ll consider here.\nIsolation forest\nThe “isolation forest” works by trying to identify variables that can be isolated in branches when randomly splitting the data. From the isotree package documentation:\n\nIsolation Forest is an algorithm originally developed for outlier detection that consists in splitting sub-samples of the data according to some attribute/feature/column at random. The idea is that, the rarer the observation, the more likely it is that a random uniform split on some feature would put outliers alone in one branch, and the fewer splits it will take to isolate an outlier observation like this.\n\nImportantly, this method operates at the row level, allowing us to identify anomalous records, but not pinpoint specifically which features on which those records may have been outliers.\n\nlibrary(isotree)\nisofor &lt;- isolation.forest(train %&gt;% select(-id), ntrees = 500, nthreads = 4)\niso_preds &lt;- predict(isofor, train %&gt;% select(-id))\ntrain[which.max(iso_preds), ]\n\n# A tibble: 1 × 37\n     id target  O2_1  O2_2  O2_3  O2_4  O2_5  O2_6  O2_7 NH4_1 NH4_2 NH4_3 NH4_4\n  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1  2662   15.9  15.9  14.9  8.98  6.17  2.28  8.98  7.15 0.573  0.54 0.208   2.3\n# ℹ 24 more variables: NH4_5 &lt;dbl&gt;, NH4_6 &lt;dbl&gt;, NH4_7 &lt;dbl&gt;, NO2_1 &lt;dbl&gt;,\n#   NO2_2 &lt;dbl&gt;, NO2_3 &lt;dbl&gt;, NO2_4 &lt;dbl&gt;, NO2_5 &lt;dbl&gt;, NO2_6 &lt;dbl&gt;,\n#   NO2_7 &lt;dbl&gt;, NO3_1 &lt;dbl&gt;, NO3_2 &lt;dbl&gt;, NO3_3 &lt;dbl&gt;, NO3_4 &lt;dbl&gt;,\n#   NO3_5 &lt;dbl&gt;, NO3_6 &lt;dbl&gt;, NO3_7 &lt;dbl&gt;, BOD5_1 &lt;dbl&gt;, BOD5_2 &lt;dbl&gt;,\n#   BOD5_3 &lt;dbl&gt;, BOD5_4 &lt;dbl&gt;, BOD5_5 &lt;dbl&gt;, BOD5_6 &lt;dbl&gt;, BOD5_7 &lt;dbl&gt;\n\n\noutForest\nThe outForest package implements a different random forest method of outlier detection in which each variable is regressed onto all others, and outliers are detected based on the difference between the observed value and the out-of-bag predicted value. This has the advantage of identifying outliers on both a row and column basis, providing more flexibility in terms of how outliers can be dealt with.\n\nlibrary(outForest)\nset.seed(42)\noutfor &lt;- outForest(train %&gt;% select(-id), \n                    verbose = 0)\noutForest::outliers(outfor) %&gt;%\n  select(-rmse, -threshold) %&gt;%\n  head()\n\n      row    col observed  predicted    score replacement\n453  2003  NH4_5  3026.00 14.0353304 50.63951      12.175\n811  1021  NO2_3     2.05  0.1152134 25.71619       0.064\n4     237 target    40.78 11.1135703 23.52858       8.100\n1315 2556 BOD5_4    55.40  5.8114438 21.74855       5.800\n340  2149  NH4_1     4.20  0.4161047 21.17629       0.360\n1327  241 BOD5_5    82.45  9.2994377 20.80525       8.400\n\n\nBelow we can see the outliers identified for each variable and how anomalous those outliers were. Using this data, I can then choose a threshold and replace anomalous values by imputation. The outForest package provides different methods of imputation out of the box, defaulting to predictive mean matching.\nI’ll use this method for detection because it’s multivariate, intuitive, and flexible.\n\nplot(outfor, what = \"scores\")"
  },
  {
    "objectID": "blog/2023/09/08/index.html#outlier-removal-or-imputation",
    "href": "blog/2023/09/08/index.html#outlier-removal-or-imputation",
    "title": "Using random forest based outlier detection to clean a training dataset",
    "section": "2. Outlier removal or imputation",
    "text": "2. Outlier removal or imputation\nNow that I’ve decided on an outlier detection method, the next step is to decide what to do about the outliers. There’s two main ways outliers can be handled: Removal or imputation. Removal is often an extreme measure that can lead to information loss, so I tend to prefer imputation over removal.\nSince I’ve decided to use outForest, I can also use its out-of-the-box imputation methods.\nFirst, I’ll go back to the dataframe containing the outliers that it had detected and try to refine the threshold. By default, it was using a score threshold of 3. But I’m not comfortable with imputing so many values. My gut tells me that if I’m identifying more than 3-5% of the records as outliers, then my threshold is too low and I’m catching too many potentially legitimate values.\nHere I can see that a score threshold of 8 yields around 2% outliers on a row-basis. That seems more reasonable\n\nround((nrow(outForest::outliers(outfor) %&gt;%\n        select(-replacement, -rmse, -threshold) %&gt;%\n        filter(abs(score) &gt; 8) %&gt;%\n        distinct(row))/nrow(sample_submission)*100), 1)\n\n[1] 1.9\n\n\nUsing this threshold, I will now impute the values.\n\nset.seed(42)\noutfor2 &lt;- outForest(train %&gt;% select(-id), \n                      verbose = 0, \n                      replace = \"pmm\",\n                      threshold = 8)\ntrain_outlier_adjusted &lt;- outfor2$Data\n\nHere I can see one of the outliers previously identified, and the value that was imputed for it.\n\ntrain[1021,]$NO2_3\n\n[1] 2.05\n\ntrain_outlier_adjusted[1021,]$NO2_3\n\n[1] 0.064\n\n\nAnd now I can quickly run the random forest model again, with the new imputed training dataset, and compare it against the baseline model.\nI see that outlier imputation has improved in-sample performance considerably (which is to be expected since the training dataset on which the cross-validation was performed is now much cleaner!), but it actually had a fairly marginal impact on out-of-sample performance.\n\nranger_fit_1 &lt;- fit_ranger_cv(train_outlier_adjusted, test %&gt;% select(-id), 'outliers imputed')\n\nranger_fit_1 %&gt;%\n  mutate(train_pct_improved = round((baseline_fit$train_perf-train_perf)/baseline_fit$train_perf*100, 2),\n         test_pct_improved = round((baseline_fit$test_perf-test_perf)/baseline_fit$test_perf*100, 2)) %&gt;%\n  bind_rows(baseline_fit) -&gt; ranger_fit_1\n\nranger_fit_1\n\n             model train_perf test_perf train_pct_improved test_pct_improved\n1 outliers imputed      1.080     2.128              12.27              0.28\n2         baseline      1.231     2.134                 NA                NA"
  },
  {
    "objectID": "blog/2023/08/25/index.html",
    "href": "blog/2023/08/25/index.html",
    "title": "Using data normalization to better compare change over time in regions with different population sizes",
    "section": "",
    "text": "For this post, I’ll be using the Week 34 Tidy Tuesday dataset, which contains data on refugee movement around the world. I want to look at the change in refugee outflows over time in different nations, and see if I can identify countries with meaningfully large increases in refugee outflows.\n\nlibrary(tidyverse)\nlibrary(wbstats)\nlibrary(gghighlight)\ndf &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2023/2023-08-22/population.csv')\n\nData cleaning\nFirst, some data cleaning.\nTo keep things simple, I’m only going to keep nations that had refugee data for all of the 13 years spanning 2010-2022.\n\n(df %&gt;%\n  group_by(coo_name) %&gt;%\n  summarize(n_years = n_distinct(year)) %&gt;%\n  filter(n_years == 13))$coo_name -&gt; coo_to_keep\n\ndf %&gt;%\n  filter(coo_name %in% coo_to_keep) %&gt;%\n  select(coo_name,\n         coo_iso,\n         year,\n         refugees) -&gt; df_clean\n\nNormalization\nNext, to make comparisons between nations more apples-apples, I’m going to do some normalization.\nI want to normalize in terms of population size and change over baseline.\nFirst, I’ll fetch population data from World Bank using wbstats.\n\nwb_search(\"SP.POP.TOTL\", fields='indicator_id') %&gt;%\n  head(1)\n\n# A tibble: 1 × 3\n  indicator_id indicator         indicator_desc                                 \n  &lt;chr&gt;        &lt;chr&gt;             &lt;chr&gt;                                          \n1 SP.POP.TOTL  Population, total Total population is based on the de facto defi…\n\n\n\npops &lt;- wb_data(\"SP.POP.TOTL\", start_date = 2010, end_date = 2022) %&gt;%\n  select(iso3c, date, \"SP.POP.TOTL\") %&gt;%\n  rename(pop = \"SP.POP.TOTL\",\n         iso = iso3c)\n\ndf_clean %&gt;%\n  left_join(pops, by=c('coo_iso'='iso', 'year'='date')) -&gt; df_enriched\n\ndf_enriched %&gt;%\n  head()\n\n# A tibble: 6 × 5\n  coo_name               coo_iso  year refugees        pop\n  &lt;chr&gt;                  &lt;chr&gt;   &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;\n1 Afghanistan            AFG      2010        0   28189672\n2 Iran (Islamic Rep. of) IRN      2010       30   75373855\n3 Iraq                   IRQ      2010        6   31264875\n4 Pakistan               PAK      2010     6398  194454498\n5 Egypt                  EGY      2010        5   87252413\n6 China                  CHN      2010        6 1337705000\n\n\nNext, I’ll compute a new variable: refugees_per_1k_pop that represents refugees leaving per 1000 persons in the original population. This is a good way to normalize, because we’d expect a larger count of refugees leaving from countries that had more people to begin with.\n\ndf_enriched %&gt;%\n  group_by(year, coo_name, coo_iso) %&gt;%\n  summarize(refugees = sum(refugees),\n            pop = first(pop)) %&gt;%\n  mutate(refugees_per_1k_pop = refugees/(pop/1000)) -&gt; df_enriched\n\ndf_enriched %&gt;%\n  head()\n\n# A tibble: 6 × 6\n# Groups:   year, coo_name [6]\n   year coo_name            coo_iso refugees      pop refugees_per_1k_pop\n  &lt;dbl&gt; &lt;chr&gt;               &lt;chr&gt;      &lt;dbl&gt;    &lt;dbl&gt;               &lt;dbl&gt;\n1  2010 Afghanistan         AFG      3054699 28189672            108.    \n2  2010 Albania             ALB        14771  2913021              5.07  \n3  2010 Algeria             DZA         6665 35856344              0.186 \n4  2010 Angola              AGO       134851 23364185              5.77  \n5  2010 Antigua and Barbuda ATG           28    85695              0.327 \n6  2010 Argentina           ARG          553 40788453              0.0136\n\n\nI’ll do a bit of cleaning again, to remove those nations for whom I didn’t have a complete record of population data, and so couldn’t calculate refugees_per_1k_pop for every year.\n\n(df_enriched %&gt;%\n  group_by(coo_name) %&gt;%\n  summarize(n_years = sum(refugees_per_1k_pop &gt; 0, na.rm=T)) %&gt;%\n  filter(n_years == 13))$coo_name -&gt; coo_to_keep_2\n\ndf_enriched %&gt;%\n  filter(coo_name %in% coo_to_keep_2)-&gt; df_enriched_clean\n\nNext, I’ll use 2010 as a baseline year, and subtract each year’s value from that. This will allow me to measure change over time from this common baseline, and compare nations in terms of a normalized change.\n\ndf_enriched_clean %&gt;%\n  filter(year == 2010) %&gt;%\n  group_by(coo_name) %&gt;%\n  summarize(baseline_refugees_per_1k_pop = sum(refugees)/(first(pop)/1000)) -&gt; baseline_year\n\ndf_enriched_clean %&gt;%\n  left_join(baseline_year, by='coo_name') %&gt;%\n  mutate(change_from_baseline = refugees_per_1k_pop - baseline_refugees_per_1k_pop) -&gt; df_enriched_clean\n\ndf_enriched_clean %&gt;%\n  head()\n\n# A tibble: 6 × 8\n# Groups:   year, coo_name [6]\n   year coo_name            coo_iso refugees      pop refugees_per_1k_pop\n  &lt;dbl&gt; &lt;chr&gt;               &lt;chr&gt;      &lt;dbl&gt;    &lt;dbl&gt;               &lt;dbl&gt;\n1  2010 Afghanistan         AFG      3054699 28189672            108.    \n2  2010 Albania             ALB        14771  2913021              5.07  \n3  2010 Algeria             DZA         6665 35856344              0.186 \n4  2010 Angola              AGO       134851 23364185              5.77  \n5  2010 Antigua and Barbuda ATG           28    85695              0.327 \n6  2010 Argentina           ARG          553 40788453              0.0136\n# ℹ 2 more variables: baseline_refugees_per_1k_pop &lt;dbl&gt;,\n#   change_from_baseline &lt;dbl&gt;\n\n\nIdentifying regions of interest\nNext, I want to identify a smaller set of “interesting” COOs that have experienced large increases over the baseline. I’ll identify an upper bound percentile of max change over baseline, and then I’ll use a value that approximates that as a filter. This gives me 4 “interesting” nations.\n\ndf_enriched_clean %&gt;%\n  group_by(coo_name) %&gt;%\n  summarize(max_change_from_baseline = max(change_from_baseline)) %&gt;%\n  summarize(p90_change = quantile(max_change_from_baseline, .975, na.rm=T))\n\n# A tibble: 1 × 1\n  p90_change\n       &lt;dbl&gt;\n1       30.0\n\ndf_enriched_clean %&gt;%\n  group_by(coo_name, coo_iso) %&gt;%\n  summarize(max_change_from_baseline = max(change_from_baseline),\n            last_value = last(change_from_baseline, order_by=year)) %&gt;%\n  filter(max_change_from_baseline &gt; 32) -&gt; coos_with_large_changes_over_baseline\n\n`summarise()` has grouped output by 'coo_name'. You can override using the\n`.groups` argument.\n\ncoos_with_large_changes_over_baseline\n\n# A tibble: 4 × 4\n# Groups:   coo_name [4]\n  coo_name             coo_iso max_change_from_baseline last_value\n  &lt;chr&gt;                &lt;chr&gt;                      &lt;dbl&gt;      &lt;dbl&gt;\n1 Central African Rep. CAF                         99.8       98.7\n2 Eritrea              ERI                         76.9       67.3\n3 Syrian Arab Rep.     SYR                        343.       295. \n4 Ukraine              UKR                        149.       149. \n\n\nData visualization\nFinally, I’ll plot change over the 2010 baseline (in refugees per 1k population), and highlight the 4 interesting nations identified above.\nI’ll use this to help me pick colors for the ggtitle text.\n\nscales::show_col(scales::hue_pal()(4))\n\n\n\n\n\n\n\n\ndf_enriched_clean %&gt;%\n  mutate(class = coo_name %in% coos_with_large_changes_over_baseline$coo_name,\n         year = as.Date(paste0(as.character(year), '-01-01'))) %&gt;%\n  arrange(year, desc(class)) %&gt;%\n  mutate(coo_iso = fct_inorder(coo_iso)) %&gt;%\n  ggplot(aes(x=year, y=change_from_baseline, color=coo_iso)) +\n    geom_line() +\n    scale_x_date(date_labels=\"%Y\", date_breaks=\"1 year\") +\n    ggthemes::theme_solarized() +\n    gghighlight::gghighlight(class == TRUE) +\n    ggtitle(\"&lt;strong&gt;&lt;span style='color:#00BFC4'&gt;SYR&lt;/span&gt;&lt;/strong&gt;, &lt;strong&gt;&lt;span style='color:#C77CFF'&gt;UKR&lt;/span&gt;&lt;/strong&gt;, &lt;strong&gt;&lt;span style='color:#F8766D'&gt;CAF&lt;/span&gt;&lt;/strong&gt;, and &lt;strong&gt;&lt;span style='color:#7CAE00'&gt;ERI&lt;/span&gt;&lt;/strong&gt; experienced large increases in&lt;br&gt;normalized refugee outflow (i.e., refugees per 1k population),&lt;br&gt; compared to their 2010 baseline.\") +\n    xlab('Year') +\n    ylab('Change in Normalized Refugee Outflow*') +\n    labs(caption = \"&lt;span style='font-size:7pt'&gt;*Change in refugees per 1k population from the baseline value observed in 2010.&lt;/span&gt;\") +\n    theme(plot.title = ggtext::element_markdown(),\n          plot.caption = ggtext::element_markdown()) -&gt; plot\n\nWarning: Tried to calculate with group_by(), but the calculation failed.\nFalling back to ungrouped filter operation...\n\nplot"
  },
  {
    "objectID": "blog/2020/05/12/index.html",
    "href": "blog/2020/05/12/index.html",
    "title": "Modeling cognitive impairment using NHANES data",
    "section": "",
    "text": "In this blog post, I build a machine learning model to predict possible cases of cognitive impairment / dementia in a population of individuals over the age of 60. My data for this model comes from the 2013-2014 NHANES (National Health and Nutrition Examination Survey) study cohort, which is a nationally representative, longitudinal study of health in the US.\nAs an outcome measure, I’ll create a composite index of cognition by combining data from the Animal Fluency and Digit Symbol Substitution tasks. As predictors of this outcome, I’ll pull together variables that seem relevant to predicting dementia at a population level. For example, variables like age, race, gender, BMI, depression symptoms, alcohol use, blood lead levels, etc.\nI’ll use xgboost to train the model, and I’ll walk through a hypothetical use-case for the model, discussing what might be the appropriate model bias (e.g., specificity/recall).\nThe data is obtained from the NHANES website, for the 2013-2014 study cohort.\nData files are converted from XPT to CSV.\nRead the files into a single dataframe by joining on participant ID (SEQN)."
  },
  {
    "objectID": "blog/2020/05/12/index.html#cognitive-functioning-data",
    "href": "blog/2020/05/12/index.html#cognitive-functioning-data",
    "title": "Modeling cognitive impairment using NHANES data",
    "section": "Cognitive functioning data",
    "text": "Cognitive functioning data\nThis dataset contains multiple tests on which cognitive functioning was assessed. For this analysis, I will be considering the Animal Fluency Task (AFT) and the Digit Symbol Substitution Task (DSST). These tasks measure different aspects of cognition.\nIn past research, these tasks have each been shown to discriminate between populations with and without dementia. For example, see Howe (2007) or Rosano et al. [2016].\nI will take these measures and combine them to create a composite measure of cognition. By creating a composite, I will be able to reduce measurement noise or bias.\nTo create a composite, I will first “standardize” each score using z-score normalization so that each score represents a standardized difference from the the mean of its distribution. I will then take the average of the standardized scores."
  },
  {
    "objectID": "blog/2020/05/12/index.html#number-of-observations",
    "href": "blog/2020/05/12/index.html#number-of-observations",
    "title": "Modeling cognitive impairment using NHANES data",
    "section": "Number of observations",
    "text": "Number of observations\nAccording to the documentation on NHANES, there should be 1661 individuals with scores on the Animal Fluency Task (AFT), and 1592 participants with scores on the Digit Symbol Substitution Task (DSST). Here we can see that the intersection of individuals who completed AFT and DSST tasks is 1575.\nprint(len(df)) # All participants in the dataset\nprint(len(df[df['RIDAGEYR'] &gt; 60])) # All participants over 60\nprint(df['CFDAST'].notnull().sum()) # Participants with AFT scores\nprint(df['CFDDS'].notnull().sum()) # Participants with DSST scores\nlen(df[df['CFDAST'].notnull() & df['CFDDS'].notnull()]) # Individuals with both AFT and DSST\n\ndf2 = df[df['CFDAST'].notnull() & df['CFDDS'].notnull()].reset_index()\n10175\n1729\n1661\n1592"
  },
  {
    "objectID": "blog/2020/05/12/index.html#score-distributions",
    "href": "blog/2020/05/12/index.html#score-distributions",
    "title": "Modeling cognitive impairment using NHANES data",
    "section": "Score distributions",
    "text": "Score distributions\nBelow we can see that the distribution of scores on each task are approximately normal.\nplt.hist(df2['CFDAST'], bins=35)\nplt.title(\"Animal Fluency Scores\")\nplt.show()\nplt.hist(df2['CFDDS'], bins=35)\nplt.title(\"Digit Symbol Substitution Scores\")\n\n\n\npng\n\n\nText(0.5, 1.0, 'Digit Symbol Substitution Scores')\n\n\n\npng"
  },
  {
    "objectID": "blog/2020/05/12/index.html#composite-scoring",
    "href": "blog/2020/05/12/index.html#composite-scoring",
    "title": "Modeling cognitive impairment using NHANES data",
    "section": "Composite scoring",
    "text": "Composite scoring\nFirst I’ll standardize each of the test columns.\nfrom scipy.stats import zscore\ndf2['DSST_z'] = df2['CFDDS'].pipe(zscore)\ndf2['AFT_z'] = df2['CFDAST'].pipe(zscore)\nNext, I’ll create a composite by taking the average of the two standardized scores.\ndf2['COG'] = (df2['DSST_z'] + df2['AFT_z']) / 2\nFinally, I’ll check to make sure that the distribution of composite scores is still normal.\nplt.hist(df2['COG'], bins=35)\nplt.title(\"Composite Cognition\")\nText(0.5, 1.0, 'Composite Cognition')\n\n\n\npng"
  },
  {
    "objectID": "blog/2020/05/12/index.html#what-is-low-cognition",
    "href": "blog/2020/05/12/index.html#what-is-low-cognition",
    "title": "Modeling cognitive impairment using NHANES data",
    "section": "What is “low” cognition?",
    "text": "What is “low” cognition?\nSince these are standardized scores, we can say that low cognition represents 1 standardized unit below the mean.\nplt.hist(df2['COG'], bins=35)\nplt.axvline(x=-1, color='red', linestyle='--')\nplt.title(\"Composite Cognition with Threshold\")\nText(0.5, 1.0, 'Composite Cognition with Threshold')\n\n\n\npng\n\n\nI’ll create a variable to track this classification.\ndf2['COG_low'] = df2['COG'] &lt; -1"
  },
  {
    "objectID": "blog/2020/05/12/index.html#model-features",
    "href": "blog/2020/05/12/index.html#model-features",
    "title": "Modeling cognitive impairment using NHANES data",
    "section": "Model features",
    "text": "Model features\nI’ll collect all the features that I think might be interesting.\nfeatures = {# Composite cognition score\n            'COG': 'cognition',\n            'COG_low': 'cognition_impaired',\n    \n            # Demographics\n            'RIAGENDR': 'gender', \n            'RIDAGEYR': 'age',\n            'RIDRETH1': 'race',\n            \n            # Poverty level\n            'INDFMMPI': 'poverty',\n            \n            # Body mass index\n            'BMXBMI': 'bmi',\n            \n            # Alcohol use\n            'ALQ120Q': 'alcohol_days',\n            \n            # Blood vitamin levels\n            'LBXVIDMS': 'vit_d',\n            'LBDB12': 'vit_b12',\n            \n            # Diet\n            'DBQ700': 'diet_healthy',\n            \n            # Lead\n            'LBXBPB': 'blood_lead',\n            \n            # Blood nicotine metabolite\n            'LBXCOT': 'cotinine',\n            \n            # Grip strength\n            # https://wwwn.cdc.gov/Nchs/Nhanes/2013-2014/MGX_H.htm#MGDCGSZ\n            'MGDCGSZ': 'grip_strength',\n            \n            # Smell test\n            'CSXCHOOD': 'smell_choco',\n            'CSXSBOD': 'smell_strawberry',\n            'CSXSMKOD': 'smell_smoke',\n            'CSXLEAOD': 'smell_leather',\n            'CSXSOAOD': 'smell_soap',\n            'CSXGRAOD': 'smell_grape',\n            'CSXONOD': 'smell_onion',\n            'CSXNGSOD': 'smell_gas',\n            \n            # Health in general\n            'HSD010': 'health_general',\n            \n            # Depression screener\n            'DPQ010': 'dep_1',\n            'DPQ020': 'dep_2',\n            'DPQ030': 'dep_3',\n            'DPQ040': 'dep_4',\n            'DPQ050': 'dep_5',\n            'DPQ060': 'dep_6',\n            'DPQ070': 'dep_7',\n            'DPQ080': 'dep_8',\n            'DPQ090': 'dep_9',\n            \n            # Sleep\n            'SLD010H': 'sleep',\n            \n            # Heart rate\n            'BPXPLS': 'heart_rate'\n            }\n\ndf2 = df2.loc[:, list(features)]\ndf2 = df2.rename(columns=features)\n\nRecoding variables\nSome of the features need to be combined. For example, the smell tests can all be combined into a single “smell test” score; the depression scale can be converted into a single depression score.\nOn some features the values are numeric but not ordinal. For example, on the depression scale scores 0-3 represent increasing levels of depression symptom severity, but a score of “9” means “don’t know” and a score of “7” means “refused”. This will be important to catch in the variable coding.\n\nDepression items\nFirst I’ll score the depression items. I’ll take the mean of all the items responded to.\nitems = ['dep_1', 'dep_2', 'dep_3', 'dep_4',\n        'dep_5', 'dep_6', 'dep_7', 'dep_8',\n        'dep_9']\n\ndef score_depression(x):\n    \n    scores = []\n    \n    for item in items:\n        value = x[item]\n        if value &lt; 4:\n            scores.append(value)\n    \n    if len(scores) == 0:\n        return None\n    else:\n        return np.mean(scores)\n    \n\ndf2.loc[:, 'dep_tot'] = df2.apply(score_depression, axis=1)\ndf2.drop(items, axis=1, inplace=True)\n\n\nSmell test\nNext, I’ll score the smell test items. Each item has one correct response and several incorrect responses. I’ll take the mean number of correct responses.\nitems = ['smell_choco', 'smell_strawberry',\n         'smell_smoke', 'smell_leather',\n         'smell_soap', 'smell_grape',\n         'smell_onion', 'smell_gas']\n\ndef score_smell(x):\n    \n    scores = []\n    \n    if x['smell_choco'] == 2:\n        scores.append(1)\n    elif ~np.isnan(x['smell_choco']):\n        scores.append(0)\n        \n    if x['smell_strawberry'] == 1:\n        scores.append(1)\n    elif ~np.isnan(x['smell_strawberry']):\n        scores.append(0)\n        \n    if x['smell_smoke'] == 3:\n        scores.append(1)\n    elif ~np.isnan(x['smell_smoke']):\n        scores.append(0)\n        \n    if x['smell_leather'] == 3:\n        scores.append(1)\n    elif ~np.isnan(x['smell_leather']):\n        scores.append(0)\n        \n    if x['smell_soap'] == 1:\n        scores.append(1)\n    elif ~np.isnan(x['smell_soap']):\n        scores.append(0)\n        \n    if x['smell_grape'] == 2:\n        scores.append(1)\n    elif ~np.isnan(x['smell_grape']):\n        scores.append(0)\n        \n    if x['smell_onion'] == 3:\n        scores.append(1)\n    elif ~np.isnan(x['smell_onion']):\n        scores.append(0)\n        \n    if x['smell_gas'] == 4:\n        scores.append(1)\n    elif ~np.isnan(x['smell_gas']):\n        scores.append(0)\n    \n    if len(scores) == 0:\n        return None\n    else:\n        return np.nanmean(scores)\n\ndf2.loc[:, 'smell_tot'] = df2.apply(score_smell, axis=1)\ndf2.drop(items, axis=1, inplace=True)\n\n\nOthers\nReplace “Don’t know” and “Refused” with missing.\ndf2['health_general'].replace([9.0, 7.0], [np.nan, np.nan], inplace=True)\ndf2['sleep'].replace([99.0, 77.0], [np.nan, np.nan], inplace=True)\ndf2['alcohol_days'].replace([999.0, 777.0], [np.nan, np.nan], inplace=True)\ndf2['diet_healthy'].replace([9.0, 7.0], [np.nan, np.nan], inplace=True)\n\n\n\nMissing values\nHow many values are missing in each column?\nprint('% missing values')\nround(df2.isnull().sum() / len(df2) * 100)\n% missing values\n\n\n\n\n\ncognition              0.0\ncognition_impaired     0.0\ngender                 0.0\nage                    0.0\nrace                   0.0\npoverty               11.0\nbmi                    1.0\nalcohol_days          18.0\nvit_d                  3.0\nvit_b12                4.0\ndiet_healthy           0.0\nblood_lead            51.0\ncotinine               4.0\ngrip_strength         11.0\nhealth_general         2.0\nsleep                  0.0\nheart_rate             3.0\ndep_tot                2.0\nsmell_tot              3.0\ndtype: float64"
  },
  {
    "objectID": "blog/2020/05/12/index.html#baseline-model",
    "href": "blog/2020/05/12/index.html#baseline-model",
    "title": "Modeling cognitive impairment using NHANES data",
    "section": "Baseline model",
    "text": "Baseline model\nI’ll train a baseline xgboost model, without any parameter tuning. This will give me a general sense of the model’s performance.\nmodel = XGBClassifier()\nmodel.fit(X_train, y_train)\nXGBClassifier(base_score=0.5, booster=None, colsample_bylevel=1,\n              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n              importance_type='gain', interaction_constraints=None,\n              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n              min_child_weight=1, missing=nan, monotone_constraints=None,\n              n_estimators=100, n_jobs=0, num_parallel_tree=1,\n              objective='binary:logistic', random_state=0, reg_alpha=0,\n              reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method=None,\n              validate_parameters=False, verbosity=None)\nmodel.score(X_test, y_test)\n0.8571428571428571\n\nTest performance\nHow did the model perform on the test set?\npreds = model.predict(X_test)\nprint(\"Accuracy: %.2f%%\" % (accuracy_score(y_test, preds) * 100.0))\nprint(\"Precision: %.2f%%\" % (precision_score(y_test, preds) * 100.0))\nprint(\"Recall: %.2f%%\" % (recall_score(y_test, preds) * 100.0))\nplot_roc_curve(model, X_test, y_test)\nAccuracy: 85.71%\nPrecision: 40.91%\nRecall: 21.95%\n\n\n\n\n\n&lt;sklearn.metrics._plot.roc_curve.RocCurveDisplay at 0x25115f7c7c8&gt;\n\n\n\npng\n\n\ntn, fp, fn, tp = confusion_matrix(y_test, preds).ravel()\nprint(f\"True Pos: {tp}\" , f\"\\nFalse Neg: {fn}\", f\"\\nFalse Pos: {fp}\")\nTrue Pos: 9 \nFalse Neg: 32 \nFalse Pos: 13"
  },
  {
    "objectID": "blog/2020/05/12/index.html#biasing-the-model-towards-specificity",
    "href": "blog/2020/05/12/index.html#biasing-the-model-towards-specificity",
    "title": "Modeling cognitive impairment using NHANES data",
    "section": "Biasing the model towards specificity",
    "text": "Biasing the model towards specificity\nThe model didn’t perform very well on specificity (a.k.a. recall), meaning that among the 41 individuals with cognitive impairment, the model was only able to correctly identify 22% of them.\nLet’s imagine a scenario in which we might want to bias the model towards high specificity:\nImagine the model is will be used to identify possible cases of dementia and when the model identifies a case of dementia they will be invited back for further testing to make a diagnosis with much higher precision. In this case, false positives would arguably carry a low risk because (let’s say for the sake of argument) further testing will be harmless and individuals who are healthy will be discovered as healthy. On the other side of the equation, let’s say that there is a high risk of negative consequences for anyone cases of dementia that go missed (and therefore untreated).\nThis is a case where we would want to optimize for detecting cases of dementia at risk of having an inflated false-positive rate.\nNow, one of the reasons for poor recall performance was the imbalanced classes used to train the data. That is to say, the impaired class had many fewer examples than the healthy class. I can correct for this using a weighting parameter when I instantiate the model, setting it to the ratio of healthy-to-impaired examples.\nimpaired = len(df2[df2['cognition_impaired'] == True])\nhealthy = len(df2[df2['cognition_impaired'] == False])\nimbalance_ratio = healthy / impaired\nprint(imbalance_ratio)\n6.720588235294118\nmodel = XGBClassifier(scale_pos_weight = imbalance_ratio)\nmodel.fit(X_train, y_train)\nmodel.score(X_test, y_test)\n0.8444444444444444\npreds = model.predict(X_test)\nprint(\"Accuracy: %.2f%%\" % (accuracy_score(y_test, preds) * 100.0))\nprint(\"Precision: %.2f%%\" % (precision_score(y_test, preds) * 100.0))\nprint(\"Recall: %.2f%%\" % (recall_score(y_test, preds) * 100.0))\nplot_roc_curve(model, X_test, y_test)\nAccuracy: 84.44%\nPrecision: 39.47%\nRecall: 36.59%\n\n\n\n\n\n&lt;sklearn.metrics._plot.roc_curve.RocCurveDisplay at 0x25116152d08&gt;\n\n\n\npng\n\n\ntn, fp, fn, tp = confusion_matrix(y_test, preds).ravel()\nprint(f\"True Pos: {tp}\" , f\"\\nFalse Neg: {fn}\", f\"\\nFalse Pos: {fp}\")\nTrue Pos: 15 \nFalse Neg: 26 \nFalse Pos: 23"
  },
  {
    "objectID": "blog/2020/05/12/index.html#model-with-hyperparameter-tuning",
    "href": "blog/2020/05/12/index.html#model-with-hyperparameter-tuning",
    "title": "Modeling cognitive impairment using NHANES data",
    "section": "Model with hyperparameter tuning",
    "text": "Model with hyperparameter tuning\nI’ve managed to bias the model to improve its specificity. This has resulted in more true positives at the cost of more false positives. But I think I can improve this metric even further by searching through the “hyperparameter space” and considering alternative models that optimize for this metric. This is what I’ll do next using random search.\n# Parameter grid\ngbm_param_grid = {\n    'n_estimators': np.arange(20, 100, 10),\n    'max_depth': range(2, 10),\n    'colsample_bytree': np.arange(0.1, 1.0, 0.005),\n    'eta': np.arange(0.1, 1.0, 0.01),\n    'scale_pos_weight': [imbalance_ratio]\n}\n\n# Initialize regressor\ngbm = XGBClassifier()\n\n# Random search\nrandomized_mse = RandomizedSearchCV(param_distributions=gbm_param_grid, \n                                    estimator=gbm, \n                                    scoring='recall', \n                                    n_iter=500, \n                                    cv=4, \n                                    random_state=42,\n                                    verbose=1)\n\n# Fit to data\nrandomized_mse.fit(X_train, y_train)\n\n# Print the best parameters and lowest RMSE\nprint(\"Best parameters found: \", randomized_mse.best_params_)\nFitting 4 folds for each of 500 candidates, totalling 2000 fits\n\n\n[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n\n\nBest parameters found:  {'scale_pos_weight': 6.720588235294118, 'n_estimators': 20, 'max_depth': 2, 'eta': 0.21999999999999995, 'colsample_bytree': 0.49500000000000033}\n\n\n[Parallel(n_jobs=1)]: Done 2000 out of 2000 | elapsed:  2.1min finished\n\nTest performance\npreds = randomized_mse.predict(X_test)\nprint(\"Accuracy: %.2f%%\" % (accuracy_score(y_test, preds) * 100.0))\nprint(\"Precision: %.2f%%\" % (precision_score(y_test, preds) * 100.0))\nprint(\"Recall: %.2f%%\" % (recall_score(y_test, preds) * 100.0))\nplot_roc_curve(randomized_mse, X_test, y_test)\nAccuracy: 72.38%\nPrecision: 27.00%\nRecall: 65.85%\n\n\n\n\n\n&lt;sklearn.metrics._plot.roc_curve.RocCurveDisplay at 0x251159b4a88&gt;\n\n\n\npng\n\n\ntn, fp, fn, tp = confusion_matrix(y_test, preds).ravel()\nprint(f\"True Pos: {tp}\" , f\"\\nFalse Neg: {fn}\", f\"\\nFalse Pos: {fp}\")\nTrue Pos: 27 \nFalse Neg: 14 \nFalse Pos: 73"
  },
  {
    "objectID": "blog/2020/04/04/index.html",
    "href": "blog/2020/04/04/index.html",
    "title": "Identifying pneumonia from chest x-rays using EfficientNet",
    "section": "",
    "text": "In my last post I used EfficientNet to identify plant diseases. I was surprised at how well this pre-trained model worked, with so few modifications, and I was curious how an approach like this might generalize to other visual image detection problems. In this post I use a similar approach to identify childhood pneumonia from chest x-ray images, using the Chest X-Ray Images (Pneumonia) dataset on Kaggle. Using this approach, I was able to achieve 97% accuracy, 97% precision, and 97% recall.\nThe code below implements this model. See also my notebook on Kaggle."
  },
  {
    "objectID": "blog/2020/04/04/index.html#training-performance",
    "href": "blog/2020/04/04/index.html#training-performance",
    "title": "Identifying pneumonia from chest x-rays using EfficientNet",
    "section": "Training performance",
    "text": "Training performance\n# Plot training and validation accuracy by epoch\nacc = model_history.history['accuracy']\nval_acc = model_history.history['val_accuracy']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'r', label='Training accuracy')\nplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.figure()\n&lt;Figure size 432x288 with 0 Axes&gt;\n\n\n\npng\n\n\n&lt;Figure size 432x288 with 0 Axes&gt;"
  },
  {
    "objectID": "blog/2020/04/04/index.html#confusion-matrix",
    "href": "blog/2020/04/04/index.html#confusion-matrix",
    "title": "Identifying pneumonia from chest x-rays using EfficientNet",
    "section": "Confusion matrix",
    "text": "Confusion matrix\nfrom sklearn.metrics import confusion_matrix\nfrom mlxtend.plotting import plot_confusion_matrix\nCM = confusion_matrix(test_generator.classes, labels)\nfig, ax = plot_confusion_matrix(conf_mat=CM ,  figsize=(5, 5))\nplt.show()\n\n\n\npng"
  },
  {
    "objectID": "blog/2020/04/04/index.html#classification-report",
    "href": "blog/2020/04/04/index.html#classification-report",
    "title": "Identifying pneumonia from chest x-rays using EfficientNet",
    "section": "Classification report",
    "text": "Classification report\nfrom sklearn.metrics import classification_report\nprint(classification_report(test_generator.classes, labels))\n              precision    recall  f1-score   support\n\n           0       0.95      0.92      0.94       317\n           1       0.97      0.98      0.98       855\n\n    accuracy                           0.97      1172\n   macro avg       0.96      0.95      0.96      1172\nweighted avg       0.97      0.97      0.97      1172"
  },
  {
    "objectID": "blog/2020/03/21/index.html",
    "href": "blog/2020/03/21/index.html",
    "title": "COVID-19 case growth and the Big 5 Personality traits",
    "section": "",
    "text": "Here I pose the following question:\nTo answer this question, I will need country-level aggregates on the Big 5 test, and a country-level aggregate that represents for “growth” over time in coronavirus cases.\nHere’s how I operationalize it: I take all the countries that reached at least 50 “confirmed cases” of the coronavirus, using data that’s up to date as of March 20, 2020. Then I take the number of cases those countries had 14-days after reaching 50 confirmed cases. This gives an estimate of growth within a country that can be compared across countries, because it puts them all on a level playing-field.\nNext, I compute country-level averages on the Big 5 Personality Test using data from the Open Source Psychometrics Project, and I only include countries with at least 1000 observations.\nFinally, I look at the correlation between Confirmed Cases at Day 14 and average scores on each of the Big 5 personality traits (openness, conscientiousness, extraversion, agreeableness, neuroticism [a.k.a. emotional stability]).\nFor easy reference, the following datasets are used:"
  },
  {
    "objectID": "blog/2020/03/21/index.html#filter",
    "href": "blog/2020/03/21/index.html#filter",
    "title": "COVID-19 case growth and the Big 5 Personality traits",
    "section": "Filter",
    "text": "Filter\nNext we’ll filter to countries that reached at least 50 confirmed cases, and had at least 14 days of data beyond reaching that point.\ncovid19 = covid19[covid19.ConfirmedCases &gt; 50]\ncovid19_numdays = covid19.loc[:, ['Country/Region', 'Date']]\\\n    .drop_duplicates()\\\n    .groupby('Country/Region')\\\n    .count()\\\n    .rename_axis('country')\\\n    .reset_index()\nprint(covid19_numdays.head())\n\ncovid19_mindays = covid19_numdays[covid19_numdays.Date &gt;= 14].reset_index()\ncovid19 = covid19[covid19['Country/Region'].isin(covid19_mindays.country)].reset_index()\n     country  Date\n0    Albania     5\n1    Algeria     5\n2    Andorra     2\n3  Argentina     5\n4    Armenia     5\nWhat/how many countries does that leave us with?\nprint(len(list(set(covid19['Country/Region'].values))))\nprint(set(covid19['Country/Region'].values))\n21\n{'Cruise Ship', 'Spain', 'United Kingdom', 'Singapore', 'Sweden', 'Kuwait', 'Bahrain', 'Germany', 'Iraq', 'Austria', 'Korea, South', 'Norway', 'China', 'Netherlands', 'Belgium', 'France', 'Malaysia', 'Switzerland', 'Iran', 'Japan', 'Italy'}\nObviously “Cruise Ship” isn’t a country. I won’t worry about it at this point, since it will get filtered out in later steps."
  },
  {
    "objectID": "blog/2020/03/21/index.html#compute-growth-over-14-days",
    "href": "blog/2020/03/21/index.html#compute-growth-over-14-days",
    "title": "COVID-19 case growth and the Big 5 Personality traits",
    "section": "Compute growth over 14 days",
    "text": "Compute growth over 14 days\nNext, we’ll compute the growth in cases for each country, from the date they reached 50 Confirmed Cases to the 14th day following that date. First we’ll need to collapse over province, since some countries are represented multiple times under different provinces.\ncovid19[covid19['Country/Region'] == 'China'].head()\n\n\n\n\n\n\n\n\nindex\n\n\nCountry/Region\n\n\nDate\n\n\nConfirmedCases\n\n\n\n\n\n\n47\n\n\n2777\n\n\nChina\n\n\n2020-01-26\n\n\n60.0\n\n\n\n\n48\n\n\n2778\n\n\nChina\n\n\n2020-01-27\n\n\n70.0\n\n\n\n\n49\n\n\n2779\n\n\nChina\n\n\n2020-01-28\n\n\n106.0\n\n\n\n\n50\n\n\n2780\n\n\nChina\n\n\n2020-01-29\n\n\n152.0\n\n\n\n\n51\n\n\n2781\n\n\nChina\n\n\n2020-01-30\n\n\n200.0\n\n\n\n\n\ncovid19_collapse_province = covid19\\\n    .groupby(['Country/Region', 'Date'])\\\n    .sum()\\\n    .reset_index()\ncovid19_collapse_province[covid19_collapse_province['Country/Region'] == 'China'].head()\n\n\n\n\n\n\n\n\nCountry/Region\n\n\nDate\n\n\nindex\n\n\nConfirmedCases\n\n\n\n\n\n\n47\n\n\nChina\n\n\n2020-01-22\n\n\n3540\n\n\n444.0\n\n\n\n\n48\n\n\nChina\n\n\n2020-01-23\n\n\n3541\n\n\n444.0\n\n\n\n\n49\n\n\nChina\n\n\n2020-01-24\n\n\n6612\n\n\n602.0\n\n\n\n\n50\n\n\nChina\n\n\n2020-01-25\n\n\n14172\n\n\n958.0\n\n\n\n\n51\n\n\nChina\n\n\n2020-01-26\n\n\n26818\n\n\n1628.0\n\n\n\n\n\ncovid19 = covid19_collapse_province\\\n    .groupby('Country/Region')\\\n    .head(14)\\\n    .groupby('Country/Region')\\\n    .tail(1)\n\ncovid19\n\n\n\n\n\n\n\n\nCountry/Region\n\n\nDate\n\n\nindex\n\n\nConfirmedCases\n\n\n\n\n\n\n13\n\n\nAustria\n\n\n2020-03-19\n\n\n1060\n\n\n2013.0\n\n\n\n\n28\n\n\nBahrain\n\n\n2020-03-17\n\n\n1176\n\n\n228.0\n\n\n\n\n45\n\n\nBelgium\n\n\n2020-03-19\n\n\n1414\n\n\n1795.0\n\n\n\n\n60\n\n\nChina\n\n\n2020-02-04\n\n\n90949\n\n\n23524.0\n\n\n\n\n119\n\n\nCruise Ship\n\n\n2020-02-20\n\n\n5103\n\n\n634.0\n\n\n\n\n162\n\n\nFrance\n\n\n2020-03-12\n\n\n6009\n\n\n2281.0\n\n\n\n\n184\n\n\nGermany\n\n\n2020-03-13\n\n\n6718\n\n\n3675.0\n\n\n\n\n205\n\n\nIran\n\n\n2020-03-08\n\n\n7657\n\n\n6566.0\n\n\n\n\n231\n\n\nIraq\n\n\n2020-03-20\n\n\n7728\n\n\n208.0\n\n\n\n\n245\n\n\nItaly\n\n\n2020-03-06\n\n\n7891\n\n\n4636.0\n\n\n\n\n273\n\n\nJapan\n\n\n2020-02-29\n\n\n8003\n\n\n241.0\n\n\n\n\n307\n\n\nKorea, South\n\n\n2020-03-04\n\n\n8302\n\n\n5621.0\n\n\n\n\n337\n\n\nKuwait\n\n\n2020-03-15\n\n\n8431\n\n\n112.0\n\n\n\n\n356\n\n\nMalaysia\n\n\n2020-03-19\n\n\n8907\n\n\n900.0\n\n\n\n\n371\n\n\nNetherlands\n\n\n2020-03-18\n\n\n9909\n\n\n2051.0\n\n\n\n\n387\n\n\nNorway\n\n\n2020-03-17\n\n\n10144\n\n\n1463.0\n\n\n\n\n404\n\n\nSingapore\n\n\n2020-02-26\n\n\n11481\n\n\n93.0\n\n\n\n\n441\n\n\nSpain\n\n\n2020-03-14\n\n\n11793\n\n\n6391.0\n\n\n\n\n461\n\n\nSweden\n\n\n2020-03-18\n\n\n12033\n\n\n1279.0\n\n\n\n\n477\n\n\nSwitzerland\n\n\n2020-03-16\n\n\n12090\n\n\n2200.0\n\n\n\n\n495\n\n\nUnited Kingdom\n\n\n2020-03-16\n\n\n16456\n\n\n1543.0"
  },
  {
    "objectID": "blog/2020/03/21/index.html#scoring-the-big-five-personality-test-items",
    "href": "blog/2020/03/21/index.html#scoring-the-big-five-personality-test-items",
    "title": "COVID-19 case growth and the Big 5 Personality traits",
    "section": "Scoring the Big Five Personality Test items",
    "text": "Scoring the Big Five Personality Test items\nThe Big 5 personality inventory contains 5 factors. Like most personality scales, the Big 5 has a mix of items that positively and negatively load onto these personality factors. For example, the factor Extraversion describes someone who is outgoing, energetic, talkative, and enjoys human interaction. The first Extraversion item [EXT1] is “I am the life of the party.”, a positively-keyed item; whereas the second item [EXT2] is “I don’t talk a lot.”, a negatively-keyed item.\nTo find out which items are positively or negatively keyed, we can look at the scale documentation on the IPIP website: https://ipip.ori.org/newBigFive5broadKey.htm"
  },
  {
    "objectID": "blog/2020/03/21/index.html#reverse-coding",
    "href": "blog/2020/03/21/index.html#reverse-coding",
    "title": "COVID-19 case growth and the Big 5 Personality traits",
    "section": "Reverse-coding",
    "text": "Reverse-coding\nBefore analyzing the data from a personality test, a psychologist will generally “reverse-code” the items that are negatively-keyed. This results in a dataset where the item values all have a common direction and interpretetion (i.e., a higher value corresponds with more of that trait). Mathematically, it allows you to then compute sums and averages for each of the factors. For example, after scoring the test items, we could compute an individual’s average for Extraversion items to get their Extraversion score.\nThis version of the Big 5 scale asks individuals to rate their level of agreement from 1 to 5, where 1 is strong disagreement and 5 is strong agreement. Reverse-coding is as simple as subtracting 6 from every reverse-keyed item.\nThe code below will accomplish this task.\npositively_keyed = ['EXT1', 'EXT3', 'EXT5', 'EXT7', 'EXT9',\n                    'EST1', 'EST3', 'EST5', 'EST6', 'EST7', 'EST8', 'EST9', 'EST10',\n                    'AGR2', 'AGR4', 'AGR6', 'AGR8', 'AGR9', 'AGR10',\n                    'CSN1', 'CSN3', 'CSN5', 'CSN7', 'CSN9', 'CSN10', \n                    'OPN1', 'OPN3', 'OPN5', 'OPN7', 'OPN8', 'OPN9', 'OPN10']\n\nnegatively_keyed = ['EXT2', 'EXT4', 'EXT6', 'EXT8', 'EXT10',\n                    'EST2', 'EST4',\n                    'AGR1', 'AGR3', 'AGR5', 'AGR7', \n                    'CSN2', 'CSN4', 'CSN6', 'CSN8', \n                    'OPN2', 'OPN4', 'OPN6']\nbig5.loc[:, negatively_keyed] = 6 - big5.loc[:, negatively_keyed]"
  },
  {
    "objectID": "blog/2020/03/21/index.html#country-level-big-5-aggregates",
    "href": "blog/2020/03/21/index.html#country-level-big-5-aggregates",
    "title": "COVID-19 case growth and the Big 5 Personality traits",
    "section": "Country-Level Big 5 Aggregates",
    "text": "Country-Level Big 5 Aggregates\nFirst, we should eliminate any country that doesn’t have very many observations. Somewhat arbitrarily, we’ll draw a line at N = 1000.\nbig5_country_count = big5.country\\\n    .value_counts()\\\n    .rename_axis('country')\\\n    .reset_index(name='counts')\n\nprint(len(big5_country_count[big5_country_count.counts &gt; 1000]))\nprint(big5_country_count[big5_country_count.counts &gt; 1000].country.values)\n58\n['US' 'GB' 'CA' 'AU' 'PH' 'IN' 'DE' 'NONE' 'NZ' 'NO' 'MY' 'MX' 'SE' 'NL'\n 'SG' 'ID' 'BR' 'FR' 'DK' 'IE' 'IT' 'ES' 'PL' 'FI' 'RO' 'BE' 'ZA' 'CO'\n 'HK' 'PK' 'RU' 'AR' 'CH' 'AE' 'TR' 'PT' 'GR' 'VN' 'HR' 'AT' 'CL' 'RS'\n 'CZ' 'TH' 'JP' 'PE' 'KR' 'HU' 'IL' 'KE' 'CN' 'BG' 'VE' 'EC' 'LT' 'SA'\n 'EG' 'EE']\nThere are 58 countries with at least 1000 observations. Let’s go with these.\nbig5 = big5[big5.country.isin(big5_country_count[big5_country_count.counts &gt; 1000].country.values)]\n\n# Filter on the columns we're going to use\nbig5 = big5.loc[:,['country'] + positively_keyed + negatively_keyed]\n\nFactor aggregation\nNext, we’ll compute averages for each of the five factors at the level of the individual.\nEXT = ['EXT' + str(i) for i in range(1,11)]\nEST = ['EST' + str(i) for i in range(1,11)]\nAGR = ['AGR' + str(i) for i in range(1,11)]\nCSN = ['CSN' + str(i) for i in range(1,11)]\nOPN = ['OPN' + str(i) for i in range(1,11)]\nbig5['EXT'] = big5.loc[:, EXT].mean(axis=1)\nbig5['EST'] = big5.loc[:, EST].mean(axis=1)\nbig5['AGR'] = big5.loc[:, AGR].mean(axis=1)\nbig5['CSN'] = big5.loc[:, CSN].mean(axis=1)\nbig5['OPN'] = big5.loc[:, OPN].mean(axis=1)\nbig5 = big5.loc[:, ['country', 'EXT', 'EST', 'AGR', 'CSN', 'OPN']]\nDrop NAs, and any with country = ‘NONE’\nbig5 = big5.dropna()\nbig5 = big5[big5.country != 'NONE']\n\n\nCountry-level averages\nNow we can calculate the country-level averages.\nbig5_cavgs = big5.groupby('country')\\\n                    .mean()\\\n                    .rename_axis('country')\\\n                    .reset_index()\nJust to illustrate, these are the top 5 countries by country-level Extraversion scores.\nbig5_cavgs.loc[:, ['country', 'EXT']]\\\n    .sort_values(by=['EXT'])\\\n    .tail()\\\n    .plot(x = 'country', \n          y = 'EXT', \n          kind='barh', \n          legend=False)\n\nplt.show()\n\n\n\npng"
  },
  {
    "objectID": "blog/2019/09/27/index.html",
    "href": "blog/2019/09/27/index.html",
    "title": "Predicting t-shirt size from height and weight",
    "section": "",
    "text": "Today I was given a task that sounded pretty straight-forward: What t-shirt size would you send to someone if you don’t know their shirt size, but instead you know their height, weight, and gender?\nIn fact, it seemed so straight-forward that I was sure there must be prior art out there that I could re-use. A StackOverflow, a mathematical formula, a GitHub repo, a blog post – there had to be something! To my surprise, there wasn’t any, not that I could find anyway.\nI guess this is a problem that hasn’t received a lot of attention. Or at least, it’s not the sort of problem that someone in the open source / open science community has tackled.\nSo I set out to build my own predictive algorithm."
  },
  {
    "objectID": "blog/2019/09/27/index.html#read-in-the-data",
    "href": "blog/2019/09/27/index.html#read-in-the-data",
    "title": "Predicting t-shirt size from height and weight",
    "section": "Read in the data",
    "text": "Read in the data\nOf course the data had to be in a SAS format. 🙄\nLuckily there’s an R package for reading SAS data files.\n\nlibrary(foreign)\nlibrary(tidyverse)\nlibrary(MASS)\n\na &lt;- read.xport(\"ARX_F.XPT\") # Arthritis data\nb &lt;- read.xport(\"BMX_F.XPT\") # Body measurements\nd &lt;- read.xport(\"DEMO_F.XPT\") # Demographics\n\nThese are the variables I’ll pull out from the different dataframes.\n\nSEQN - Participant ID\nARXCCIN - Inhale chest circumference in CM\nBMXWT - Weight in KG\nBMXHT - Height in CM\nBMXBMI - Body Mass Index (BMI)\nDMDHRGND - Gender of participant (1 = Male, 2 = Female)\n\nI’m using the inhale chest circumference because I found in some exploratory analyses (not reported here) that it has a stronger correlation to the other measurements. I guess the exhale circumference was more noisy for some reason?\n\na %&gt;% dplyr::select(id = SEQN, chest_in_cm = ARXCCIN) -&gt; chest_measures\nb %&gt;% dplyr::select(id = SEQN, weight_kg = BMXWT, height_cm = BMXHT, bmi = BMXBMI) -&gt; height_weight\nd %&gt;% dplyr::select(id = SEQN, gender = DMDHRGND) %&gt;%\n  mutate(gender = case_when(gender == 1 ~ \"M\", TRUE ~ \"F\")) -&gt; gender\n\n# Join datasets and select only the rows that have all measurements\nchest_measures %&gt;%\n  left_join(., height_weight, by = c('id')) %&gt;%\n  left_join(., gender, by = c('id')) %&gt;%\n  filter(!is.na(chest_in_cm),\n         !is.na(height_cm), \n         !is.na(weight_kg),\n         !is.na(gender), \n         !is.na(bmi)) -&gt; df"
  },
  {
    "objectID": "blog/2019/09/27/index.html#height-and-weight-model",
    "href": "blog/2019/09/27/index.html#height-and-weight-model",
    "title": "Predicting t-shirt size from height and weight",
    "section": "Height and weight model",
    "text": "Height and weight model\nTo build a model, I’ll run a stepwise linear regression to determine the model of best fit. I’ll enter height, weight, and gender as predictors and allow interaction terms. I’ll use AIC (Akaike’s Information Criterion) for model selection, since it penalizes models with added complexity and I want a parsimonious model that doesn’t overfit the data.\nI see that the best model includes all terms, including weight*height and weight*gender interaction terms.\n\nlm(data = subset(df, select= c(chest_in_cm, height_cm, weight_kg, gender)), \n   chest_in_cm ~ .) -&gt; mod\nstep.model &lt;- stepAIC(mod, direction = \"both\", trace = TRUE, scope = . ~ .^2)\n\nStart:  AIC=14857.43\nchest_in_cm ~ height_cm + weight_kg + gender\n\n                      Df Sum of Sq    RSS   AIC\n+ height_cm:weight_kg  1       220 115291 14851\n- height_cm            1         2 115513 14856\n+ weight_kg:gender     1        89 115421 14856\n&lt;none&gt;                             115510 14857\n+ height_cm:gender     1         7 115503 14859\n- gender               1      2052 117563 14937\n- weight_kg            1    397116 512627 21725\n\nStep:  AIC=14850.64\nchest_in_cm ~ height_cm + weight_kg + gender + height_cm:weight_kg\n\n                      Df Sum of Sq    RSS   AIC\n+ weight_kg:gender     1    144.02 115147 14847\n&lt;none&gt;                             115291 14851\n+ height_cm:gender     1     13.37 115277 14852\n- height_cm:weight_kg  1    219.87 115510 14857\n- gender               1   2064.63 117355 14930\n\nStep:  AIC=14846.88\nchest_in_cm ~ height_cm + weight_kg + gender + height_cm:weight_kg + \n    weight_kg:gender\n\n                      Df Sum of Sq    RSS   AIC\n&lt;none&gt;                             115147 14847\n+ height_cm:gender     1     3.499 115143 14849\n- weight_kg:gender     1   144.020 115291 14851\n- height_cm:weight_kg  1   274.743 115421 14856\n\nsummary(step.model)\n\n\nCall:\nlm(formula = chest_in_cm ~ height_cm + weight_kg + gender + height_cm:weight_kg + \n    weight_kg:gender, data = subset(df, select = c(chest_in_cm, \n    height_cm, weight_kg, gender)))\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-21.3179  -3.2347   0.2087   3.4462  15.4911 \n\nCoefficients:\n                     Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)         41.491415   4.708485   8.812  &lt; 2e-16 ***\nheight_cm            0.086786   0.028263   3.071 0.002148 ** \nweight_kg            0.666925   0.055507  12.015  &lt; 2e-16 ***\ngenderM             -0.030639   0.599462  -0.051 0.959239    \nheight_cm:weight_kg -0.001087   0.000328  -3.314 0.000925 ***\nweight_kg:genderM    0.016955   0.007065   2.400 0.016449 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.001 on 4604 degrees of freedom\nMultiple R-squared:  0.8152,    Adjusted R-squared:  0.815 \nF-statistic:  4061 on 5 and 4604 DF,  p-value: &lt; 2.2e-16\n\n# Save the model for later\nheight_weight_model &lt;- step.model"
  },
  {
    "objectID": "blog/2019/09/27/index.html#body-mass-index-bmi-model",
    "href": "blog/2019/09/27/index.html#body-mass-index-bmi-model",
    "title": "Predicting t-shirt size from height and weight",
    "section": "Body Mass Index (BMI) model",
    "text": "Body Mass Index (BMI) model\nNow I’ll do the same with BMI and gender.\n\nlm(data = subset(df, select= c(chest_in_cm, bmi, gender)), chest_in_cm ~ .) -&gt; mod\nstep.model &lt;- stepAIC(mod, direction = \"both\", trace = TRUE, scope = . ~ .^2)\n\nStart:  AIC=17986.13\nchest_in_cm ~ bmi + gender\n\n             Df Sum of Sq    RSS   AIC\n+ bmi:gender  1       725 227076 17973\n&lt;none&gt;                    227801 17986\n- gender      1     11229 239030 18206\n- bmi         1    385144 612946 22547\n\nStep:  AIC=17973.44\nchest_in_cm ~ bmi + gender + bmi:gender\n\n             Df Sum of Sq    RSS   AIC\n&lt;none&gt;                    227076 17973\n- bmi:gender  1    724.73 227801 17986\n\nsummary(step.model)\n\n\nCall:\nlm(formula = chest_in_cm ~ bmi + gender + bmi:gender, data = subset(df, \n    select = c(chest_in_cm, bmi, gender)))\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-26.7682  -5.0630   0.2613   5.2463  23.2969 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 56.77733    0.66042  85.971  &lt; 2e-16 ***\nbmi          1.31235    0.02203  59.573  &lt; 2e-16 ***\ngenderM     -0.34122    0.92789  -0.368 0.713084    \nbmi:genderM  0.11906    0.03105   3.834 0.000128 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 7.021 on 4606 degrees of freedom\nMultiple R-squared:  0.6355,    Adjusted R-squared:  0.6353 \nF-statistic:  2677 on 3 and 4606 DF,  p-value: &lt; 2.2e-16\n\n# Save the model for later\nbmi_model &lt;- step.model"
  },
  {
    "objectID": "blog/2019/09/27/index.html#predict-chest-size-given-height-weight-and-gender",
    "href": "blog/2019/09/27/index.html#predict-chest-size-given-height-weight-and-gender",
    "title": "Predicting t-shirt size from height and weight",
    "section": "Predict chest size given height, weight, and gender",
    "text": "Predict chest size given height, weight, and gender\nNext we’ll take the final model selected from the above procedure and use it to predict chest circumference, in inches, given height, weight, and gender.\nTo test the model, I’ll use average values.\n\nmean(df$weight_kg)\n\n[1] 82.48026\n\nmean(df$height_cm)\n\n[1] 168.0299\n\nmean(df$bmi)\n\n[1] 29.12334\n\n\nHeight, weight, and gender\n\ninput &lt;- data.frame(height_cm = 168, weight_kg = 83, gender = \"F\")\n\n# 1 cm = 0.393701 inches\npredict(height_weight_model, input) * 0.393701\n\n       1 \n37.90109 \n\n\nBMI and gender\n\ninput &lt;- data.frame(bmi = 29, gender = \"F\")\npredict(bmi_model, input) * 0.393701\n\n       1 \n37.33684"
  },
  {
    "objectID": "blog/2019/09/27/index.html#chest-size-to-shirt-size",
    "href": "blog/2019/09/27/index.html#chest-size-to-shirt-size",
    "title": "Predicting t-shirt size from height and weight",
    "section": "Chest size to shirt size",
    "text": "Chest size to shirt size\nFinally, I’ll need to take the chest size prediction and convert it to a shirt size. Remember the size chart?\n\nFor some reason the chart leaves out “XS” and the ranges lso don’t provide full coverage of the possible chest size values (34-36” and then 38-40”???). So I’ll extend the upper bound of each range to meet the lower bound of each size above it. This will cause the predictions to err on the size of larger sizes rather than smaller sizes, which I think is better because if a shirt is too big, at least you can still wear it!\n\ninput &lt;- data.frame(height_cm = 168, weight_kg = 83, gender = \"F\")\n\ndata.frame(chest = predict(height_weight_model,input)[[1]] * 0.393701) %&gt;%\n  mutate(shirt_size = case_when(\n          chest &lt; 32 ~ \"XS\",\n          between(chest, 32, 36) ~ \"S\",\n          between(chest, 36, 40) ~ \"M\",\n          between(chest, 40, 44) ~ \"L\",\n          between(chest, 44, 48) ~ \"XL\",\n          between(chest, 48, 52) ~ \"2XL\",\n          between(chest, 52, 56) ~ \"3XL\",\n          between(chest, 56, 64) ~ \"4XL\",\n          chest &gt; 64 ~ \"5XL\"\n    )\n)\n\n     chest shirt_size\n1 37.90109          M"
  },
  {
    "objectID": "blog/2020/03/20/index.html",
    "href": "blog/2020/03/20/index.html",
    "title": "Using a logistic regression model to predict heart disease",
    "section": "",
    "text": "I decided to explore and model the Heart Disease UCI dataset from Kaggle. The original source can be found at the UCI Machine Learning Repository. The dataset contains 303 individuals and 14 attribute observations (the original source data contains additional features). The features included various heart disease-related measurements, like chest pain and resting ECG, as well as age and sex, and represented a mix of binary, categorical, ordinal, and numeric data. The outcome variable represented the presence or absence of heart disease.\nI applied a fairly standard machine learning process, beginning with understanding what the data represented – this involved looking at the raw data and reading the data dictionary and other documentation – followed by splitting the data into training and test sets, Exploratory Data Analysis to understand how the features relate to the outcome, feature encoding, model fitting (logistic regression), and model evaluation.\nUltimately, the model was 75% accurate in predicting heart disease. It correctly predicted 46 out of the 61 test cases. Of the errors it made, 5 were false-positive errors and 10 were false-negative errors."
  },
  {
    "objectID": "blog/2020/03/20/index.html#binary",
    "href": "blog/2020/03/20/index.html#binary",
    "title": "Using a logistic regression model to predict heart disease",
    "section": "Binary",
    "text": "Binary\n\nsex (0 = female; 1 = male)\nfbs: Fasting blood sugar &gt; 120 mg/dl\nexang: Exercise induced angina (0 = no; 1 = yes)"
  },
  {
    "objectID": "blog/2020/03/20/index.html#categorical",
    "href": "blog/2020/03/20/index.html#categorical",
    "title": "Using a logistic regression model to predict heart disease",
    "section": "Categorical",
    "text": "Categorical\n\ncp: Chest pain type (0 = Asymptomatic angina; 1 = Atypical angina; 2 = Non-angina; 3 = Typical angina)\nrestecg: Resting ECG (0 = Left ventricular hypertrophy; 1 = Normal; 2 = ST-T wave abnormality)\nslope: Slope of the peak exercise ST segment (0 = downsloping; 1 = upsloping; 2 = flat)\nthal: Thalium stress test result (0 = NA; 1 = Fixed defect; 2 = Normal; 3 = Reversible defect)"
  },
  {
    "objectID": "blog/2020/03/20/index.html#ordinal",
    "href": "blog/2020/03/20/index.html#ordinal",
    "title": "Using a logistic regression model to predict heart disease",
    "section": "Ordinal",
    "text": "Ordinal\n\nca: number of major vessels (0-3) colored by flourosopy"
  },
  {
    "objectID": "blog/2020/03/20/index.html#numeric",
    "href": "blog/2020/03/20/index.html#numeric",
    "title": "Using a logistic regression model to predict heart disease",
    "section": "Numeric",
    "text": "Numeric\n\nage\noldpeak: ST depression induced by exercise relative to rest\ntrestbps: Resting blood pressure\nchol: Serum cholestoral in mg/dl\nthalach: Maximum heart rate achieved during thalium stress test"
  },
  {
    "objectID": "blog/2020/03/20/index.html#target",
    "href": "blog/2020/03/20/index.html#target",
    "title": "Using a logistic regression model to predict heart disease",
    "section": "Target",
    "text": "Target\n\ntarget: 1 = heart disease; 0 = no heart disease\n\nI’ll create arrays so the features are easier to access later by type.\nbins = ['sex', 'fbs', 'exang']\ncats = ['cp', 'restecg', 'slope', 'thal']\nords = ['ca']\nnums = ['age', 'oldpeak', 'trestbps', 'chol', 'thalach']\ntarget = ['target']\nI’ll recode the categorical variables so the data exploration is easier.\ndf.cp = df.cp.replace({0:'Asympt.', 1:'Atypical', 2:'Non', 3:'Typical'})\ndf.restecg = df.restecg.replace({0:'LV hyper', 1:'Normal', 2:'ST-T wave'})\ndf.slope = df.slope.replace({0:'down', 1:'up', 2:'flat'})\ndf.thal = df.thal.replace({0:'NA', 1:'Fixed', 2:'Normal', 3:'Revers.'})"
  },
  {
    "objectID": "blog/2020/03/20/index.html#numeric-and-ordinal-descriptives",
    "href": "blog/2020/03/20/index.html#numeric-and-ordinal-descriptives",
    "title": "Using a logistic regression model to predict heart disease",
    "section": "Numeric and ordinal descriptives",
    "text": "Numeric and ordinal descriptives\nX_train[X_train.target == 0].drop(cats + bins + target, \n                                  axis=1).describe().loc[['mean', 'std']]\n\n\n\n\n\n\n\n\nage\n\n\ntrestbps\n\n\nchol\n\n\nthalach\n\n\noldpeak\n\n\nca\n\n\n\n\n\n\nmean\n\n\n52.598485\n\n\n129.000000\n\n\n247.340909\n\n\n158.280303\n\n\n0.585606\n\n\n0.30303\n\n\n\n\nstd\n\n\n9.366058\n\n\n16.414944\n\n\n56.661824\n\n\n18.929082\n\n\n0.759282\n\n\n0.73036\n\n\n\n\n\nX_train[X_train.target == 1].drop(cats + bins + target, \n                                  axis=1).describe().loc[['mean', 'std']]\n\n\n\n\n\n\n\n\nage\n\n\ntrestbps\n\n\nchol\n\n\nthalach\n\n\noldpeak\n\n\nca\n\n\n\n\n\n\nmean\n\n\n56.554545\n\n\n134.236364\n\n\n252.190909\n\n\n139.718182\n\n\n1.616364\n\n\n1.090909\n\n\n\n\nstd\n\n\n8.085082\n\n\n18.436067\n\n\n49.041547\n\n\n21.377400\n\n\n1.314669\n\n\n1.018593\n\n\n\n\n\nHere we see that individuals with heart disease are/have…\n\nOlder [age]\nHigher resting blood pressure [trestbps]\nHigher cholesterol [chol]\nLower maximum heart rate [thalach]\nHigher exercise-induced ST depression [oldpeak]\nMore vessels colored by fluoroscopy [ca]"
  },
  {
    "objectID": "blog/2020/03/20/index.html#categorical-and-boolean-counts",
    "href": "blog/2020/03/20/index.html#categorical-and-boolean-counts",
    "title": "Using a logistic regression model to predict heart disease",
    "section": "Categorical and boolean counts",
    "text": "Categorical and boolean counts\n\nCategorical\nfig = plt.figure(figsize=(8, 6))\nfig.subplots_adjust(hspace=0.4, wspace=0.4, bottom=0.01, top=0.95)\n\nfor i, var in enumerate(cats):\n    i = i + 1\n    ax = fig.add_subplot(2, 2, i)\n    ax.set_xticklabels(ax.get_xticklabels(), rotation=45)\n    sns.countplot(data = X_train, x = var, hue = 'target', ax = ax)\n\nplt.show()\n\n\n\nRelationship between categorical variables and outcome.\n\n\nHere we see that individuals with heart disease are/have…\n\nMore likely to present with asymptomatic angina [cp]\nLess likely to present with atypical or no angina [cp]\nLess likely to present with normal resting ECG [restecg]\nMore likely to present with an up slope [slope]\nLess likely to present with a flat slope [slope]\nMore likely to preset with a reversible defect [thal]\nLess likely to present with a normal result on the thalium test [thal]\n\n\nCombining sparse classes\nSome of the categorical feature classes are sparse. There are instances where it might also make conceptual sense to collapse them. For example, the resting ECG test [restecg] has values that essentially correspond with “normal” and “abnormal”. The “ST-T wave” class is relatively rare, but it behaves similar to “LV hyper”. So this is a case where it might make sense to collapse the two abnormal classes.\ndf.restecg = df.restecg.replace({'Normal':0, 'LV hyper':1, 'ST-T wave':1})\ndf.thal = df.thal.replace({'NA':0, 'Normal':0, 'Fixed': 1, 'Revers.': 1})\nX_train, X_test, y_train, y_test = train_test_split(df, \n                                                    df.target, \n                                                    test_size = 0.2, \n                                                    random_state = 42,\n                                                    stratify = df.target)\nWe’ll also re-classify the features for which we just now collapsed classes to binary, and remove them from the categorical feature list.\nbins = ['sex', 'fbs', 'exang', 'thal', 'restecg']\ncats = ['cp', 'slope']\n\n\n\nBinary\nfig = plt.figure(figsize=(8, 6))\nfig.subplots_adjust(hspace=0.4, wspace=0.4, bottom=0.01, top=0.95)\n\nfor i, var in enumerate(bins):\n    i = i + 1\n    ax = fig.add_subplot(2, 3, i)\n    sns.countplot(data = X_train, x = var, hue = 'target', ax = ax)\n\nplt.show()\n\n\n\nRelationship between binary variables and outcome.\n\n\nHere we see that individuals with heart disease are/have…\n\nMore likely to be male [sex]\nLess likely to present with fbs &lt;= 120 mg/dl [fbs]\nMore likely to experience exercise-induced angina [exang]\nMore likely to have an abnormal reading on the thalium test [thal]\nLess likely to have a normal reading on the resting ECG test [restecg]"
  },
  {
    "objectID": "blog/2020/03/20/index.html#fit-the-model",
    "href": "blog/2020/03/20/index.html#fit-the-model",
    "title": "Using a logistic regression model to predict heart disease",
    "section": "Fit the model",
    "text": "Fit the model\nfrom sklearn.linear_model import LogisticRegression\nlr = LogisticRegression()\nlr.fit(X_train_transformed, y_train)\nLogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n                   multi_class='auto', n_jobs=None, penalty='l2',\n                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n                   warm_start=False)"
  },
  {
    "objectID": "blog/2020/03/20/index.html#score-the-model",
    "href": "blog/2020/03/20/index.html#score-the-model",
    "title": "Using a logistic regression model to predict heart disease",
    "section": "Score the model",
    "text": "Score the model\nlr.score(X_test_transformed, y_test)\n0.7540983606557377\n75% is not terrible, but not terribly great either. Generally 80% and above is considered acceptable, though of course it depends on the application, and specific kinds of errors might be important here. We fell short of this rule of thumb but not by a huge margin."
  },
  {
    "objectID": "blog/2020/03/20/index.html#confusion-matrix",
    "href": "blog/2020/03/20/index.html#confusion-matrix",
    "title": "Using a logistic regression model to predict heart disease",
    "section": "Confusion matrix",
    "text": "Confusion matrix\nfrom sklearn.metrics import confusion_matrix\ny_pred = lr.predict(X_test_transformed)\nconfusion_matrix = confusion_matrix(y_test, y_pred)\nconfusion_matrix\narray([[28,  5],\n       [10, 18]])\nHere we can see where the mistakes were made. We made 46 (28+18) correct predictions and 15 (10+5) incorrect predictions. 5 errors were false-positive errors and 10 were false-negative errors. Depending on how we plan to use this data, one of these types of errors might be more important than the other. For example, maybe we want to minimize false-negatives, because we don’t want to run the risk of missing a diagnosis and taking proactive measures to treat it."
  },
  {
    "objectID": "blog/2020/04/01/index.html",
    "href": "blog/2020/04/01/index.html",
    "title": "Using tensorflow with EfficientNet to predict plant diseases",
    "section": "",
    "text": "As I continue to practice using tensorflow for image recognition tasks, I thought I would experiment with the Plant Pathology dataset on Kaggle. Like MNIST, this is an image recognition challenge. But in contrast to the simplicity of MNIST, this challenge is about making “fine-grained” visual discriminations. The images are larger and in RGB color, and the features are smaller and more nuanced.\nI ran into a few challenges here because the task was so compute intensive. The first challenge was getting tensorflow setup and working with my ultrabook’s GPU instead of the CPU. This was an important step to speed up how quickly I could iterate on models. The second challenge was getting past the initial poor performance of a custom convolutional neural network. I noticed that some Kagglers were using EfficientNet as a base model, so I decided to give that a try.\nEfficientNet is a CNN derived from ImageNet with similar accuracy but “an order of magnitude fewer parameters and FLOPS”. In other words, it’s a really efficient drop-in replacement for ImageNet. Once I added this as a base model, I quickly reached high validation accuracy in relatively few epochs.\nI’m starting to understand better the value of training these models with lots of compute power. My ultrabook’s GPU only has 4GB memory, which imposed a significant limitation on the batch size and image size that I could train the model with. In comparison to this, when I used a GPU-powered notebook on Kaggle that has 15GB of GPU memory, I was able to train on batch sizes and image sizes almost twice as large, which allowed the model to reach higher validation accuracy.\nUsing the code below, I was able to reach 91% validation accuracy. With large batch and image size settings on Kaggle, this model reached 94% test accuracy (see here).\n\nRead in data/libraries\n# Download data from Kaggle\n#!kaggle competitions download -c plant-pathology-2020-fgvc7\nimport pandas as pd\nimport numpy as np\n\ntrain = pd.read_csv('train.csv')\ntest = pd.read_csv('test.csv')\n\n# Append \".jpg\" to make things easier later\ntrain['image_id'] = train['image_id'] + '.jpg'\ntest['image_id'] = test['image_id'] + '.jpg'\nCheck devices available. Hopefully we see a GPU :)\nimport tensorflow as tf\n\n# Check devices\ntf.config.list_physical_devices(None)\n[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\ntrain.head()\n\n\n\n\n\n\n\n\nimage_id\n\n\nhealthy\n\n\nmultiple_diseases\n\n\nrust\n\n\nscab\n\n\n\n\n\n\n0\n\n\nTrain_0.jpg\n\n\n0\n\n\n0\n\n\n0\n\n\n1\n\n\n\n\n1\n\n\nTrain_1.jpg\n\n\n0\n\n\n1\n\n\n0\n\n\n0\n\n\n\n\n2\n\n\nTrain_2.jpg\n\n\n1\n\n\n0\n\n\n0\n\n\n0\n\n\n\n\n3\n\n\nTrain_3.jpg\n\n\n0\n\n\n0\n\n\n1\n\n\n0\n\n\n\n\n4\n\n\nTrain_4.jpg\n\n\n1\n\n\n0\n\n\n0\n\n\n0\n\n\n\n\n\nLet’s take a look at some of these images.\nfrom matplotlib import pyplot as plt\nfrom matplotlib import image as mpimg\n\nIMG_PATH = 'images/'\n\nfor i in range(5):\n    plt.imshow(mpimg.imread(IMG_PATH + train.iloc[i,:]['image_id']))\n    if train.iloc[i,:]['healthy'] == 1:\n        plt.title('healthy')\n    elif train.iloc[i,:]['multiple_diseases'] == 1:\n        plt.title('multiple_diseases')\n    elif train.iloc[i,:]['rust'] == 1:\n        plt.title('rust')\n    else:\n        plt.title('scab')\n    plt.show()\n\n\n\npng\n\n\n\n\n\npng\n\n\n\n\n\npng\n\n\n\n\n\npng\n\n\n\n\n\npng\n\n\n\n\nModel with EfficientNet Transfer Learning\nNow we’ll train a model using EfficientNet transfer learning.\nFor this model, we will use the following:\n\nA variety of image augmentations\nA ModelCheckpoint callback, so we can load the best model at the end\nReduceLROnPlateau to reduce the learning rate when the training gets stuck\nSigmoidFocalCrossEntropy loss function, which is good for imbalanced classes\n128x128 image sizes, because my GPU only has 4GB of memory :)\n\nfrom sklearn.model_selection import train_test_split\n\n# Training-validation split\ntraining, validation = train_test_split(train, \n                                        test_size = 0.2,\n                                        random_state = 42)\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nSIZE = 128\nBATCH = 16\nTARGETS = ['healthy','multiple_diseases','rust','scab']\n\n# image augmentations\nimage_gen = ImageDataGenerator(rescale=1./255,\n                                rotation_range=20,\n                                width_shift_range=0.2,\n                                height_shift_range=0.2,\n                                zoom_range=0.2,\n                                brightness_range=[0.5, 1.5],\n                                horizontal_flip=True,\n                                vertical_flip=True)\n\n# flow_from_dataframe generators\ntrain_generator = image_gen\\\n    .flow_from_dataframe(train,\n                        directory=IMG_PATH,\n                        target_size=(SIZE, SIZE),\n                        x_col=\"image_id\",\n                        y_col=TARGETS,\n                        class_mode='raw',\n                        shuffle=False,\n                        batch_size=BATCH)\n\nvalidation_generator = image_gen\\\n    .flow_from_dataframe(validation,\n                        directory=IMG_PATH,\n                        target_size=(SIZE, SIZE),\n                        x_col=\"image_id\",\n                        y_col=TARGETS,\n                        class_mode='raw',\n                        shuffle=False,\n                        batch_size=BATCH)\n\ntest_generator = image_gen\\\n    .flow_from_dataframe(test,\n                        directory=IMG_PATH,\n                        target_size=(SIZE, SIZE),\n                        x_col=\"image_id\",\n                        y_col=None,\n                        class_mode=None,\n                        shuffle=False,\n                        batch_size=BATCH)\nFound 1821 validated image filenames.\nFound 365 validated image filenames.\nFound 1821 validated image filenames.\nimport efficientnet.keras as efn \nimport tensorflow_addons as tfa\nfrom tensorflow.keras.callbacks import Callback\nfrom keras.models import Model\nfrom keras.layers import Dense, GlobalAveragePooling2D\nfrom keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\nfrom keras.optimizers import Adadelta\n\n# Callbacks\n## Keep the best model\nmc = ModelCheckpoint('model.hdf5', save_best_only=True, verbose=0, monitor='val_loss', mode='min')\n\n## Reduce learning rate if it gets stuck in a plateau\nrlr = ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=3, min_lr=0.000001, verbose=1)\n\n# Model\n## Define the base model with EfficientNet weights\nmodel = efn.EfficientNetB4(weights = 'imagenet', \n                           include_top = False, \n                           input_shape = (SIZE, SIZE, 3))\n\n## Output layer\nx = model.output\nx = GlobalAveragePooling2D()(x)\nx = Dense(128, activation=\"relu\")(x)\nx = Dense(64, activation=\"relu\")(x)\npredictions = Dense(4, activation=\"softmax\")(x)\n\n## Compile and run\nmodel = Model(inputs=model.input, outputs=predictions)\n\nmodel.compile(optimizer='adam',\n              loss=tfa.losses.SigmoidFocalCrossEntropy(), \n              metrics=['accuracy'])\n\nmodel_history = model.fit(train_generator,\n                            validation_data=validation_generator,\n                            steps_per_epoch=train_generator.n/BATCH,\n                            validation_steps=validation_generator.n/BATCH,\n                            epochs=7,\n                            verbose=1,\n                            callbacks = [rlr, mc])\nEpoch 1/7\n114/113 [==============================] - 96s 844ms/step - loss: 0.1770 - accuracy: 0.6425 - val_loss: 0.2638 - val_accuracy: 0.7589\nEpoch 2/7\n114/113 [==============================] - 68s 595ms/step - loss: 0.1193 - accuracy: 0.8034 - val_loss: 0.1677 - val_accuracy: 0.7890\nEpoch 3/7\n114/113 [==============================] - 68s 597ms/step - loss: 0.1116 - accuracy: 0.8276 - val_loss: 0.1171 - val_accuracy: 0.8137\nEpoch 4/7\n114/113 [==============================] - 68s 597ms/step - loss: 0.0851 - accuracy: 0.8655 - val_loss: 0.1628 - val_accuracy: 0.8630\nEpoch 5/7\n114/113 [==============================] - 69s 601ms/step - loss: 0.0758 - accuracy: 0.8836 - val_loss: 0.0551 - val_accuracy: 0.9068\nEpoch 6/7\n114/113 [==============================] - 68s 600ms/step - loss: 0.0724 - accuracy: 0.8984 - val_loss: 0.0455 - val_accuracy: 0.9096\nEpoch 7/7\n114/113 [==============================] - 69s 602ms/step - loss: 0.0714 - accuracy: 0.8874 - val_loss: 0.0827 - val_accuracy: 0.8959\n# Load best model\n#model.load_weights(\"model.hdf5\")\n# Plot training and validation accuracy\nacc = model_history.history['accuracy']\nval_acc = model_history.history['val_accuracy']\nloss = model_history.history['loss']\nval_loss = model_history.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'r', label='Training accuracy')\nplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.figure()\n&lt;Figure size 432x288 with 0 Axes&gt;\n\n\n\npng\n\n\n&lt;Figure size 432x288 with 0 Axes&gt;\n\n\nMake predictions\n# Make predictions\npreds = model.predict(test_generator, steps=test_generator.n/BATCH)\n\n\nPrepare submission\n# Make submission\nsample_sub = pd.read_csv('sample_submission.csv')\n\nsubmission = pd.DataFrame({'image_id': sample_sub['image_id'],\n                           'healthy': preds[:,0],\n                           'multiple_diseases': preds[:,1],\n                           'rust': preds[:,2],\n                           'scab': preds[:,3]\n                         })\nsubmission.to_csv(\"submission.csv\", index=False)\nsubmission.head()\n\n\n\n\n\n\n\n\nimage_id\n\n\nhealthy\n\n\nmultiple_diseases\n\n\nrust\n\n\nscab\n\n\n\n\n\n\n0\n\n\nTest_0\n\n\n0.092860\n\n\n0.169678\n\n\n0.656923\n\n\n0.080539\n\n\n\n\n1\n\n\nTest_1\n\n\n0.111859\n\n\n0.198063\n\n\n0.606325\n\n\n0.083752\n\n\n\n\n2\n\n\nTest_2\n\n\n0.026520\n\n\n0.044308\n\n\n0.003016\n\n\n0.926157\n\n\n\n\n3\n\n\nTest_3\n\n\n0.604854\n\n\n0.147050\n\n\n0.111277\n\n\n0.136820\n\n\n\n\n4\n\n\nTest_4\n\n\n0.078862\n\n\n0.118420\n\n\n0.750966\n\n\n0.051751"
  },
  {
    "objectID": "blog/2020/04/11/index.html",
    "href": "blog/2020/04/11/index.html",
    "title": "Estimating how many people live near a landmark / point-of-interest",
    "section": "",
    "text": "It can be useful to know how many people live near a landmark / point-of-interest (POI). For example, a location is often considered “walkable” if you can walk to it in 10 minutes or less. Understanding how many people live near a POI is one way of estimating how many people are within walking distance of a POI, if they were to walk from their home to the POI.\nIn this post, I start with a point-of-interest, “Times Square, NYC”, and using the Census API I find out how many people live within the census tract that contains this POI (a tract is one of the smallest sub-divisions for which the Census provides population estimates).\nIf we wanted to go a bit further down this path of estimating “population within walking distance” we could take this approach and expand it to include all census tracts within a certain distance of our POI census tract. I used this approach one time to understand the potential “reach” of outdoor neighborhood advertising."
  },
  {
    "objectID": "blog/2020/04/11/index.html#getting-shapefiles",
    "href": "blog/2020/04/11/index.html#getting-shapefiles",
    "title": "Estimating how many people live near a landmark / point-of-interest",
    "section": "Getting shapefiles",
    "text": "Getting shapefiles\nshpurls = states.NY.shapefile_urls()\nfor region, url in shpurls.items():\n    print(region, url)\ntract https://www2.census.gov/geo/tiger/TIGER2010/TRACT/2010/tl_2010_36_tract10.zip\ncd https://www2.census.gov/geo/tiger/TIGER2010/CD/111/tl_2010_36_cd111.zip\ncounty https://www2.census.gov/geo/tiger/TIGER2010/COUNTY/2010/tl_2010_36_county10.zip\nstate https://www2.census.gov/geo/tiger/TIGER2010/STATE/2010/tl_2010_36_state10.zip\nzcta https://www2.census.gov/geo/tiger/TIGER2010/ZCTA5/2010/tl_2010_36_zcta510.zip\nblock https://www2.census.gov/geo/tiger/TIGER2010/TABBLOCK/2010/tl_2010_36_tabblock10.zip\nblockgroup https://www2.census.gov/geo/tiger/TIGER2010/BG/2010/tl_2010_36_bg10.zip\nNow we’ll download and unzip the shapefiles for the tract zip.\nwget.download('https://www2.census.gov/geo/tiger/TIGER2010/TRACT/2010/tl_2010_36_tract10.zip')\nwith zipfile.ZipFile('tl_2010_36_tract10.zip', 'r') as zip_ref:\n    zip_ref.extractall()\n-1 / unknown"
  },
  {
    "objectID": "blog/2020/04/11/index.html#converting-shapefile-to-lnglat-coords",
    "href": "blog/2020/04/11/index.html#converting-shapefile-to-lnglat-coords",
    "title": "Estimating how many people live near a landmark / point-of-interest",
    "section": "Converting shapefile to LNG/LAT coords",
    "text": "Converting shapefile to LNG/LAT coords\nNext, we’ll read the shape files into a dataframe, giving us a “coords” column, using the shapefile library. Note that these will be in LNG, LAT (not LAT, LNG).\ndef read_shapefile(sf):\n    \"\"\"\n    Read a shapefile into a Pandas dataframe with a 'coords' \n    column holding the geometry information. This uses the pyshp\n    package\n    \"\"\"\n    fields = [x[0] for x in sf.fields][1:]\n    records = sf.records()\n    shps = [s.points for s in sf.shapes()]    \n    df = pd.DataFrame(columns=fields, data=records)\n    df = df.assign(coords=shps)\n    return df\n\nshp_path = 'tl_2010_36_tract10.shp'\nsf = shp.Reader(shp_path)\ndf = read_shapefile(sf)\nThis is the tract we’re interested in:\npoi_tract = df[df['GEOID10'] == poi_cg['Census Tracts'][0]['GEOID']].reset_index()\npoi_tract['coords']\n0    [(-73.985085, 40.758589), (-73.98225599999999,...\nName: coords, dtype: object"
  },
  {
    "objectID": "blog/2020/04/11/index.html#map-the-poi-marker-and-tract-polygon",
    "href": "blog/2020/04/11/index.html#map-the-poi-marker-and-tract-polygon",
    "title": "Estimating how many people live near a landmark / point-of-interest",
    "section": "Map the POI marker and tract polygon",
    "text": "Map the POI marker and tract polygon\nFinally, we’re ready to map the POI and the tract polygon in which it is located. We’ll use shapely to get the polygon and folium to do the mapping.\n# Convert to Polygon\npoi_poly = Polygon(poi_tract['coords'][0])\n\n# Initialize map with zoom and custom tileset, centered on POI\nm = folium.Map(location=[poi['lat'], poi['lng']],\n               zoom_start=16,\n               tiles='cartodbpositron')\n\n# Add a map pin\nfolium.Marker([poi['lat'], poi['lng']]).add_to(m)\n\n# Add the polygon\nfolium.GeoJson(poi_poly).add_to(m)\n\nm"
  },
  {
    "objectID": "blog/2023/08/19/index.html",
    "href": "blog/2023/08/19/index.html",
    "title": "Building a prediction model to detect spam email",
    "section": "",
    "text": "Getting back into the swing of things. This is my first blog post in more than 3 years!\nFor this post, I’ll be using the Week 33 Tidy Tuesday dataset. This one is all about spam email.\nFrom the dataset description:\nlibrary(tidyverse)\nlibrary(caret)\nlibrary(corrplot)\nlibrary(tidymodels)\nlibrary(usemodels)\nlibrary(future)\nlibrary(rpart)\nlibrary(rpart.plot)\nknitr::opts_chunk$set(echo = TRUE, fig.width = 4.5, fig.height = 2.5)"
  },
  {
    "objectID": "blog/2023/08/19/index.html#average-values-by-spam",
    "href": "blog/2023/08/19/index.html#average-values-by-spam",
    "title": "Building a prediction model to detect spam email",
    "section": "Average values, by spam",
    "text": "Average values, by spam\nLet’s start by looking at some averages (mean and median), split by the outcome variable.\n\ndf %&gt;%\n  group_by(yesno) %&gt;%\n  summarise_all(mean)\n\n# A tibble: 2 × 7\n  yesno crl.tot dollar  bang  money    n000   make\n  &lt;fct&gt;   &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n1 TRUE     471. 0.174  0.514 0.213  0.247   0.152 \n2 FALSE    161. 0.0116 0.110 0.0171 0.00709 0.0735\n\n\nWe can see that on average, spam emails have higher mean values for each of the predictors. No surprise there.\nHowever, the medians of some variables are zero, which suggests those variables have heavily positively skewed distributions with many zero values (sometimes called “zero-inflation”).\n\ndf %&gt;%\n  group_by(yesno) %&gt;%\n  summarise_all(median)\n\n# A tibble: 2 × 7\n  yesno crl.tot dollar  bang money  n000  make\n  &lt;fct&gt;   &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 TRUE      194   0.08 0.331     0     0     0\n2 FALSE      54   0    0         0     0     0\n\n\nWe can confirm this by looking at the counts of zero values, in relation to the total counts.\nAs we see, the vast majority of the spam emails had non-zero values on these variables, and non-spam emails had significantly fewer non-zero values, with the exception of crl.tot. In particular, spam emails were MUCH more likely to contain “!”, “$”, “000”, and “money”.\n\nno = df %&gt;% filter(yesno == FALSE) %&gt;% select(-yesno)\nyes = df %&gt;% filter(yesno == TRUE) %&gt;% select(-yesno)\n\nround(colSums(no&gt;0)/nrow(no)*100)\n\ncrl.tot  dollar    bang   money    n000    make \n    100      10      27       2       3      15 \n\nround(colSums(yes&gt;0)/nrow(yes)*100)\n\ncrl.tot  dollar    bang   money    n000    make \n    100      61      83      38      33      35"
  },
  {
    "objectID": "blog/2023/08/19/index.html#distributions-by-spam",
    "href": "blog/2023/08/19/index.html#distributions-by-spam",
    "title": "Building a prediction model to detect spam email",
    "section": "Distributions, by spam",
    "text": "Distributions, by spam\nNext, let’s look at the distributions.\nFor these plots, since they all have extreme skew, I’m going to truncate them at the 90th percentile and look at the left side where most of the mass is.\n\nfor (c in c('crl.tot', 'dollar', 'bang', 'money', 'n000', 'make')){\n  \n  qtile_90 &lt;- quantile(df[[c]], .90)\n  \n  df %&gt;%\n    filter(!!sym(c) &lt; qtile_90) %&gt;%\n    ggplot(aes(x = !!sym(c), fill=yesno)) +\n      geom_density(alpha=.7) +\n      ggtitle(c) -&gt; plot\n  print(plot)\n  \n}"
  },
  {
    "objectID": "blog/2023/08/19/index.html#feature-correlations",
    "href": "blog/2023/08/19/index.html#feature-correlations",
    "title": "Building a prediction model to detect spam email",
    "section": "Feature correlations",
    "text": "Feature correlations\nIt doesn’t look like the features are very strongly correlated. The strongest correlation is between n000 and dollar, which is not particularly surprising since I would expect that “000” would tend to appear in the context of a dollar value like “$1000”.\n\ndf %&gt;% \n  select(-yesno) %&gt;%\n  cor(use = \"complete.obs\")\n\n           crl.tot    dollar       bang      money       n000       make\ncrl.tot 1.00000000 0.2019477 0.03632120 0.08099318 0.16597657 0.08916478\ndollar  0.20194768 1.0000000 0.14291296 0.10469131 0.31097072 0.11741853\nbang    0.03632120 0.1429130 1.00000000 0.05107591 0.07010334 0.05829200\nmoney   0.08099318 0.1046913 0.05107591 1.00000000 0.05258693 0.18815518\nn000    0.16597657 0.3109707 0.07010334 0.05258693 1.00000000 0.13407211\nmake    0.08916478 0.1174185 0.05829200 0.18815518 0.13407211 1.00000000\n\n\nIf we convert the features to boolean, we can see that the presence of features have stronger correlations. The strongest correlation is again between dollar and n000, but money and dollar also occur together more often than not.\n\ndf %&gt;%\n  select(-yesno, -crl.tot) %&gt;%\n  mutate(dollar = dollar &gt; 0,\n         bang = bang &gt; 0,\n         money = money &gt; 0,\n         n000 = n000 &gt; 0,\n         make = make &gt; 0\n  ) %&gt;%\n  cor(use = \"complete.obs\")\n\n          dollar      bang     money      n000      make\ndollar 1.0000000 0.3779057 0.5058803 0.5372603 0.4133374\nbang   0.3779057 1.0000000 0.3290505 0.3404896 0.2641339\nmoney  0.5058803 0.3290505 1.0000000 0.4140177 0.4092119\nn000   0.5372603 0.3404896 0.4140177 1.0000000 0.3757565\nmake   0.4133374 0.2641339 0.4092119 0.3757565 1.0000000"
  },
  {
    "objectID": "blog/2023/08/19/index.html#simple-classification-algorithm",
    "href": "blog/2023/08/19/index.html#simple-classification-algorithm",
    "title": "Building a prediction model to detect spam email",
    "section": "Simple classification algorithm",
    "text": "Simple classification algorithm\nJust for fun, let’s see how well we can distinguish spam vs. not spam using a simple heuristic.\nI’ll label anything as spam if it contained at least 1 “money”, “$”, “000”, and “!” OR if it contained more than 100 uninterrupted sequences of capital letters and at least 1 “!”. This is just what comes to mind after looking at the frequency plots above.\n\ndf %&gt;%\n  mutate(simple_spam_flag = factor((money &gt; 0 & dollar &gt; 0 & bang &gt; 0 & n000 &gt; 0) | \n                                     (crl.tot &gt; 100 & bang &gt; 0), \n                                   levels=c(TRUE, FALSE))\n         ) -&gt; df_flag\n\nThis simple classification algorithm achieved an accuracy of 79%, with 64% sensitivity and 89% specificity. This doesn’t seem too bad. But what is a good baseline of performance?\n\nconfusionMatrix(df_flag$simple_spam_flag, df_flag$yesno, mode='everything')\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction TRUE FALSE\n     TRUE  1172   309\n     FALSE  641  2479\n                                          \n               Accuracy : 0.7935          \n                 95% CI : (0.7815, 0.8051)\n    No Information Rate : 0.606           \n    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       \n                                          \n                  Kappa : 0.5533          \n                                          \n Mcnemar's Test P-Value : &lt; 2.2e-16       \n                                          \n            Sensitivity : 0.6464          \n            Specificity : 0.8892          \n         Pos Pred Value : 0.7914          \n         Neg Pred Value : 0.7946          \n              Precision : 0.7914          \n                 Recall : 0.6464          \n                     F1 : 0.7116          \n             Prevalence : 0.3940          \n         Detection Rate : 0.2547          \n   Detection Prevalence : 0.3219          \n      Balanced Accuracy : 0.7678          \n                                          \n       'Positive' Class : TRUE            \n                                          \n\n\nWe can see that the base rate of spam is 39%.\n\nmean(df$yesno == TRUE)\n\n[1] 0.3940448\n\n\nA good baseline model might be to predict the majority class, which in this case is not-spam.\nThis “always predict FALSE” baseline model can be expected to achieve 1 minus the base rate of spam (i.e., 61%), and we can see that this is the case if we construct just such a model. This tells us that the heuristic model above is quite a bit better than a completely naive model.\n\nconfusionMatrix(factor(rep('FALSE',nrow(df_flag))), df_flag$yesno, mode='everything')\n\nWarning in confusionMatrix.default(factor(rep(\"FALSE\", nrow(df_flag))), :\nLevels are not in the same order for reference and data. Refactoring data to\nmatch.\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction TRUE FALSE\n     TRUE     0     0\n     FALSE 1813  2788\n                                          \n               Accuracy : 0.606           \n                 95% CI : (0.5917, 0.6201)\n    No Information Rate : 0.606           \n    P-Value [Acc &gt; NIR] : 0.5064          \n                                          \n                  Kappa : 0               \n                                          \n Mcnemar's Test P-Value : &lt;2e-16          \n                                          \n            Sensitivity : 0.000           \n            Specificity : 1.000           \n         Pos Pred Value :   NaN           \n         Neg Pred Value : 0.606           \n              Precision :    NA           \n                 Recall : 0.000           \n                     F1 :    NA           \n             Prevalence : 0.394           \n         Detection Rate : 0.000           \n   Detection Prevalence : 0.000           \n      Balanced Accuracy : 0.500           \n                                          \n       'Positive' Class : TRUE"
  },
  {
    "objectID": "blog/2023/08/19/index.html#decision-tree",
    "href": "blog/2023/08/19/index.html#decision-tree",
    "title": "Building a prediction model to detect spam email",
    "section": "Decision Tree",
    "text": "Decision Tree\nProceeding from simpler to more complex, we can go a step further and try fitting a decision tree model. The decision tree will help us to identify a more sophisticated rule set for classifying spam mail. Decision trees also have the advantage of being highly interpretable.\nWe’ll start by splitting our data into training and test – that way, we won’t be testing performance on the same data that our model was trained on, and we can minimize the risk of overfitting.\n\nset.seed(200)\nsplit &lt;- initial_split(df)\ntrain &lt;- training(split)\ntest &lt;- testing(split)\n\nNext, we’ll fit the model and then visualize its logic.\nWe can read this chart by starting at the root node and following the branches until we reach a terminal node. The predicted value at this terminal node will give us the prediction that the model has made, and the path that we followed to get there provides its reasoning for the prediction.\nSo for example, if we follow the tree to the left-most terminal node, we can see that it would predict that an email was spam if it contained dollar &gt;= 0.056. If we follow the tree to the right-most terminal, we can see that it would predict that an email was not spam if it contained dollar &lt; 0.056 and bang &gt;= 0.12. The percentage value in the node tells us what percentage of emails met these criteria. So 24% of emails met the former criteria, and 54% the latter.\n\ndecision_tree &lt;- rpart(yesno ~ ., data=train, method='class')\ndecision_tree\n\nn= 3450 \n\nnode), split, n, loss, yval, (yprob)\n      * denotes terminal node\n\n 1) root 3450 1358 FALSE (0.3936232 0.6063768)  \n   2) dollar&gt;=0.0555 839   94 TRUE (0.8879619 0.1120381) *\n   3) dollar&lt; 0.0555 2611  613 FALSE (0.2347759 0.7652241)  \n     6) bang&gt;=0.1205 739  330 TRUE (0.5534506 0.4465494)  \n      12) crl.tot&gt;=80.5 361   75 TRUE (0.7922438 0.2077562) *\n      13) crl.tot&lt; 80.5 378  123 FALSE (0.3253968 0.6746032)  \n        26) bang&gt;=0.802 85   34 TRUE (0.6000000 0.4000000) *\n        27) bang&lt; 0.802 293   72 FALSE (0.2457338 0.7542662) *\n     7) bang&lt; 0.1205 1872  204 FALSE (0.1089744 0.8910256) *\n\nrpart.plot(decision_tree)\n\n\n\n\n\n\n\nFinally, we can test the model on the out-of-sample test dataset and see how it performs.\nOverall it achieved an accuracy of 85%, with 78% sensitivity and 89% specificity. This model has similar specificity as the heuristic model, but better sensitivity, and therefore better overall accuracy.\n\ntest_pred &lt;- predict(decision_tree, test, type='class')\nconfusionMatrix(test_pred, test$yesno, mode='everything')\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction TRUE FALSE\n     TRUE   355    77\n     FALSE  100   619\n                                          \n               Accuracy : 0.8462          \n                 95% CI : (0.8241, 0.8666)\n    No Information Rate : 0.6047          \n    P-Value [Acc &gt; NIR] : &lt;2e-16          \n                                          \n                  Kappa : 0.6755          \n                                          \n Mcnemar's Test P-Value : 0.0982          \n                                          \n            Sensitivity : 0.7802          \n            Specificity : 0.8894          \n         Pos Pred Value : 0.8218          \n         Neg Pred Value : 0.8609          \n              Precision : 0.8218          \n                 Recall : 0.7802          \n                     F1 : 0.8005          \n             Prevalence : 0.3953          \n         Detection Rate : 0.3084          \n   Detection Prevalence : 0.3753          \n      Balanced Accuracy : 0.8348          \n                                          \n       'Positive' Class : TRUE"
  },
  {
    "objectID": "blog/2023/08/19/index.html#random-forest",
    "href": "blog/2023/08/19/index.html#random-forest",
    "title": "Building a prediction model to detect spam email",
    "section": "Random forest",
    "text": "Random forest\nNext, we’ll try a random forest model. Random forest models tend to perform better than decision trees, due to the fact that they are ensemble decision trees, meaning they group together the decisions of lots of decision trees. But as a result, they tend to be less interpretable. So if our goal was only to create the most accurate prediction model possible, then a random forest would be better suited to the task.\n\ncv &lt;- vfold_cv(train)\n\nI’ll use usemodels::use_ranger to give me a starting template.\n\nuse_ranger(yesno ~ ., train)\n\nranger_recipe &lt;- \n  recipe(formula = yesno ~ ., data = train) \n\nranger_spec &lt;- \n  rand_forest(mtry = tune(), min_n = tune(), trees = 1000) %&gt;% \n  set_mode(\"classification\") %&gt;% \n  set_engine(\"ranger\") \n\nranger_workflow &lt;- \n  workflow() %&gt;% \n  add_recipe(ranger_recipe) %&gt;% \n  add_model(ranger_spec) \n\nset.seed(17214)\nranger_tune &lt;-\n  tune_grid(ranger_workflow, resamples = stop(\"add your rsample object\"), grid = stop(\"add number of candidate points\"))\n\n\nI’ll remove the parameter tuning to keep things simple.\n\nranger_recipe &lt;- \n  recipe(formula = yesno ~ ., data = df)\n\nranger_spec &lt;- \n  rand_forest(trees = 1000) %&gt;% \n  set_mode(\"classification\") %&gt;% \n  set_engine(\"ranger\") \n\nranger_workflow &lt;- \n  workflow() %&gt;% \n  add_recipe(ranger_recipe) %&gt;% \n  add_model(ranger_spec) \n\nNext, I’ll fit the model using a resampling approach.\n\nset.seed(100)\nplan(multisession)\n\nfit_rf &lt;- fit_resamples(\n  ranger_workflow,\n  cv,\n  metrics = metric_set(accuracy, sens, spec),\n  control = control_resamples(verbose = TRUE,\n                              save_pred = TRUE,\n                              extract = function(x) x)\n)\n\nOverall, accuracy is pretty good: 89% accuracy, 79% sensitivity, and 95% specificity.\n\nfit_rf %&gt;%\n  collect_metrics()\n\n# A tibble: 3 × 6\n  .metric  .estimator  mean     n std_err .config             \n  &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n1 accuracy binary     0.886    10 0.00497 Preprocessor1_Model1\n2 sens     binary     0.793    10 0.00797 Preprocessor1_Model1\n3 spec     binary     0.946    10 0.00523 Preprocessor1_Model1\n\n\nNext, we can check the performance on the test set.\nWe can use collect_metrics() function on the last fit.\n\nranger_workflow %&gt;%\n  last_fit(split) %&gt;% \n  collect_metrics()\n\n# A tibble: 2 × 4\n  .metric  .estimator .estimate .config             \n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 accuracy binary         0.888 Preprocessor1_Model1\n2 roc_auc  binary         0.930 Preprocessor1_Model1\n\n\nOr we can use confusionMatrix() to get a bit more information.\nPerformance on the test set is similar to the training performance. Overall, accuracy is pretty good – and better than the decision tree. For a spam detection filter, we’d want to bias towards minimizing false positives (it would arguably be worse for people to lose legitimate mail to the filter, than to have spam mail slip through), and here we see that the specificity was quite good at ~95%.\n\nranger_workflow %&gt;%\n  last_fit(split) %&gt;% \n  extract_workflow() -&gt; final_model\n\nconfusionMatrix(predict(final_model, test)$.pred_class, test$yesno, mode='everything', positive='TRUE')\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction TRUE FALSE\n     TRUE   362    34\n     FALSE   93   662\n                                          \n               Accuracy : 0.8897          \n                 95% CI : (0.8701, 0.9072)\n    No Information Rate : 0.6047          \n    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       \n                                          \n                  Kappa : 0.7639          \n                                          \n Mcnemar's Test P-Value : 2.652e-07       \n                                          \n            Sensitivity : 0.7956          \n            Specificity : 0.9511          \n         Pos Pred Value : 0.9141          \n         Neg Pred Value : 0.8768          \n              Precision : 0.9141          \n                 Recall : 0.7956          \n                     F1 : 0.8508          \n             Prevalence : 0.3953          \n         Detection Rate : 0.3145          \n   Detection Prevalence : 0.3440          \n      Balanced Accuracy : 0.8734          \n                                          \n       'Positive' Class : TRUE"
  },
  {
    "objectID": "blog/2023/08/31/index.html",
    "href": "blog/2023/08/31/index.html",
    "title": "Joining messy dataframes using fuzzy joining, string cleaning, and column binding",
    "section": "",
    "text": "From the dataset description:\nThis last point is what I’ll be focusing on in this post: The challenge of joining two datasets together that don’t line up for a clean join.\nlibrary(tidyverse)\nlibrary(fuzzyjoin)\nlibrary(gt)\nfair_use_cases &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2023/2023-08-29/fair_use_cases.csv')\nfair_use_findings &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2023/2023-08-29/fair_use_findings.csv')"
  },
  {
    "objectID": "blog/2023/08/31/index.html#validation-checks",
    "href": "blog/2023/08/31/index.html#validation-checks",
    "title": "Joining messy dataframes using fuzzy joining, string cleaning, and column binding",
    "section": "Validation checks",
    "text": "Validation checks\nWhen inspecting the final result I expect to see 251 rows; none of which should be duplicates, and I do.\n\nfinal_join %&gt;%\n  summarize(\n    n_rows = n(),\n    n_distinct_rows = n_distinct(case, title)\n  )\n\n# A tibble: 1 × 2\n  n_rows n_distinct_rows\n   &lt;int&gt;           &lt;int&gt;\n1    251             251\n\n\nAs another check, I can look at the same records that were misaligned with the first approach. I can see they are now aligned.\n\nfinal_join %&gt;% \n  select(case, title, case_number) %&gt;%\n  head(111) %&gt;%\n  tail(3) %&gt;%\n  gt() %&gt;%\n  opt_interactive() %&gt;%\n  tab_header(title = \"Rows that were previously misaligned with bind_cols() are now aligned\") %&gt;%\n  tab_options(table.background.color = '#f1f3f5',\n              ihtml.page_size_default = 3)\n\n\n\n\nRows that were previously misaligned with bind_cols() are now aligned\n\n\n\n\n\n\n\nAnd here is the full table.\n\nfinal_join %&gt;% \n  select(case, title, case_number) %&gt;%\n  gt() %&gt;%\n  opt_interactive() %&gt;%\n  tab_header(title = \"Final results table (case, title, case_number)\") %&gt;%\n  tab_options(table.background.color = '#f1f3f5',\n              ihtml.page_size_default = 3)\n\n\n\n\nFinal results table (case, title, case_number)\n\n\n\n\n\n\n\nIt looks like the matches are now correct."
  },
  {
    "objectID": "blog/2023/09/19/index.html",
    "href": "blog/2023/09/19/index.html",
    "title": "Encoding high cardinality features with “embeddings”",
    "section": "",
    "text": "Embedding is categorical encoding method that that uses deep learning to represent categorical features as vectors. It’s particularly useful for categorical features with many levels, since it can be used to project high-dimensional features into low-dimensional space.\nIn this blog post, I’ll show how ML models with embedding encoding outperform models with other common categorical encoding methods (frequency, label, one-hot, and target). For this demonstration, I’ll be using the dataset from Kaggle’s Playground Series S3E22: Predict Health Outcomes of Horses."
  },
  {
    "objectID": "blog/2023/09/19/index.html#one-hot-encoding",
    "href": "blog/2023/09/19/index.html#one-hot-encoding",
    "title": "Encoding high cardinality features with “embeddings”",
    "section": "One-hot encoding",
    "text": "One-hot encoding\n\nrecipe_1hot_with_novel &lt;- \n  recipe(outcome ~ ., data = train %&gt;% select(-id)) %&gt;%\n  step_normalize(all_numeric_predictors()) %&gt;%\n  step_novel(all_nominal_predictors(), new_level = \"NA\") %&gt;%\n  step_dummy(all_nominal_predictors(), one_hot=T)\n\nThe first – and probably most popular – type of categorical encoding is one-hot encoding. One-hot encoding transforms a single categorical variable with N levels into binary variables encoding each of the N levels.\nFor example, age is a categorical variable with 2 levels.\n\nlevels(train$age)\n\n[1] \"adult\" \"young\"\n\nlength(levels(train$age))\n\n[1] 2\n\n\nWhen age is one-hot encoded, a column is created for each level to encode the value (e.g., if the original value was adult, then the age_adult column gets a 1 and the other columns get a 0). And since I’ve also included a step to encode novel levels as NA, there is also a third column for that.\n\nrecipe_1hot_with_novel %&gt;%\n  prep() %&gt;%\n  bake(new_data = NULL) %&gt;%\n  select(starts_with('age')) %&gt;%\n  head(3)\n\n# A tibble: 3 × 3\n  age_adult age_young age_NA.\n      &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1         1         0       0\n2         1         0       0\n3         1         0       0"
  },
  {
    "objectID": "blog/2023/09/19/index.html#label-encoding",
    "href": "blog/2023/09/19/index.html#label-encoding",
    "title": "Encoding high cardinality features with “embeddings”",
    "section": "Label encoding",
    "text": "Label encoding\n\nrecipe_label &lt;- \n  recipe(outcome ~ ., data = train %&gt;% select(-id)) %&gt;%\n  step_normalize(all_numeric_predictors()) %&gt;%\n  step_integer(all_nominal_predictors())\n\nWith label encoding, each level of the categorical variable is given an (arbitrary) number. In the tidymodels framework, step_integer works like scikit’s LabelEncoder, and encodes new values as zero. Here we see that one level of age was encoded as “1” and the other was encoded as “2”.\n\nrecipe_label %&gt;%\n  prep() %&gt;%\n  bake(new_data = NULL) %&gt;%\n  select(age) %&gt;%\n  distinct\n\n# A tibble: 2 × 1\n    age\n  &lt;int&gt;\n1     1\n2     2"
  },
  {
    "objectID": "blog/2023/09/19/index.html#frequency-encoding",
    "href": "blog/2023/09/19/index.html#frequency-encoding",
    "title": "Encoding high cardinality features with “embeddings”",
    "section": "Frequency encoding",
    "text": "Frequency encoding\n\nfreq_encoding &lt;- encodeR::frequency_encoder(\n  X_train = train,\n  X_test = test, \n  cat_columns = colnames(df %&gt;% select(where(is.factor), -outcome))\n)\n\ntrain_freq &lt;- freq_encoding$train\ntest_freq &lt;- freq_encoding$test\n\nWith frequency encoding, levels of the categorical variable are replaced with their frequency. Here, we can see how the levels of age have been replaced with their frequency in the training set. (When this is applied to the test set, these same training frequencies will be used.)\n\ntrain_freq %&gt;%\n  select(age) %&gt;%\n  distinct()\n\n# A tibble: 2 × 1\n     age\n   &lt;dbl&gt;\n1 0.937 \n2 0.0626\n\n\n\nrecipe_freq &lt;- \n  recipe(outcome ~ ., data = train_freq %&gt;% select(-id)) %&gt;%\n  step_normalize(all_numeric_predictors())"
  },
  {
    "objectID": "blog/2023/09/19/index.html#target-encoding",
    "href": "blog/2023/09/19/index.html#target-encoding",
    "title": "Encoding high cardinality features with “embeddings”",
    "section": "Target encoding",
    "text": "Target encoding\nFor target encoding (also called “effect encoding” or “likelihood encoding”), I’ll be using the h2o package because it supports multi-class targets. (The embed package can also do target encoding and integrates better with a tidymodels workflow, but at the moment it only supports binary targets.)\nUsing h2o requires some additional setup.\n\n# Convert to h2o format\ndf_h2o &lt;- as.h2o(df)\n\n# Split the dataset into train and test\nsplits_h2o &lt;- h2o.splitFrame(data = df_h2o, ratios = .8, seed = 42)\ntrain_h2o &lt;- splits_h2o[[1]]\ntest_h2o &lt;- splits_h2o[[2]]\n\nWith target encoding, the levels of the categorical variable are replaced with their mean value on the target. For example, if the level “young” was associated with a mean target value of 0.75, then this is the value with which that level would be replaced.\nBecause the outcome is being used for encoding, care needs to be taken when using this method to avoid leakage and overfitting. In this case, I’ll use the “Leave One Out” method: for each row, the mean is calculated over all rows excluding that row.\n\n# Choose which columns to encode\nencode_columns &lt;- colnames(df %&gt;% select(where(is.factor), -outcome)) # All categorical variables\n\n# Train a TE model\nte_model &lt;- h2o.targetencoder(x = encode_columns,\n                              y = 'outcome', \n                              keep_original_categorical_columns=T,\n                              training_frame = train_h2o,\n                              noise=0,\n                              seed=100,\n                              blending = T, # Blending helps with levels that are more rare\n                              data_leakage_handling = \"LeaveOneOut\")\n\n# New target encoded training and test datasets\ntrain_te &lt;- h2o.transform(te_model, train_h2o)\ntest_te &lt;- h2o.transform(te_model, test_h2o)\n\nHere we can see how the target encoding strategy encoded age: Two new variables are created, age_euthanized_te and age_lived_te. The encoded values represent the proportion of cases that were euthanized, or lived, for each level of age. (Note: The “died” level of the outcome variable is missing. This is because if we know the proportion that were euthanized and lived, we also know the proportion that died.)\n\ntrain_te %&gt;%\n  as.data.frame() %&gt;%\n  select(starts_with('age') & ends_with('te'), age) %&gt;%\n  distinct()\n\n  age_euthanized_te age_lived_te   age\n1        0.20937841    0.4776445 adult\n2        0.06005923    0.2157985 young\n\n\n\n# Drop the unencoded columns\ntrain_te %&gt;% \n  as.data.frame() %&gt;%\n  select(-all_of(encode_columns)) %&gt;%\n  as.h2o() -&gt; train_te\ntest_te %&gt;% \n  as.data.frame() %&gt;%\n  select(-all_of(encode_columns)) %&gt;%\n  as.h2o() -&gt; test_te\n\n\n# Create a recipe to use later\nrecipe_target &lt;- \n  recipe(outcome ~ ., data = train_te %&gt;% as.data.frame() %&gt;% select(-id)) %&gt;%\n  step_normalize(all_numeric_predictors())"
  },
  {
    "objectID": "blog/2023/09/19/index.html#model-fit-function",
    "href": "blog/2023/09/19/index.html#model-fit-function",
    "title": "Encoding high cardinality features with “embeddings”",
    "section": "Model fit function",
    "text": "Model fit function\nWith 3 models and 5 categorical encodings, I’ll need to fit 15 models. To streamline this process, I’ll define two functions:\n\n\nfit_model(): Given training and test datasets, a workflow containing a recipe for the categorical encoding, a model type, and an encoding type, this function will evaluate the model in-sample using cross-validation, then evaluate it out-of-sample, and then return a dataframe containing the results\n\nfit_encodings(): Given a model and model type, this function will generate recipes for each of the 5 categorical encodings, fit the 5 encodings using the model, and then return a dataframe with the results\n\n\nfit_model &lt;- function(train, test, workflow, model_type, encoding_type){\n  \n  set.seed(42)\n  folds &lt;- vfold_cv(train, v = 5)\n  \n  resampled_fit &lt;- \n    workflow %&gt;% \n    fit_resamples(folds,\n                  metrics = metric_set(f_meas))\n  \n  # Get in-sample F1\n  (resampled_fit %&gt;%\n    collect_metrics())$mean -&gt; train_perf\n  \n  # Get out-of-sample F1\n  fit &lt;- \n    workflow %&gt;%\n    fit(train)\n  \n  test$pred &lt;- predict(fit, test)$.pred_class\n  (f_meas(test, outcome, pred, estimator='micro'))$.estimate -&gt; test_perf\n  \n  # Combine in-sample and out-of-sample into a dataframe\n  df_perf &lt;- data.frame(model_type = model_type,\n                        encoding_type = encoding_type,\n                        train_perf = train_perf,\n                        test_perf = test_perf)\n  return(df_perf)\n}\n\n\n# Given a model, run it across the 4 encodings and return a dataframe that summarizes the results\nfit_encodings &lt;- function(model, model_type){\n  \n  set.seed(42)\n  tensorflow::set_random_seed(42)\n  \n  # One-hot encoded model\n  wflow_1hot &lt;- \n    workflow() %&gt;% \n    add_model(model) %&gt;%\n    add_recipe(recipe_1hot_with_novel)\n  \n  fit_model(train %&gt;% select(-id), \n            test %&gt;% select(-id), \n            wflow_1hot, \n            model_type,\n            'onehot') -&gt; onehot_model_results\n  \n  # Label encoded model\n  wflow_label &lt;- \n    workflow() %&gt;% \n    add_model(model) %&gt;%\n    add_recipe(recipe_label)\n  \n  fit_model(train %&gt;% select(-id), \n            test %&gt;% select(-id), \n            wflow_label, \n            model_type,\n            'label') -&gt; label_model_results\n  \n  # Frequency encoded model\n  wflow_freq &lt;- \n    workflow() %&gt;% \n    add_model(model) %&gt;%\n    add_recipe(recipe_freq)\n  \n  fit_model(train_freq %&gt;% select(-id), \n            test_freq %&gt;% select(-id), \n            wflow_freq, \n            model_type,\n            'frequency') -&gt; freq_model_results\n  \n  # Target encoded model\n  wflow_target &lt;- \n    workflow() %&gt;% \n    add_model(model) %&gt;%\n    add_recipe(recipe_target)\n  \n  fit_model(train_te %&gt;% as.data.frame() %&gt;% select(-id), \n            test_te %&gt;% as.data.frame() %&gt;% select(-id), \n            wflow_target, \n            model_type,\n            'target') -&gt; target_model_results\n  \n  \n  # Embedding encoded model\n  wflow_embedding &lt;- \n    workflow() %&gt;% \n    add_model(model) %&gt;%\n    add_recipe(recipe_embedding)\n  \n  fit_model(train %&gt;% as.data.frame() %&gt;% select(-id), \n            test %&gt;% as.data.frame() %&gt;% select(-id), \n            wflow_embedding, \n            model_type,\n            'embedding') -&gt; embedding_model_results\n  \n  # Compile results into a dataframe\n  onehot_model_results %&gt;%\n    bind_rows(label_model_results) %&gt;%\n    bind_rows(freq_model_results) %&gt;%\n    bind_rows(target_model_results) %&gt;%\n    bind_rows(embedding_model_results) -&gt; results\n  \n  results\n}\n\nI’ll run each of the models using the fit_encodings() and fit_model() functions that I just defined.\n\nfit_encodings(multinom_mod, 'multinomial logistic') -&gt; multinom_results\nfit_encodings(ranger_mod, 'random forest') -&gt; rf_results\nfit_encodings(xgboost_mod, 'xgboost') -&gt; xgb_results"
  },
  {
    "objectID": "blog/2023/12/04/index.html",
    "href": "blog/2023/12/04/index.html",
    "title": "Tackling the GSM8K (grade school math) with GPT-3.5 and self-consistency prompting",
    "section": "",
    "text": "I’ve been interested in AI tutoring applications for education for a long time, and with today’s Large Language Models like GPT, which have been shown to perform extremely well on standardized tests like the SAT and GRE, it seems that building these applications is now achievable. In fact, some companies have already started building these applications, like Khan Academy’s own Khanmigo.\nThe current generation of LLMs perform pretty well at many tasks, and research (like this paper on chain-of-thought prompting) has shown that there are a variety of “prompt engineering” techniques that can be used to boost performance even further. Basically, prompt engineering refers to the process of writing effective instructions for the model, as well as the process of breaking a complex task into sub-tasks and “chaining” prompts together.\nIn this post, I use the Self-Consistency prompt engineering strategy to improve the performance of a GPT-3.5 based model tasked with solving problems from the GSM8K (grade school math) benchmark dataset. Conceptually, the Self-Consistency strategy involves asking the LLM to follow multiple reasoning paths to generate multiple answers, and then taking a majority vote of its answers.\nI explore implementing the Self-Consistency strategy first by using a single prompt that instructs the model to generate multiple reasoning paths and answers, followed by identifying the majority vote of its own answers – all within a single response. In addition, I explore an implementation in which the LLM is asked to generate an answer multiple times using independent requests to the API, followed by using a simple frequency count to obtain the majority vote of its answers.\nUsing the Self-Consistency strategy, model performance was increased from 75% correct answers at baseline to 93% with the multiple-attempts implementation. Overall, this analysis suggests that Self-Consistency is an effective strategy to improve LLM performance on cognitive tasks like answering grade school math questions.\n(Note: This blog post uses a mix of python and R code.)"
  },
  {
    "objectID": "blog/2023/12/04/index.html#validity-checks",
    "href": "blog/2023/12/04/index.html#validity-checks",
    "title": "Tackling the GSM8K (grade school math) with GPT-3.5 and self-consistency prompting",
    "section": "Validity checks",
    "text": "Validity checks\nCheck that there are 1200 total records.\n\n\n\nR\n\nnrow(df)\n\n\n[1] 1200\n\n\nCheck that each of the 12 levels has 100 questions each.\n\n\n\nR\n\ndf %&gt;%\n  group_by(n_experts, n_attempts) %&gt;%\n  count() %&gt;%\n  filter(n == 100)\n\n\n# A tibble: 12 × 3\n# Groups:   n_experts, n_attempts [12]\n   n_experts n_attempts     n\n   &lt;fct&gt;     &lt;fct&gt;      &lt;int&gt;\n 1 1         1            100\n 2 1         3            100\n 3 1         5            100\n 4 1         10           100\n 5 3         1            100\n 6 3         3            100\n 7 3         5            100\n 8 3         10           100\n 9 5         1            100\n10 5         3            100\n11 5         5            100\n12 5         10           100"
  },
  {
    "objectID": "blog/2023/12/04/index.html#baseline-performance",
    "href": "blog/2023/12/04/index.html#baseline-performance",
    "title": "Tackling the GSM8K (grade school math) with GPT-3.5 and self-consistency prompting",
    "section": "Baseline performance",
    "text": "Baseline performance\nAs a baseline, I’ll use performance when the model is given 1 attempt using 1 expert.\nBaseline performance is 75%.\n\n\n\nR\n\ndf %&gt;%\n  filter(n_experts == 1, n_attempts == 1) %&gt;%\n  summarize(pct_correct = mean(is_correct)*100)\n\n\n  pct_correct\n1          75"
  },
  {
    "objectID": "blog/2023/12/04/index.html#single-prompt-imagined-experts",
    "href": "blog/2023/12/04/index.html#single-prompt-imagined-experts",
    "title": "Tackling the GSM8K (grade school math) with GPT-3.5 and self-consistency prompting",
    "section": "Single-prompt “imagined experts”",
    "text": "Single-prompt “imagined experts”\nIf the single-prompt “imagined experts” implementation improves performance, then I would expect that prompting the model to imagine 3 (or 5) experts would perform better than asking it to imagine only 1 expert. Contrary to this expectation, I see no improvement.\n\n\n\nR\n\ndf %&gt;%\n  group_by(n_experts) %&gt;%\n  summarize(pct_correct = mean(is_correct)*100) %&gt;%\n  ggplot(aes(x = n_experts, y = pct_correct, group = 1)) +\n    geom_line() +\n    labs(x=\"# of Imagined Experts\",\n         y='% Correct Answers',\n         title=\"Imagined experts had minimal benefits when averaged over\\ndifferent numbers of attempts\") +\n    ylim(65, 100) +\n    geom_text(aes(x = n_experts, y = pct_correct, label = paste0(round(pct_correct), '%')), vjust=-0.5)\n\n\n\n\n\n\n\n\nHowever, it’s possible that the improvement is obscured by the fact that I’m taking the average across number of attempts. It’s possible that the two implementations are redundant, and that the single-prompt “imagined experts” implementation is only beneficial when the model is given a single attempt.\nBelow we can see that if the model is given only 1 attempt, the prompt with 3 experts performed better than the prompt with only 1 imagined expert. There’s also a non-linear pattern, which may suggest that asking the model to imagine too many experts with different reasoning leads to some experts engaging sub-optimal reasoning, which then leads to poorer performance.\n\n\n\nR\n\ndf %&gt;%\n  filter(n_attempts == 1) %&gt;%\n  group_by(n_experts) %&gt;%\n  summarize(pct_correct = mean(is_correct)*100) %&gt;%\n  ggplot(aes(x = n_experts, y = pct_correct, group = 1)) +\n    geom_line() +\n    labs(x=\"# of Imagined Experts\",\n         y='% Correct Answers',\n         title=\"In the absence of multiple attempts, imagining 3 experts was best\") +\n    ylim(65, 100) +\n    geom_text(aes(x = n_experts, y = pct_correct, label = paste0(round(pct_correct), '%')), vjust=-0.5)"
  },
  {
    "objectID": "blog/2023/12/04/index.html#multiple-attempts",
    "href": "blog/2023/12/04/index.html#multiple-attempts",
    "title": "Tackling the GSM8K (grade school math) with GPT-3.5 and self-consistency prompting",
    "section": "Multiple attempts",
    "text": "Multiple attempts\nI expect that when I take the most frequent answer across attempts, performance would improve with the number of attempts (at least, up to a certain point). This would support the multiple-attempts implementation. Indeed this does seem to be the case: Model performance increased linearly with number of attempts, with 10 attempts performing better than 5, 5 better than 3, and 3 better than 1.\n\n\n\nR\n\ndf %&gt;%\n  group_by(n_attempts) %&gt;%\n  summarize(pct_correct = mean(is_correct)*100) %&gt;%\n  ggplot(aes(x = n_attempts, y = pct_correct, group = 1)) +\n    geom_line() +\n    labs(x=\"# of Attempts\",\n         y='% Correct Answers',\n         title=\"More attempts means more accuracy\") +\n    ylim(65, 100) +\n    geom_text(aes(x = n_attempts, y = pct_correct, label = paste0(round(pct_correct), '%')), vjust=-0.5)\n\n\n\n\n\n\n\n\nThe strongest model was one that was given 10 attempts, with only 1 imagined expert per attempt, which achieved 93% correct answers. This suggests that giving the model multiple attempts, while generating only 1 answer per attempt may be the best implementation of the Self-Consistency strategy.\n\n\n\nR\n\ndf %&gt;%\n  group_by(n_attempts, n_experts) %&gt;%\n  summarize(pct_correct = mean(is_correct)*100, .groups = 'drop') %&gt;%\n  ggplot(aes(x = n_attempts, y = pct_correct, group = n_experts, color = n_experts)) +\n    geom_line() +\n    labs(x=\"# of Attempts\",\n         y='% Correct Answers',\n         color=\"# of Imagined Experts\",\n         title=\"The best implementation: 10 attempts with 1 imagined expert\") +\n    ylim(65, 100) +\n    geom_text(aes(x = n_attempts, y = pct_correct, label = paste0(round(pct_correct), '%')), vjust=-0.5)\n\n\n\n\n\n\n\n\nOverall, this analysis provides strong evidence in favor of the multiple-attempts implementation of Self-Consistency, and weaker evidence in favor of the single-prompt “imagined experts” implementation. The best implementation involved asking the LLM to generate only 1 answer per attempt, while giving it 10 attempts in total. Using this implementation of the strategy, performance was increased from 75% correct answers at baseline to 93% correct answers."
  },
  {
    "objectID": "blog/2025/01/12/index.html",
    "href": "blog/2025/01/12/index.html",
    "title": "Challenging SAMRE: Comparing multi-round debate-style LLM evaluation to a robust (and much simpler) baseline",
    "section": "",
    "text": "I’ve been doing a lot of work with LLM-based evaluations lately, and I’ve been thinking about how to improve the quality of these evaluations.\nI like to read research papers from arXiv for inspiration, and I recently came across a paper called Adversarial Multi-Agent Evaluation of Large Language Models through Iterative Debates, which introduces a new method inspired by judicial process called Single Advocate Multi-Round Evaluation (SAMRE). Briefly, the SAMRE method evaluates the quality of different LLM outputs through an iterative debate process.\nI was initially impressed by the results, which reported a gain of ~6-8% over baseline. Below I’ve reproduced an excerpt from one of the tables in the paper showing their results.\nNote that the authors had tested versions of SAMRE with and without the addition of “juries”. In the table I’ve included only the version without juries, as it was both simpler and more performant. It is also this more performant version without juries that I am interested in testing. So with that said, in this blog post when I mention “SAMRE”, I will be referring to the version without juries.\nDespite the impressive results reported in the paper, I am often skeptical when researchers claim to have found that new methods outperform “baseline” models. I have observed that researchers often fail to implement standard best practices in their baseline models, and so their results are therefore not represenative of true gains over baseline. It is as if they are knocking down a straw man.\nGiven this skepticism of mine, I decided that it might be interesting to put it this skepticism the test: What if I implemented the SAMRE method (again, note that I am referring to the version without juries), and compared it to a baseline model that does implement standard best practices for prompt engineering? Would I find that the SAMRE method is indeed an improvement over the baseline? Or would I find that SAMRE is inferior to a properly implemented baseline?"
  },
  {
    "objectID": "blog/2025/01/12/index.html#tldr-what-i-did-and-what-i-found",
    "href": "blog/2025/01/12/index.html#tldr-what-i-did-and-what-i-found",
    "title": "Challenging SAMRE: Comparing multi-round debate-style LLM evaluation to a robust (and much simpler) baseline",
    "section": "TL;DR: What I did and what I found",
    "text": "TL;DR: What I did and what I found\nI tested three model variants:\n\nSAMRE, as implemented in the paper (without juries)\nBaseline-Weak: The baseline model used in the paper (which does not implement standard best practices for prompt engineering)\nBaseline-Strong: A baseline model that implements standard best practices for prompt engineering as I understand them.\n\nI evaluated each of these models using a sample of 300 conversations from MT-Bench for testing and evaluation. (MT-Bench was used in the original paper as well.)\nAfter running the evaluations and calculating Krippendorff alpha agreement with human judge ground truth, I found that although SAMRE did yield better agreement than Baseline-Weak more importantly it was inferior to Baseline-Strong – and by a fair margin. A similar result was found when examining binary classification accuracy using Matthews Correlation Coefficient (MCC).\nThese results serve to highlight the importance of implementing standard best practices in baseline models, as well as being skeptical of claims in research papers that compare new methods to a “baseline model”. Prompt engineers need to remain cautious and resist the urge to use complex methods that may seem more sophisticated than standard best practices, without first testing them against a well-engineered baseline."
  },
  {
    "objectID": "blog/2025/02/02/index.html",
    "href": "blog/2025/02/02/index.html",
    "title": "RAG-Powered LLM Longevity Coach",
    "section": "",
    "text": "In this post, I want to share a project I recently released on GitHub: a RAG-Powered LLM Longevity Coach.\nThis application implements a Retrieval-Augmented Generation (RAG) chatbot that offers personalized health and longevity advice — ideal for anyone (like myself) who is both curious about health and longevity, and also curious about how LLMs can tap into large datasets in a more targeted and efficient way.\nThe chatbot leverages both a large language model (LLM) and a vector-based retrieval system (i.e., FAISS) to ensure that only the most relevant user data is used to generate responses. This post will walk you through the motivation, the workflow, and practical considerations for building a RAG-powered health app.\nI built this in a weekend, collaborating with an AI coding assistant (currently I am using Cursor AI with a Claude 3.5 Sonnet model). However it has taken longer than that to collect my own health information for the vector store. I have been using this app (and a more nascent version of it) for a few weeks now, and it seems to provide useful insights that can be the starting points for actionable steps to improve longevity. Of course, the usual disclaimer applies: I am not a doctor, and the advice provided by the LLM is not intended to be a substitute for professional medical advice."
  },
  {
    "objectID": "blog/2025/02/02/index.html#motivation-and-context",
    "href": "blog/2025/02/02/index.html#motivation-and-context",
    "title": "RAG-Powered LLM Longevity Coach",
    "section": "Motivation and context",
    "text": "Motivation and context\nHealth-related information can become extensive. Simply dumping all of your medical details into a prompt often leads to bloated responses, token overuse, and confusion in the generated content.\nBy contrast, a RAG approach narrows the scope to only the pieces of information that matter to any given query. This can both reduce cost and improve the relevance of LLM responses."
  },
  {
    "objectID": "blog/2025/02/02/index.html#project-overview",
    "href": "blog/2025/02/02/index.html#project-overview",
    "title": "RAG-Powered LLM Longevity Coach",
    "section": "Project overview",
    "text": "Project overview\n\nStreamlit frontend\nThe user interacts with the Longevity Coach via a simple Streamlit app. The conversation is displayed in real time, with an optional “explanation” or “thought process” view to understand how the system arrives at a given retrieval strategy.\n\n\nVector search integration\nWhen a user types a query, the application constructs a search strategy and queries a FAISS-backed vector store for relevant data. This store can hold large amounts of health data – ranging from gene variants to complex lab results – and only the documents that match the query context are retrieved.\nFAISS (Facebook AI Similarity Search) is a library developed by Meta (formerly Facebook) that enables the efficient searching of vector embeddings. In a Retrieval-Augmented Generation (RAG) pipeline, FAISS allows you to store and quickly retrieve documents or data chunks based on their vectorized similarity to a given query.\n\n\nCost and accuracy considerations\nBy focusing on relevant data, you avoid a giant prompt stuffed with irrelevant details. This directly reduces token usage (and associated costs) while also boosting accuracy. There’s less “noise” to distract the model."
  },
  {
    "objectID": "blog/2025/02/02/index.html#how-it-works",
    "href": "blog/2025/02/02/index.html#how-it-works",
    "title": "RAG-Powered LLM Longevity Coach",
    "section": "How it works",
    "text": "How it works\n\nUser Interaction via Streamlit\nAll queries start with a simple text box in the Streamlit interface. For instance, a query might be:\n“What supplements should I consider for longevity based on my genetics and lab results?”\nDeveloping a Search Strategy\nThe system analyzes the user’s question (e.g., “heart disease risk”) and filters the search space to only match relevant genetic markers, lab results, or supplement details. This helps the chatbot focus on the user’s specific needs rather than drowning in the entire dataset.\nRetrieving Relevant Information\nA vector-based search kicks in, using FAISS to efficiently look up documents from a large repository of user health data. Only the top-matching documents are returned.\nGenerating the Response\nThe final query plus the retrieved snippets are passed into the LLM. Since the model only sees relevant info, it produces a more trustworthy, concise answer."
  },
  {
    "objectID": "blog/2025/02/02/index.html#screenshots",
    "href": "blog/2025/02/02/index.html#screenshots",
    "title": "RAG-Powered LLM Longevity Coach",
    "section": "Screenshots",
    "text": "Screenshots\nHere are a few snapshots of what the interface looks like:\n\nUser enters a query\n\nChatbot thinking\n\nRAG search strategy\n\nFinal response"
  },
  {
    "objectID": "blog/2025/02/02/index.html#getting-started",
    "href": "blog/2025/02/02/index.html#getting-started",
    "title": "RAG-Powered LLM Longevity Coach",
    "section": "Getting started",
    "text": "Getting started\nIf you want to try the app, you can get the code at the GitHub repository. The repo includes instructions for how to set up the environment and run the app."
  },
  {
    "objectID": "blog/2025/02/02/index.html#why-rag",
    "href": "blog/2025/02/02/index.html#why-rag",
    "title": "RAG-Powered LLM Longevity Coach",
    "section": "Why RAG?",
    "text": "Why RAG?\n\nEfficient Resource Use\nAvoid flooding the model with data. RAG narrows the prompt to only what’s necessary.\nRelevance and Accuracy\nA targeted context feed yields answers that are more on-point and less prone to hallucination.\nScales with Large Datasets\nAs more data is added—like new lab results or updated genetic findings—the retrieval pipeline still only picks the relevant bits."
  },
  {
    "objectID": "blog/2025/02/02/index.html#conclusion",
    "href": "blog/2025/02/02/index.html#conclusion",
    "title": "RAG-Powered LLM Longevity Coach",
    "section": "Conclusion",
    "text": "Conclusion\nBuilding an LLM-based chatbot in the health and longevity domain presents unique challenges: large, variable datasets and a high need for personalized yet accurate responses. Using a RAG approach strikes the right balance between efficiency and user-specific context. By gathering only the “must-know” details from a vector store, we reduce token usage, and produce more reliable insights."
  },
  {
    "objectID": "cv/index.html",
    "href": "cv/index.html",
    "title": "Curriculum vitæ",
    "section": "",
    "text": "Download current CV"
  },
  {
    "objectID": "research/articles/burleigh-et-al-2013/index.html",
    "href": "research/articles/burleigh-et-al-2013/index.html",
    "title": "Does the uncanny valley exist? An empirical test of the relationship between eeriness and the human likeness of digitally created faces",
    "section": "",
    "text": "The uncanny valley theory (UVT) (Mori, 1970) proposes that when stimuli are defined by a near-perfect resemblance to humans they cause people to experience greater negative affect relative to when they have perfect human likeness (HL) or little to no HL. Empirical research to support this non-linear relationship between negative affect and HL has been inconclusive, however, and a satisfactory causal explanation has not yet emerged to explain existing findings. In two studies, we examined the relationship between HL and eeriness using digital human faces. First, we examined the relationship between HL and eeriness while controlling for extraneous variation in stimulus appearance. We created two HL continua by manipulating the facial proportions and polygon count of several digital human models. Second, we proposed and tested two causal hypotheses regarding the uncanny valley phenomenon that we refer to as category conflict and feature atypicality. We created two additional HL continua by manipulating the skin coloration and category membership of models. Across these continua we introduced an atypical feature. Our results suggest that HL is linearly related to emotional response, except under conditions where HL varies by category membership, suggesting that previous empirical findings might be explained as a category conflict."
  },
  {
    "objectID": "research/articles/burleigh-et-al-2013/index.html#abstract",
    "href": "research/articles/burleigh-et-al-2013/index.html#abstract",
    "title": "Does the uncanny valley exist? An empirical test of the relationship between eeriness and the human likeness of digitally created faces",
    "section": "",
    "text": "The uncanny valley theory (UVT) (Mori, 1970) proposes that when stimuli are defined by a near-perfect resemblance to humans they cause people to experience greater negative affect relative to when they have perfect human likeness (HL) or little to no HL. Empirical research to support this non-linear relationship between negative affect and HL has been inconclusive, however, and a satisfactory causal explanation has not yet emerged to explain existing findings. In two studies, we examined the relationship between HL and eeriness using digital human faces. First, we examined the relationship between HL and eeriness while controlling for extraneous variation in stimulus appearance. We created two HL continua by manipulating the facial proportions and polygon count of several digital human models. Second, we proposed and tested two causal hypotheses regarding the uncanny valley phenomenon that we refer to as category conflict and feature atypicality. We created two additional HL continua by manipulating the skin coloration and category membership of models. Across these continua we introduced an atypical feature. Our results suggest that HL is linearly related to emotional response, except under conditions where HL varies by category membership, suggesting that previous empirical findings might be explained as a category conflict."
  },
  {
    "objectID": "research/articles/burleigh-et-al-2013/index.html#highlights",
    "href": "research/articles/burleigh-et-al-2013/index.html#highlights",
    "title": "Does the uncanny valley exist? An empirical test of the relationship between eeriness and the human likeness of digitally created faces",
    "section": "Highlights",
    "text": "Highlights\nWe create four human likeness continua using multiple digital human models. This is done by manipulating facial proportions, realism, and category membership. We obtain human likeness and emotion ratings, and examine their relationships. Linearity is found among all continua except for the category membership continuum. We suggest that this result may explain previous evidence of the uncanny valley."
  },
  {
    "objectID": "research/articles/burleigh-et-al-2018/index.html",
    "href": "research/articles/burleigh-et-al-2018/index.html",
    "title": "How to Screen Out VPS and International Respondents Using Qualtrics: A Protocol",
    "section": "",
    "text": "This protocol provides a method and code used to screen out respondents on Amazon’s Mechanical Turk (MTurk), or other microtask service providers, who are using VPS to cover their location or are responding from a country other than the one the researcher is targeting. It is designed for surveys using Qualtrics software, although it could be easily adapted for other online survey systems that provide JavaScript support. This protocol is likely to be broadly useful in addressing the quality crisis that has affected MTurk studies."
  },
  {
    "objectID": "research/articles/burleigh-et-al-2018/index.html#abstract",
    "href": "research/articles/burleigh-et-al-2018/index.html#abstract",
    "title": "How to Screen Out VPS and International Respondents Using Qualtrics: A Protocol",
    "section": "",
    "text": "This protocol provides a method and code used to screen out respondents on Amazon’s Mechanical Turk (MTurk), or other microtask service providers, who are using VPS to cover their location or are responding from a country other than the one the researcher is targeting. It is designed for surveys using Qualtrics software, although it could be easily adapted for other online survey systems that provide JavaScript support. This protocol is likely to be broadly useful in addressing the quality crisis that has affected MTurk studies."
  },
  {
    "objectID": "research/articles/burleigh-meegan-2017/index.html",
    "href": "research/articles/burleigh-meegan-2017/index.html",
    "title": "Risky prospects and risk aversion tendencies: does competition in the classroom depend on grading practices and knowledge of peer-status?",
    "section": "",
    "text": "When students are faced with the decision of whether to assist a peer, they should be sensitive to the potential risks associated with doing so. Two factors associated with risky helping behaviour in the classroom are: (1) the grading practices that are used, and (2) knowledge of a peer’s relative status. Normative (“curved”) grading creates a situation in which peer-interactions are potentially competitive, but it is only those interactions with peers of a similar status that carry the potential for assistance to be costly to oneself. In two studies, we created hypothetical scenarios in which the grading practices (normative or absolute) and peer-status proximity (proximate, distant, or unknown) were manipulated, and asked participants to report their willingness to cooperate with a peer by sharing their notes from an important lecture. We found that when normative grading was used, individuals were less willing to assist a peer when they knew that the peer’s status was proximate to their own. There was also less cooperation when peer status was unknown, under normative grading, which is consistent with a risk-aversion tendency."
  },
  {
    "objectID": "research/articles/burleigh-meegan-2017/index.html#abstract",
    "href": "research/articles/burleigh-meegan-2017/index.html#abstract",
    "title": "Risky prospects and risk aversion tendencies: does competition in the classroom depend on grading practices and knowledge of peer-status?",
    "section": "",
    "text": "When students are faced with the decision of whether to assist a peer, they should be sensitive to the potential risks associated with doing so. Two factors associated with risky helping behaviour in the classroom are: (1) the grading practices that are used, and (2) knowledge of a peer’s relative status. Normative (“curved”) grading creates a situation in which peer-interactions are potentially competitive, but it is only those interactions with peers of a similar status that carry the potential for assistance to be costly to oneself. In two studies, we created hypothetical scenarios in which the grading practices (normative or absolute) and peer-status proximity (proximate, distant, or unknown) were manipulated, and asked participants to report their willingness to cooperate with a peer by sharing their notes from an important lecture. We found that when normative grading was used, individuals were less willing to assist a peer when they knew that the peer’s status was proximate to their own. There was also less cooperation when peer status was unknown, under normative grading, which is consistent with a risk-aversion tendency."
  },
  {
    "objectID": "research/articles/burleigh-meegan-2017/index.html#important-figure",
    "href": "research/articles/burleigh-meegan-2017/index.html#important-figure",
    "title": "Risky prospects and risk aversion tendencies: does competition in the classroom depend on grading practices and knowledge of peer-status?",
    "section": "Important figure",
    "text": "Important figure\n\n\n\nFigure 1. Histograms of responses in the Normative grading conditions, indicating the presence of a bimodal distribution in the Uncertain condition, and unimodal distributions in the Distant and Proximate conditions."
  },
  {
    "objectID": "research/articles/ferrey-et-al-2015/index.html",
    "href": "research/articles/ferrey-et-al-2015/index.html",
    "title": "Stimulus-category competition, inhibition and affective devaluation: A novel account of the Uncanny Valley",
    "section": "",
    "text": "Stimuli that resemble humans, but are not perfectly human-like, are disliked compared to distinctly human and non-human stimuli. Accounts of this “Uncanny Valley” effect often focus on how changes in human resemblance can evoke different emotional responses. We present an alternate account based on the novel hypothesis that the Uncanny Valley is not directly related to ‘human-likeness’ per se, but instead reflects a more general form of stimulus devaluation that occurs when inhibition is triggered to resolve conflict between competing stimulus-related representations. We consider existing support for this inhibitory-devaluation hypothesis and further assess its feasibility through tests of two corresponding predictions that arise from the link between conflict-resolving inhibition and aversive response: (1) that the pronounced disliking of Uncanny-type stimuli will occur for any image that strongly activates multiple competing stimulus representations, even in the absence of any human-likeness, and (2) that the negative peak of an ‘Uncanny Valley’ should occur at the point of greatest stimulus-related conflict and not (in the presence of human-likeness) always closer to the ‘human’ end of a perceptual continuum. We measured affective responses to a set of line drawings representing non-human animal–animal morphs, in which each continuum midpoint was a bistable image (Experiment 1), as well as to sets of human-robot and human-animal computer-generated morphs (Experiment 2). Affective trends depicting classic Uncanny Valley functions occurred for all continua, including the non-human stimuli. Images at continua midpoints elicited significantly more negative affect than images at endpoints, even when the continua included a human endpoint. This illustrates the feasibility of the inhibitory-devaluation hypothesis and the need for further research into the possibility that the strong dislike of Uncanny-type stimuli reflects the negative affective consequences of cognitive inhibition."
  },
  {
    "objectID": "research/articles/ferrey-et-al-2015/index.html#abstract",
    "href": "research/articles/ferrey-et-al-2015/index.html#abstract",
    "title": "Stimulus-category competition, inhibition and affective devaluation: A novel account of the Uncanny Valley",
    "section": "",
    "text": "Stimuli that resemble humans, but are not perfectly human-like, are disliked compared to distinctly human and non-human stimuli. Accounts of this “Uncanny Valley” effect often focus on how changes in human resemblance can evoke different emotional responses. We present an alternate account based on the novel hypothesis that the Uncanny Valley is not directly related to ‘human-likeness’ per se, but instead reflects a more general form of stimulus devaluation that occurs when inhibition is triggered to resolve conflict between competing stimulus-related representations. We consider existing support for this inhibitory-devaluation hypothesis and further assess its feasibility through tests of two corresponding predictions that arise from the link between conflict-resolving inhibition and aversive response: (1) that the pronounced disliking of Uncanny-type stimuli will occur for any image that strongly activates multiple competing stimulus representations, even in the absence of any human-likeness, and (2) that the negative peak of an ‘Uncanny Valley’ should occur at the point of greatest stimulus-related conflict and not (in the presence of human-likeness) always closer to the ‘human’ end of a perceptual continuum. We measured affective responses to a set of line drawings representing non-human animal–animal morphs, in which each continuum midpoint was a bistable image (Experiment 1), as well as to sets of human-robot and human-animal computer-generated morphs (Experiment 2). Affective trends depicting classic Uncanny Valley functions occurred for all continua, including the non-human stimuli. Images at continua midpoints elicited significantly more negative affect than images at endpoints, even when the continua included a human endpoint. This illustrates the feasibility of the inhibitory-devaluation hypothesis and the need for further research into the possibility that the strong dislike of Uncanny-type stimuli reflects the negative affective consequences of cognitive inhibition."
  },
  {
    "objectID": "research/articles/ferrey-et-al-2015/index.html#important-figure",
    "href": "research/articles/ferrey-et-al-2015/index.html#important-figure",
    "title": "Stimulus-category competition, inhibition and affective devaluation: A novel account of the Uncanny Valley",
    "section": "Important figure",
    "text": "Important figure\n\n\n\nFIGURE 4. Computer-generated morphs (human-robot, human-stag, human-tiger, human-lion, human-bird)."
  },
  {
    "objectID": "research/articles/rubel-burleigh-2018/index.html",
    "href": "research/articles/rubel-burleigh-2018/index.html",
    "title": "Counting polyamorists who count: Prevalence and definitions of an under-researched form of consensual nonmonogamy",
    "section": "",
    "text": "Despite a growing interest in polyamory, it is unknown how many polyamorists there are in the general population. In acknowledging that the meaning of “polyamory” is contested (e.g. Klesse, 2014), we estimated the prevalence of polyamory when it was defined as: (1) an identity, (2) relationship beliefs/preferences, (3) relationship status, and (4) relationship agreements. We recruited 972 individuals from Mechanical Turk and used a sample weighting procedure to approximate a representative sample of the population of the USA. Point prevalence estimates ranged from about 0.6% to 5%, and lifetime estimates ranged from about 2% to 23%. Thus, we estimate that there are at least 1.44 million adults in the USA who count as polyamorous."
  },
  {
    "objectID": "research/articles/rubel-burleigh-2018/index.html#abstract",
    "href": "research/articles/rubel-burleigh-2018/index.html#abstract",
    "title": "Counting polyamorists who count: Prevalence and definitions of an under-researched form of consensual nonmonogamy",
    "section": "",
    "text": "Despite a growing interest in polyamory, it is unknown how many polyamorists there are in the general population. In acknowledging that the meaning of “polyamory” is contested (e.g. Klesse, 2014), we estimated the prevalence of polyamory when it was defined as: (1) an identity, (2) relationship beliefs/preferences, (3) relationship status, and (4) relationship agreements. We recruited 972 individuals from Mechanical Turk and used a sample weighting procedure to approximate a representative sample of the population of the USA. Point prevalence estimates ranged from about 0.6% to 5%, and lifetime estimates ranged from about 2% to 23%. Thus, we estimate that there are at least 1.44 million adults in the USA who count as polyamorous."
  },
  {
    "objectID": "research/articles/rubel-burleigh-2018/index.html#important-figure",
    "href": "research/articles/rubel-burleigh-2018/index.html#important-figure",
    "title": "Counting polyamorists who count: Prevalence and definitions of an under-researched form of consensual nonmonogamy",
    "section": "Important figure",
    "text": "Important figure\n\n\n\nFigure 1. Interest in polyamory has been increasing over time, as measured by records in Google Ngram database with “polyamory” keyword (top) and records in the Web of Science database with “polyamory” or “polyamorous” keywords (bottom)."
  },
  {
    "objectID": "research/articles/schoenherr-burleigh-2020/index.html",
    "href": "research/articles/schoenherr-burleigh-2020/index.html",
    "title": "Dissociating affective and cognitive dimensions of uncertainty by altering regulatory focus",
    "section": "",
    "text": "Cognitive uncertainty is evidenced across learning, memory, and decision-making tasks. Uncertainty has also been examined in studies of positive affect and preference by manipulating stimulus presentation frequency. Despite the extensive research in both of these areas, there has been little systematic study into the relationship between affective and cognitive uncertainty. Using a categorization task, the present study examined changes in cognitive and affective uncertainty by manipulating stimulus presentation frequency and processing focus (i.e., promotion v. prevention focus). Following training, participants categorized stimuli and provided ratings of both typicality and negative affect. Results indicated that cognitive uncertainty was influenced by a categorical representation of stimuli whereas affective uncertainty was also influenced by exemplar presentation frequency during training. We additionally found that when the training was framed in terms of the avoidance of errors (i.e., a prevention focus), categorization performance was affected across the stimulus continuum whereas affective ratings remained unchanged."
  },
  {
    "objectID": "research/articles/schoenherr-burleigh-2020/index.html#abstract",
    "href": "research/articles/schoenherr-burleigh-2020/index.html#abstract",
    "title": "Dissociating affective and cognitive dimensions of uncertainty by altering regulatory focus",
    "section": "",
    "text": "Cognitive uncertainty is evidenced across learning, memory, and decision-making tasks. Uncertainty has also been examined in studies of positive affect and preference by manipulating stimulus presentation frequency. Despite the extensive research in both of these areas, there has been little systematic study into the relationship between affective and cognitive uncertainty. Using a categorization task, the present study examined changes in cognitive and affective uncertainty by manipulating stimulus presentation frequency and processing focus (i.e., promotion v. prevention focus). Following training, participants categorized stimuli and provided ratings of both typicality and negative affect. Results indicated that cognitive uncertainty was influenced by a categorical representation of stimuli whereas affective uncertainty was also influenced by exemplar presentation frequency during training. We additionally found that when the training was framed in terms of the avoidance of errors (i.e., a prevention focus), categorization performance was affected across the stimulus continuum whereas affective ratings remained unchanged."
  },
  {
    "objectID": "research/articles/winter-et-al-2019/index.html",
    "href": "research/articles/winter-et-al-2019/index.html",
    "title": "A simplified protocol to screen out VPS and international respondents using Qualtrics",
    "section": "",
    "text": "This protocol is a much simplified update of our original protocol for screening out international and VPS respondents from Qualtrics surveys. It utilizes Qualtrics’ built-in Web Service functionality to interact with IP Hub in looking up potentially problematic respondents."
  },
  {
    "objectID": "research/articles/winter-et-al-2019/index.html#abstract",
    "href": "research/articles/winter-et-al-2019/index.html#abstract",
    "title": "A simplified protocol to screen out VPS and international respondents using Qualtrics",
    "section": "",
    "text": "This protocol is a much simplified update of our original protocol for screening out international and VPS respondents from Qualtrics surveys. It utilizes Qualtrics’ built-in Web Service functionality to interact with IP Hub in looking up potentially problematic respondents."
  },
  {
    "objectID": "research/index.html",
    "href": "research/index.html",
    "title": "Research",
    "section": "",
    "text": "My research is mainly related to cognitive and social psychology. Areas of research include: student perceptions of classroom grading practices, the “Uncanny Valley”, zero-sum thinking, prejudice, social justice, competitiveness, and online research methods."
  },
  {
    "objectID": "research/index.html#journal-articles",
    "href": "research/index.html#journal-articles",
    "title": "Research",
    "section": "Journal articles",
    "text": "Journal articles\n\n\n\n    \n        \n            \n                Kennedy, R., Clifford, S., Burleigh, T., Waggoner, P. D., Jewell, R., & Winter, N. J. (2020). The shape of and solutions to the MTurk quality crisis. Political Science Research and Methods, 8(4), 614-629. doi: 10.1017/psrm.2020.6 \n            \n\n            \n            \n                \n                    \n                            Research Methods\n                        \n                    \n                    \n                            Online Research\n                        \n                    \n                    \n                            Mechanical Turk\n                        \n                    \n            \n            \n\n            \n            \n            \n            \n                \n                    \n                        \n                             Full details »\n                        \n                    \n                    \n                        \n                    \n                        \n                        \n                        \n                             Open access\n                        \n                    \n                        \n                    \n                        \n                        \n                        \n                             Final version\n                        \n                    \n                        \n                    \n                \n            \n        \n        \n        \n            \n                Schoenherr, J. R., & Burleigh, T. J. (2020). Dissociating affective and cognitive dimensions of uncertainty by altering regulatory focus. Acta Psychologica, 205, 103017. doi: 10.1016/j.actpsy.2020.103017\n            \n\n            \n            \n                \n                    \n                            Uncanny Valley\n                        \n                    \n                    \n                            Cognition\n                        \n                    \n                    \n                            Categorical Perception\n                        \n                    \n                    \n                            Experimental\n                        \n                    \n            \n            \n\n            \n            \n            \n            \n                \n                    \n                        \n                             Full details »\n                        \n                    \n                    \n                        \n                    \n                        \n                        \n                        \n                             Final version\n                        \n                    \n                        \n                    \n                \n            \n        \n        \n        \n            \n                Winter, N., Burleigh, T., Kennedy, R., & Clifford, S. (2019). A simplified protocol to screen out VPS and international respondents using Qualtrics. Available at SSRN 3327274. doi: 10.2139/ssrn.3327274 \n            \n\n            \n            \n                \n                    \n                            Online Research\n                        \n                    \n                    \n                            Research Methods\n                        \n                    \n                    \n                            Mechanical Turk\n                        \n                    \n                    \n                            Qualtrics\n                        \n                    \n            \n            \n\n            \n            \n            \n            \n                \n                    \n                        \n                             Full details »\n                        \n                    \n                    \n                        \n                    \n                        \n                        \n                        \n                             Preprint\n                        \n                    \n                        \n                    \n                        \n                        \n                        \n                             Final version\n                        \n                    \n                        \n                    \n                \n            \n        \n        \n        \n            \n                Burleigh, T., Kennedy, R., & Clifford, S. (2018). How to screen out VPS and international respondents using Qualtrics: A protocol. Available at SSRN 3265459. doi: 10.2139/ssrn.3265459 \n            \n\n            \n            \n                \n                    \n                            Research Methods\n                        \n                    \n                    \n                            Online Research\n                        \n                    \n                    \n                            Mechanical Turk\n                        \n                    \n                    \n                            Qualtrics\n                        \n                    \n            \n            \n\n            \n            \n            \n            \n                \n                    \n                        \n                             Full details »\n                        \n                    \n                    \n                        \n                    \n                        \n                        \n                        \n                             Preprint\n                        \n                    \n                        \n                    \n                        \n                        \n                        \n                             Final version\n                        \n                    \n                        \n                    \n                \n            \n        \n        \n        \n            \n                Burleigh, T., & Rubel, A. (2018). Counting polyamorists who count: Prevalence and definitions of an under-researched form of consensual nonmonogamy. doi: 10.1177/1363460718779781\n            \n\n            \n            \n                \n                    \n                            Online Research\n                        \n                    \n                    \n                            Demographics\n                        \n                    \n                    \n                            Sexuality\n                        \n                    \n                    \n                            Consensual Non-Monogamy\n                        \n                    \n            \n            \n\n            \n            \n            \n            \n                \n                    \n                        \n                             Full details »\n                        \n                    \n                    \n                        \n                    \n                        \n                        \n                        \n                             Preprint\n                        \n                    \n                        \n                    \n                        \n                        \n                        \n                             Final version\n                        \n                    \n                        \n                    \n                \n            \n        \n        \n        \n            \n                Sparks, A., Burleigh, T., & Barclay, P. (2016). We can see inside: Accurate prediction of Prisoner's Dilemma decisions in announced games following a face-to-face interaction. Evolution and Human Behavior, 37(3), 210-216. doi: 10.1016/j.evolhumbehav.2015.11.003\n            \n\n            \n            \n                \n                    \n                            Social Cognition\n                        \n                    \n                    \n                            Experimental\n                        \n                    \n                    \n                            Meta-Analysis\n                        \n                    \n            \n            \n\n            \n            \n            \n            \n                \n                    \n                        \n                             Full details »\n                        \n                    \n                    \n                        \n                    \n                        \n                        \n                        \n                             Open Access\n                        \n                    \n                        \n                    \n                        \n                        \n                        \n                             Final version\n                        \n                    \n                        \n                    \n                \n            \n        \n        \n        \n            \n                Wood, J., Desmarais, S., Burleigh, T., & Milhausen, R. (2018). Reasons for sex and relational outcomes in consensually nonmonogamous and monogamous relationships: A self-determination theory approach. Journal of Social and Personal Relationships, 35(4), 632-654. doi: 10.1177/0265407517743082\n            \n\n            \n            \n                \n                    \n                            Sexuality\n                        \n                    \n                    \n                            Consensual Non-Monogamy\n                        \n                    \n            \n            \n\n            \n            \n            \n            \n                \n                    \n                        \n                             Full details »\n                        \n                    \n                    \n                        \n                    \n                        \n                        \n                        \n                             Preprint\n                        \n                    \n                        \n                    \n                        \n                        \n                        \n                             Final version\n                        \n                    \n                        \n                    \n                \n            \n        \n        \n        \n            \n                Burleigh, T. J., & Meegan, D. V. (2018). Risky prospects and risk aversion tendencies: does competition in the classroom depend on grading practices and knowledge of peer-status?. Social Psychology of Education, 21, 323-335. doi: 10.1007/s11218-017-9414-x\n            \n\n            \n            \n                \n                    \n                            Social Justice\n                        \n                    \n                    \n                            Social Cognition\n                        \n                    \n                    \n                            Competition\n                        \n                    \n                    \n                            Student Perceptions\n                        \n                    \n                    \n                            Experimental\n                        \n                    \n            \n            \n\n            \n            \n            \n            \n                \n                    \n                        \n                             Full details »\n                        \n                    \n                    \n                        \n                    \n                        \n                        \n                        \n                             Preprint\n                        \n                    \n                        \n                    \n                        \n                        \n                        \n                             Final version\n                        \n                    \n                        \n                    \n                \n            \n        \n        \n        \n            \n                Burleigh, T. J., Rubel, A. N., & Meegan, D. V. (2017). Wanting ‘the whole loaf’: Zero-sum thinking about love is associated with prejudice against consensual non-monogamists. Psychology & Sexuality, 8(1-2), 24-40. doi: 10.1080/19419899.2016.1269020\n            \n\n            \n            \n                \n                    \n                            Sexuality\n                        \n                    \n                    \n                            Prejudice\n                        \n                    \n                    \n                            Consensual Non-Monogamy\n                        \n                    \n                    \n                            Zero-sum Thinking\n                        \n                    \n                    \n                            Experimental\n                        \n                    \n            \n            \n\n            \n            \n            \n            \n                \n                    \n                        \n                             Full details »\n                        \n                    \n                    \n                        \n                    \n                        \n                        \n                        \n                             Preprint\n                        \n                    \n                        \n                    \n                        \n                        \n                        \n                             Final version\n                        \n                    \n                        \n                    \n                \n            \n        \n        \n        \n            \n                Ferrey, A. E., Burleigh, T. J., & Fenske, M. J. (2015). Stimulus-category competition, inhibition, and affective devaluation: a novel account of the uncanny valley. Frontiers in psychology, 6, 249. doi: 10.3389/fpsyg.2015.00249\n            \n\n            \n            \n                \n                    \n                            Cognition\n                        \n                    \n                    \n                            Categorical Perception\n                        \n                    \n                    \n                            Experimental\n                        \n                    \n            \n            \n\n            \n            \n            \n            \n                \n                    \n                        \n                             Full details »\n                        \n                    \n                    \n                        \n                    \n                        \n                        \n                        \n                             Preprint\n                        \n                    \n                        \n                    \n                        \n                        \n                        \n                             Final version\n                        \n                    \n                        \n                    \n                \n            \n        \n        \n        \n            \n                Burleigh, T. J., & Schoenherr, J. R. (2015). A reappraisal of the uncanny valley: categorical perception or frequency-based sensitization?. Frontiers in Psychology, 5, 1488. doi: 10.3389/fpsyg.2014.01488\n            \n\n            \n            \n                \n                    \n                            Uncanny Valley\n                        \n                    \n                    \n                            Categorical Perception\n                        \n                    \n                    \n                            Cognition\n                        \n                    \n                    \n                            Experimental\n                        \n                    \n            \n            \n\n            \n            \n            \n            \n                \n                    \n                        \n                             Full details »\n                        \n                    \n                    \n                        \n                    \n                        \n                        \n                        \n                             Open access\n                        \n                    \n                        \n                    \n                        \n                        \n                        \n                             Final version\n                        \n                    \n                        \n                    \n                \n            \n        \n        \n        \n            \n                Schoenherr, J. R., & Burleigh, T. J. (2015). Uncanny sociocultural categories. Frontiers in Psychology, 5, 1456. doi: 10.3389/fpsyg.2014.01456\n            \n\n            \n            \n                \n                    \n                            Uncanny Valley\n                        \n                    \n                    \n                            Cognition\n                        \n                    \n            \n            \n\n            \n            \n            \n            \n                \n                    \n                        \n                             Full details »\n                        \n                    \n                    \n                        \n                    \n                        \n                        \n                        \n                             Preprint\n                        \n                    \n                        \n                    \n                        \n                        \n                        \n                             Final version\n                        \n                    \n                        \n                    \n                \n            \n        \n        \n        \n            \n                Burleigh, T. J., Schoenherr, J. R., & Lacroix, G. L. (2013). Does the uncanny valley exist? An empirical test of the relationship between eeriness and the human likeness of digitally created faces. Computers in human behavior, 29(3), 759-771. doi: 10.1016/j.chb.2012.11.021\n            \n\n            \n            \n                \n                    \n                            Uncanny Valley\n                        \n                    \n                    \n                            Categorical Perception\n                        \n                    \n                    \n                            Cognition\n                        \n                    \n                    \n                            Experimental\n                        \n                    \n            \n            \n\n            \n            \n            \n            \n                \n                    \n                        \n                             Full details »\n                        \n                    \n                    \n                        \n                    \n                        \n                        \n                        \n                             Preprint\n                        \n                    \n                        \n                    \n                        \n                        \n                        \n                             Final version\n                        \n                    \n                        \n                    \n                \n            \n        \n        \n        \n            \n                Burleigh, T. J., & Meegan, D. V. (2013). Keeping up with the Joneses affects perceptions of distributive justice. Social justice research, 26, 120-131. doi: 10.1007/s11211-013-0181-3\n            \n\n            \n            \n                \n                    \n                            Social Justice\n                        \n                    \n                    \n                            Social Cognition\n                        \n                    \n                    \n                            Fairness\n                        \n                    \n                    \n                            Student Perceptions\n                        \n                    \n                    \n                            Experimental\n                        \n                    \n            \n            \n\n            \n            \n            \n            \n                \n                    \n                        \n                             Full details »\n                        \n                    \n                    \n                        \n                    \n                        \n                        \n                        \n                             Preprint\n                        \n                    \n                        \n                    \n                        \n                        \n                        \n                             Final version\n                        \n                    \n                        \n                    \n                \n            \n        \n        \n\n\n\nNo matching items"
  }
]